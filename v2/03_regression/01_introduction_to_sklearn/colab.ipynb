{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to scikit-learn",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1",
        "exercise-3-key-1",
        "exercise-4-key-1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/v2/03_regression/01_introduction_to_sklearn/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pGgUGFhfBtri",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56E1PL91CGS0"
      },
      "source": [
        "# Introduction to scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fW-s1cCLCJ8n"
      },
      "source": [
        "[Scikit-learn](https://scikit-learn.org) is a machine learning library in Python.\n",
        "\n",
        "Scikit-learn is the first of the several machine learning libraries we will explore in this course. It is relatively approachable, supports a wide variety of traditional machine learning models, and is ubiquitous in the world of data science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ftyf6QX2GWPy"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3nvll9SJpVF"
      },
      "source": [
        "Scikit-learn contains methods for loading, fetching, and making (generating) data. The methods for doing this all fall under the [datasets](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) subpackage. Most of the functions in this package have `load`, `fetch`, or `make` in the name to let you know what the method is doing under the hood.\n",
        "\n",
        "**Loading functions** bring static datasets into your program. The data comes pre-packaged with scikit-learn, so no network access is required.\n",
        "\n",
        "**Fetching functions** also bring static datasets into your program. However, the data is pulled from the internet, so if you don't have network access, these functions might fail.\n",
        "\n",
        "**Generating functions** make dynamic datasets based on some equation.\n",
        "\n",
        "These pre-packaged dataset functions exist for many popular datasets, such as the [MNIST digits dataset](https://en.wikipedia.org/wiki/MNIST_database) and the [Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). The generation functions reference classic dataset \"shape\" formations such as [moons](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html#sklearn.datasets.make_moons) and [swiss rolls](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html#sklearn.datasets.make_swiss_roll). These datasets are perfect for getting familiar with machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sO11StjHLvDS"
      },
      "source": [
        "### Loading\n",
        "\n",
        "Let us first look at an example of loading data. We will load the iris flowers dataset using the [load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ky399k0ENjHA",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "iris_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1uP53SEUlNL"
      },
      "source": [
        "That's a lot to take in. Let's examine this loaded data a little more closely. First we'll see what data type this dataset is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XItKuboUvPw",
        "colab": {}
      },
      "source": [
        "type(iris_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyLpaX9YgX7E"
      },
      "source": [
        "`sklearn.utils.Bunch` is a type that you'll see quite often when working with datasets built into scikit-learn. It is a dictionary-like container for feature and target data within a dataset.\n",
        "\n",
        "You won't find much documentation about `Bunch` objects because they are not really meant for usage beyond containing data native to scikit-learn.\n",
        "\n",
        "Let's look at the attributes of the iris dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eGrbFQUmg1-o",
        "colab": {}
      },
      "source": [
        "dir(iris_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z_jc4IenhD-R"
      },
      "source": [
        "`DESCR` is a description of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "naIUF-N6hHRE",
        "colab": {}
      },
      "source": [
        "print(iris_data['DESCR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nOpF9GErhUR1"
      },
      "source": [
        "`filename` is the name of the source file where the data is stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MAMVCeH3hW4E",
        "colab": {}
      },
      "source": [
        "print(iris_data['filename'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAk8huE1henA"
      },
      "source": [
        "`feature_names` is the names of the feature columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDe49sqchg6B",
        "colab": {}
      },
      "source": [
        "print(iris_data['feature_names'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-sWrsHG9hz9m"
      },
      "source": [
        "`target_names`, despite the name, is not the names of the target columns. There is only one column of targets.\n",
        "\n",
        "Instead, `target_names` is the human-readable names of the classes in the target list within the bunch. In this case,`target_names` is the names of the three species of iris in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "axZadl--hy09",
        "colab": {}
      },
      "source": [
        "print(iris_data['target_names'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6haqEFs2iXBX"
      },
      "source": [
        "We can now examine `target` and see that it contains zeros, ones, and twos. These correspond to the target names 'setosa', 'versicolor', and 'virginica'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S6DV058KiSxA",
        "colab": {}
      },
      "source": [
        "print(iris_data['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LdHpL7wxikzx"
      },
      "source": [
        "Last, we'll look at the `data` within the bunch. The data is an array of arrays. Each sub-array contains four values. These values match up with the `feature_names`. The first item in each sub-array is 'sepal length (cm)', the next is 'sepal width (cm)', and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FGp_Zod2iovU",
        "colab": {}
      },
      "source": [
        "iris_data['data']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dwObt9fhi-e_"
      },
      "source": [
        "The number of target values should always equal the number of rows in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ce26qiH8jDOr",
        "colab": {}
      },
      "source": [
        "print(len(iris_data['data']))\n",
        "print(len(iris_data['target']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JMRCb4sFjPwE"
      },
      "source": [
        "`Bunch` objects are an adequate container for data. They can be used directly to feed models. However, `Bunch` objects are *not* very good for analyzing and manipulating your data.\n",
        "\n",
        "In this course, we will typically convert `Bunch` objects into Pandas `DataFrame` objects to make analysis, data cleaning, visualization, and train/test splitting easier.\n",
        "\n",
        "To do this, we will take the matrix of feature data and append the target data to it to create a single matrix of data. We also take the list of feature names and append the word 'species' to represent the target classes in the matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RV9YXbofkESG",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iris_df = pd.DataFrame(\n",
        "  data=np.append(\n",
        "    iris_data['data'], \n",
        "    np.array(iris_data['target']).reshape(len(iris_data['target']), 1), \n",
        "    axis=1),\n",
        "  columns=np.append(iris_data['feature_names'], ['species'])\n",
        ")\n",
        "\n",
        "iris_df.sample(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mGJSXwWUiLAQ"
      },
      "source": [
        "You might notice that the integer representation of species got converted to a floating point number along the way. We can change that back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nIM1mPm2iYLj",
        "colab": {}
      },
      "source": [
        "iris_df['species'] = iris_df['species'].astype('int64')\n",
        "\n",
        "iris_df.sample(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22oKL4SMexsr"
      },
      "source": [
        "### Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6K9IrnNBoHxB"
      },
      "source": [
        "Load the [Boston house price dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) into a Pandas `DataFrame`. Append the target values to the last column of the `DataFrame` called `boston_df`. Name the target column 'PRICE'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDd0ygxP-o3L"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SJCrOW1DfOBe",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zKs1Z873NGC",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IICeaKEEfTdl",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "boston_data = load_boston()\n",
        "\n",
        "boston_df = pd.DataFrame(\n",
        "  data=np.append(\n",
        "    boston_data['data'], \n",
        "    np.array(boston_data['target']).reshape(len(boston_data['target']), 1), \n",
        "    axis=1),\n",
        "  columns=np.append(boston_data['feature_names'], ['PRICE'])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3eDXYm53LYl",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SCsSQGBBi0XX"
      },
      "source": [
        "### Fetching\n",
        "\n",
        "Fetching is similar to loading. Scikit-learn will first see if it can find the dataset locally, and, if so, it will simply load the data. Otherwise, it will attempt to pull the data from the internet.\n",
        "\n",
        "We can see fetching in action with the [fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing) function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IWIjnqDEjVXX",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing_data = fetch_california_housing()\n",
        "\n",
        "type(housing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sal1rRb0j1G7"
      },
      "source": [
        "The dataset is once again a `Bunch`.\n",
        "\n",
        "If you follow the link to the [fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing) documentation, you notice that the dataset is a **regression** dataset as opposed to the iris dataset, which was a **classification** dataset.\n",
        "\n",
        "We can see the difference in the dataset by checking out the attributes of the `Bunch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0NOhdK0gjxWS",
        "colab": {}
      },
      "source": [
        "dir(housing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CJ8bVa53kYv9"
      },
      "source": [
        "We see that four of the attributes that we expect are present, but 'target_names' is missing. This is because our target is now a continuous variable (home price) and not a discrete value (iris species)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ClIX_emkj9N",
        "colab": {}
      },
      "source": [
        "print(housing_data['target'][:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PUDwxxB2J8wP"
      },
      "source": [
        "Converting a `Bunch` of regression data to a `DataFrame` is no different than for a `Bunch` of classification data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LdRWov44k3lJ",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "housing_df = pd.DataFrame(\n",
        "  data=np.append(\n",
        "    housing_data['data'], \n",
        "    np.array(housing_data['target']).reshape(len(housing_data['target']), 1), \n",
        "    axis=1),\n",
        "  columns=np.append(housing_data['feature_names'], ['price'])\n",
        ")\n",
        "\n",
        "housing_df.sample(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "omIwmr8QlX4W"
      },
      "source": [
        "### Generating\n",
        "\n",
        "In the example datasets we've seen so far in this colab, the data is static and loaded from a file. Sometimes it makes more sense to generate a dataset. For this, we can use one of the many [generator functions](https://scikit-learn.org/stable/modules/classes.html#samples-generator)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tIV-WDaLnKoZ"
      },
      "source": [
        "`make_regression` is a generator that creates a dataset with an underlying regression that you can then attempt to discover using various machine learning models.\n",
        "\n",
        "In the example below, we create a dataset with 10 data points. For the sake of visualization, we have only one feature per datapoint, but we could ask for more.\n",
        "\n",
        "The return value are the $X$ and $y$ values for the regression. $X$ is a matrix of features. $y$ is a list of targets.\n",
        "\n",
        "Since a generator uses randomness to generate data, we are going to set a `random_state` in this colab for reproducibility. This ensures we get the same result every time we run the code. **You won't do this in your production code.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MiR5MD06l44S",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "features, targets = make_regression(n_samples=10, n_features=1, random_state=42)\n",
        "\n",
        "features, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mPGFAiWXn-L2"
      },
      "source": [
        "We can use a visualization library to plot the regression data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a3G9YzxnnlgN",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6CaLo1RUoFaa"
      },
      "source": [
        "That data appears to have a very linear pattern!\n",
        "\n",
        "If we want to make it more realistic (non-linear), we can add some noise during data generation.\n",
        "\n",
        "**Remember that random_state is for reproducibility only. Don't use this in your code unless you have a good reason to.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_FL8nFnoOET",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "features, targets = make_regression(n_samples=10, n_features=1, random_state=42, noise=5.0)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xEAwguq9oqU_"
      },
      "source": [
        "There are dozens of dataset loaders and generators in the scikit-learn [datasets](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) package. When you want to play with a new machine learning algorithm, they are a great source of data for getting started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3QLCOmwXi3Gn"
      },
      "source": [
        "### Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YAB-WxNgoKDp"
      },
      "source": [
        "Search the [scikit-learn datasets documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) and find a function to make a \"Moons\" dataset. Create a dataset with 75 samples. Use a random state of 42 and a noise of 0.08. Store the $X$ return value in a variable called `features` and the $y$ return value in a variable called `targets`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uenWPTVD-iYN"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fg8y7o5bjw5-",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipe_qpOy3GF4",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWKxB3hfjz9m",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "features, targets = make_moons(n_samples=75, random_state=42, noise=0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "elKuseTE-bKU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kx7HErvKnAbE"
      },
      "source": [
        "### Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRQq8jR6oMYc"
      },
      "source": [
        "In Exercise Two, you created a \"moons\" dataset. In that dataset, the features are $(x,y)$-coordinates that can be graphed in a scatterplot. The targets are zeros and ones that represent a binary classification.\n",
        "\n",
        "Use matplotlib's [scatter method](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) to visualize the data as a scatterplot. Use the `c` argument to make the dots for each class a different color."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "atYw390N-Yn-"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWDeint14m3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ugn5JaN5aGh",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-3-key-1"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_5dHZ5lnkfd",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features, targets = make_moons(n_samples=75, random_state=42, noise=0.08)\n",
        "\n",
        "plt.scatter(features[:, 0], features[:, 1], c=targets)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCHoH5lt5bds",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PH7eg79ApDWK"
      },
      "source": [
        "## Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgxQbr7apHtX"
      },
      "source": [
        "Machine learning involves training a model to gain insight and predictive power from a dataset. Scikit-learn has support for many different types of models, ranging from classic algebraic models to more modern deep learning models.\n",
        "\n",
        "Throughout the remainder of this course, you will learn about many of these models in much more depth. This section will walk you through some of the overarching concepts across all models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NQZBibFBlgaI"
      },
      "source": [
        "### Estimators\n",
        "\n",
        "Most of the models in scikit-learn are considered [estimators](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator). An estimator is expected to implement two methods: `fit` and `predict`.\n",
        "\n",
        "`fit` is used to train the model. At a minimum, it is passed the feature data used to train the model. In supervised models, it is also passed the target data.\n",
        "\n",
        "`predict` is used to get predictions from the model. This method is passed features and returns target predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YAbSxJWngm_"
      },
      "source": [
        "Let's see an example of this in action.\n",
        "\n",
        "Linear regression is a simple model that you might have encountered in a statistics class in the past. The model attempts to draw a straight line through a set of data points, so the line is as close to as many points as possible.\n",
        "\n",
        "We'll use scikit-learn's [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class to fit a line to the regression data that we generated earlier in this colab. To do that, we simply call the `fit(features, targets)` method.\n",
        "\n",
        "After fitting, we can ask the model for predictions. To do this, we use the `predict(features)` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5LNyQLumj8Qt",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regression = LinearRegression()\n",
        "regression.fit(features, targets)\n",
        "predictions = regression.predict(features)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.plot(features, predictions, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYzxy7UeofmQ"
      },
      "source": [
        "At this point, don't worry too much about the details of what `LinearRegression` is doing. There is a deep-dive into regression problems coming up soon.\n",
        "\n",
        "For now, just note the `fit`/`predict` pattern for training estimators, and know that you'll see it throughout our adventures with scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6DgmveIfo6g9"
      },
      "source": [
        "### Transformers\n",
        "\n",
        "In practice, it is rare that you will get perfectly clean data that is ready to feed into your model for training. Most of the time, you will need to perform some type of cleaning on the data first.\n",
        "\n",
        "You've had some hands-on experience doing this in our Pandas colabs. Scikit-learn can also be used to perform some data preprocessing.\n",
        "\n",
        "Transformers are spread about within the scikit-learn library. Some are in the [preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module while others are in more specialized packages like [compose](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose), [feature_extraction](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction), [impute](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute), and others.\n",
        "\n",
        "All transformers implement the `fit` and `transform` methods. The `fit` method calculates parameters necessary to perform the data transformation. The `transform` method actually applies the transformation. There is a convenience `fit_transform` method that performs both fitting and transformation in one method call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pTgwqMxuPmPA"
      },
      "source": [
        "Let's see a transformer in action.\n",
        "\n",
        "We will use the [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) to scale our feature data between zero and one. This scales the data with a linear transform so that the minimum value becomes 0 and the maximum value becomes 1, so all values are within 0 and 1.\n",
        "\n",
        "Looking at our feature data pre-transformation, we can see values that are below zero and above one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I-LZHd6LP60G",
        "colab": {}
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyPTAg2JP9xO"
      },
      "source": [
        "We will now create a `MinMaxScaler` and fit it to our feature data.\n",
        "\n",
        "Each transformer has different information that it needs in order to perform a transformation. In the case of the `MinMaxScaler`, the smallest and largest values in the data are needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4O9ZSNZdOg9J",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "transformer = MinMaxScaler()\n",
        "transformer.fit(features)\n",
        "transformer.data_min_, transformer.data_max_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QoxuBVpFQmOP"
      },
      "source": [
        "You might notice that the values are stored in arrays. This is because transformers can operate on more than one feature. In this case, however, we have only one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xDS2hECWQvRi"
      },
      "source": [
        "Next, we need to apply the transformation to our features. After the transformation, we can now see that all of the features fall between the range of zero to one. Moreover, you might notice that the minimum and maximum value in the untransformed `features` array correspond to the 0 and 1 in the transformed array, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j_xYLozNQxrP",
        "colab": {}
      },
      "source": [
        "features = transformer.transform(features)\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0UPfbF0CQ-lI"
      },
      "source": [
        "### Pipelines\n",
        "\n",
        "A [pipeline](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline) is simply a series of transformers, often with an estimator at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l0O6u-_2TfAj"
      },
      "source": [
        "In the example below, we use a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class to perform min-max scaling or our feature data and then train a linear regression model using the scaled features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4p2o-I2fSG1O",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "features, targets = make_regression(\n",
        "    n_samples=10, n_features=1, random_state=42, noise=5.0)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('scale', MinMaxScaler()),\n",
        "  ('regression', LinearRegression())\n",
        "])\n",
        "\n",
        "pipeline.fit(features, targets)\n",
        "\n",
        "predictions = pipeline.predict(features)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.plot(features, predictions, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "prTIe6_GUkm9"
      },
      "source": [
        "### Metrics\n",
        "\n",
        "So far we have seen ways that scikit-learn can help you get data, modify that data, train a model, and finally, make predictions. But how do we know how good these predictions are?\n",
        "\n",
        "Scikit-learn also comes with many functions for measuring model performance in the [metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) package. Later in this course, you will learn about different ways to measure the performance of regression and classification models, as well as tradeoffs between the different metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AWi3wKw_cYbN"
      },
      "source": [
        "We can use the [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) function to find the mean squared error (MSE) between the target values that we used to train our linear regression model and the predicted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tLs7G3oWaJBd",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(targets, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7xZORiurbb4D"
      },
      "source": [
        "In this case, the MSE value alone doesn't have much meaning. Since the data that we fit the regression to isn't related to any real-world metrics, the MSE is hard to interpret alone.\n",
        "\n",
        "As we learn more about machine learning and begin training models on real data, you'll learn how to interpret MSE and other metrics in the context of the data being analyzed and the problem being solved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yvBWBvc9cyRN"
      },
      "source": [
        "There are also metrics that come with each estimator class. These metrics can be extracted using the `score` method.\n",
        "\n",
        "The `regression` class we created earlier can be scored, as can the `pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b2vz0Y__cQT3",
        "colab": {}
      },
      "source": [
        "print(regression.score(features, targets))\n",
        "print(pipeline.score(features, targets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kfEBzfm9dSce"
      },
      "source": [
        "The return value of the `score` method depends on the estimator being used. In the case of `LinearRegression`, the score is the $R^2$ score, where scores closer to 1.0 are better. You can find the metric that `score` returns in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) for the given estimator you're using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UQhscobnqFdc"
      },
      "source": [
        "### Exercise 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VLNgam9WoQc8"
      },
      "source": [
        "Use the [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class to combine a data pre-processor and an estimator.\n",
        "\n",
        "To accomplish this:\n",
        "\n",
        "1. Find a [preprocessor](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) that uses the max absolute value for scaling.\n",
        "1. Find a [linear_model](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) based on the Huber algorithm.\n",
        "1. Combine this preprocessor and estimator into a pipeline.\n",
        "1. Make a sample regression dataset with 200 samples and 1 feature. Use a random state of 85 and a noise of 5.0. Save the features in a variable called `features` and the targets in a variable called `targets`.\n",
        "1. Fit the model.\n",
        "1. Using the features that were created when the regression dataset was created, make predictions with the model and save them into a variable called `predictions`.\n",
        "1. Plot the features and targets used to train the model on a scatterplot with blue dots.\n",
        "1. Plot the features and predictions over the scatterplot as a red line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aAidCrO3-PtA"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgEaukESqHpm",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FocRxbST6XpW",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-4-key-1"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5KL8WwFqJEV",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('scale', MaxAbsScaler()),\n",
        "  ('regression', HuberRegressor())\n",
        "])\n",
        "\n",
        "features, targets = make_regression(n_samples=200, n_features=1, random_state=85, noise=5.0)\n",
        "\n",
        "pipeline.fit(features, targets)\n",
        "\n",
        "predictions = pipeline.predict(features)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.plot(features, predictions, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTWMU17y6YjF",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T_mlNNxxd-8l"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Scikit-learn is a widely used library that contains scores of resources for performing machine learning. In this colab, we have introduced some basic concepts that you will see repeated throughout your career in data science. We will cover other parts of scikit-learn later in the course.\n",
        "\n",
        "You are also encouraged to check out the [scikit-learn documentation](https://scikit-learn.org/stable/documentation.html), where you will find a user guide, tutorials, and a full API reference.\n",
        "\n",
        "Scikit-learn is an open source project. You can find it on Github [here](https://github.com/scikit-learn/scikit-learn)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8aQ_TRj-DCms"
      },
      "source": [
        "## Resources\n",
        "\n",
        "* https://scikit-learn.org/stable/documentation.html\n",
        "* https://en.wikipedia.org/wiki/Scikit-learn\n",
        "* https://en.wikipedia.org/wiki/Estimator\n",
        "* https://en.wikipedia.org/wiki/Mean_squared_error\n",
        "* https://github.com/scikit-learn/scikit-learn"
      ]
    }
  ]
}
