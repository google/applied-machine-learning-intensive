{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification Project",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "yFwKrxE38t9S",
        "w5j2HpIW-ocU",
        "GSsiZ2YB1ADy"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/v2/04_classification/10_image_classification_project/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFwKrxE38t9S",
        "colab_type": "text"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpcrMDk48nqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZOeKjw8waH",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK5j0BXxrbfX",
        "colab_type": "text"
      },
      "source": [
        "In this project, we will build an image classification model and use the model to identify if the lungs pictured indicate that the patient has pneumonia.  The outcome of the model will be true or false for each image.\n",
        "\n",
        "The [data is hosted on Kaggle](https://www.kaggle.com/rob717/pneumonia-dataset) and consists of 5,863 x-ray images. Each image is classified as 'pneumonia' or 'normal'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ht1GVr68swO",
        "colab_type": "text"
      },
      "source": [
        "## Ethical Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW94_8-98vpR",
        "colab_type": "text"
      },
      "source": [
        "We will frame the problem as:\n",
        "\n",
        "> *A global pandemic has broken out and hospitals are overwhelmed. One of the primary symptoms of infected individuals is pneumonia. If a patient can be quickly confirmed to have pneumonia, then they can be quickly quarantined before infecting other patients.*\n",
        ">\n",
        "> *The problem is that medical staff are overwhelmed and under-rested. There are often times when there is no trained technician available to read lung x-rays and make the call of pneumonia/normal.*\n",
        ">\n",
        "> *We have been given some recent x-rays of patients, along with the pneumonia/normal classification. We've been asked to build a model that can be used by an untrained technician to get an initial pneumonia/normal indication for a patient. If the model indicates that the patient is positive for pneumonia, then the patient will be quarantined until a trained technician can make a final call.*\n",
        "\n",
        "Discuss some of the ethical considerations of building and using this model. \n",
        "\n",
        "* Consider potential bias in the data that we have been provided. \n",
        "* Should this model err toward precision or accuracy?\n",
        "* What are the implications of massively over-classifying patients as having pneumonia?\n",
        "* What are the implications of massively under-classifying patients as having pneumonia?\n",
        "* Are there any concerns with untrained technicians making the initial call?\n",
        "\n",
        "The questions above are prompts. Feel free to bring in other considerations that you might have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgUwTn_K-iK6",
        "colab_type": "text"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i0zCRDT-j58",
        "colab_type": "text"
      },
      "source": [
        "> *Your answer goes here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9AxwuxE-nQt",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5j2HpIW-ocU",
        "colab_type": "text"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9iropON-uet",
        "colab_type": "text"
      },
      "source": [
        "As with other ethics question, there are many right answers. We are looking for solid consideration of trade-offs.\n",
        "\n",
        "Some example solutions for the prompt questions:\n",
        "\n",
        "**Consider potential bias in the data that we've been provided.**\n",
        "\n",
        "> *This is recent data from one hospital. What if other hospitals choose to use the model? Would it generalize to non-local patients? Expecially if the x-ray equipment is different across hospitals.*\n",
        "\n",
        "**Should this model err toward precision or accuracy?**\n",
        "\n",
        "> *This is a tough call because one can overwhelm the isolation spaces while the other could speed up the spread of the pandemic. A higher recall would be preferred if the pandemic was highly contagious. A higher precision might be preferred if the hospital was already out of space.*\n",
        "\n",
        "**What are the implications of massively over-classifying patients as having pneumonia?**\n",
        "\n",
        "> *Overwhelmed hospitals.*\n",
        "\n",
        "**What are the implications of massively under-classifying patients as having pneumonia?**\n",
        "\n",
        "> *Larger than necessary disease spread.*\n",
        "\n",
        "**Are there any concerns with untrained technicians making the initial call?**\n",
        "\n",
        "> *The techs might lean too much on the model and not make \"expert decisions\" on their own. They would likely trust the model too much.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0hUUdtKAlMk",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZFanABOAoHl",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxnS0ZlQAqNj",
        "colab_type": "text"
      },
      "source": [
        "In this section of the lab, you will build, train, test, and validate a model or models. The data is the [\"Detecting Pneumonia\" dataset](https://www.kaggle.com/rob717/pneumonia-dataset). You will build a binary classifier that determines if an x-ray image has pneumonia or not.\n",
        "\n",
        "You'll need to:\n",
        "\n",
        "* Download the dataset\n",
        "* Perform EDA on the dataset\n",
        "* Build a model that can classify the data\n",
        "* Train the model using the training portion of the dataset (it is already split out)\n",
        "* Test at least three different models or model configurations using the testing portion of the dataset. This can include changing model types, adding and removing layers or nodes from a neural network, or any other parameter tuning that you find potentially useful. Score the model (using accuracy, precision, recall, F1, or some other relevant score(s)) for each configuration.\n",
        "* After finding the \"best\" model and parameters, use the validation portion of the dataset to perform one final sanity check by scoring the model once more with the hold-out data.\n",
        "* If you train a neural network (or other model that you can get epoch-per-epoch performance), graph that performance over each epoch.\n",
        "\n",
        "Explain your work!\n",
        "\n",
        "> *Note: You'll likely want to [enable GPU in this lab](https://colab.research.google.com/notebooks/gpu.ipynb), if it is not already enabled.*\n",
        "\n",
        "If you get to a working solution that you are happy with and want another challenge, you'll find pre-trained models on the [landing page of the dataset](https://www.kaggle.com/paultimothymooney/detecting-pneumonia-in-x-ray-images). Try to load one of those and see how it compares to your best model.\n",
        "\n",
        "Use as many text and code cells as you need to for your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7XM35vYWSbim"
      },
      "source": [
        "### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ivTzfzQN5jDk",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5AaFcUV8NCB",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GSsiZ2YB1ADy"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suA3Bvj_C398",
        "colab_type": "text"
      },
      "source": [
        "After uploading our `kaggle.json` file into the colab, we move it into place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9mgG0hRw0sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix-v_z8nC7Va",
        "colab_type": "text"
      },
      "source": [
        "Then we download the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFFgd2QaxYI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle datasets download paultimothymooney/chest-xray-pneumonia/kernels\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPuwAo0_C95v",
        "colab_type": "text"
      },
      "source": [
        "And extract it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFFnn6kExj4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "zipfile.ZipFile('chest-xray-pneumonia.zip').extractall()\n",
        "os.listdir('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs2DnwULDAZe",
        "colab_type": "text"
      },
      "source": [
        "We search all of the directories to see what files we are dealing with. All end up being `jpeg` files. However, they are triplicated in the version of the data that we tested with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2pCuf-e3g7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "for directory, _, files in os.walk('chest_xray'):\n",
        "  extensions = collections.defaultdict(int)\n",
        "  for file_name in files:\n",
        "    extensions[file_name[file_name.rindex('.') + 1:]] += 1\n",
        "  print(directory, extensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBPYR2zaDMRe",
        "colab_type": "text"
      },
      "source": [
        "Set up some useful variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyQDSzTi4X0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_dir = 'chest_xray/train'\n",
        "testing_dir = 'chest_xray/test'\n",
        "validation_dir = 'chest_xray/val'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haVFlzVGDRan",
        "colab_type": "text"
      },
      "source": [
        "Build and score our first model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmD_NbRqjwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', \n",
        "                           input_shape=(256, 256 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "train_data_gen = ImageDataGenerator().flow_from_directory(\n",
        "    directory=training_dir)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=200,\n",
        "    steps_per_epoch=200,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss')]\n",
        ")\n",
        "\n",
        "testing_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    directory=testing_dir,\n",
        "    image_data_generator=None)\n",
        "\n",
        "predictions = model.predict(testing_image_iterator)\n",
        "predicted_classes = [int(prediction > 0.5) for prediction in predictions.flatten()]\n",
        "\n",
        "actual_classes = testing_image_iterator.classes\n",
        "\n",
        "f1_score(actual_classes, predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2wteHseERVZ",
        "colab_type": "text"
      },
      "source": [
        "Plot the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hI_HoxESxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VzXT_PHETV3",
        "colab_type": "text"
      },
      "source": [
        "And loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1hoYhA8EUHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))),\n",
        "         history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYdZRS0BDbT6",
        "colab_type": "text"
      },
      "source": [
        "Add a few more layers and score again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9GqUxIo5pug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                           input_shape=(256, 256 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    # New layers below\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    # New layers above\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "train_data_gen = ImageDataGenerator().flow_from_directory(\n",
        "    directory=training_dir)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=200,\n",
        "    steps_per_epoch=200,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss')]\n",
        ")\n",
        "\n",
        "testing_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    directory=testing_dir,\n",
        "    image_data_generator=None)\n",
        "\n",
        "predictions = model.predict(testing_image_iterator)\n",
        "predicted_classes = [int(prediction > 0.5) for prediction in predictions.flatten()]\n",
        "\n",
        "actual_classes = testing_image_iterator.classes\n",
        "\n",
        "f1_score(actual_classes, predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAqYMLOVEWw_",
        "colab_type": "text"
      },
      "source": [
        "Plot the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCFI3Hz2EYZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT_RcBoqEZF7",
        "colab_type": "text"
      },
      "source": [
        "And loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qDGXS8iEaM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))),\n",
        "         history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxKydfHbDuS9",
        "colab_type": "text"
      },
      "source": [
        "Try using a different threshold for our classifier and score that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW_M_1Mg7L-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',\n",
        "                           input_shape=(256, 256 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "train_data_gen = ImageDataGenerator().flow_from_directory(\n",
        "    directory=training_dir)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=200,\n",
        "    steps_per_epoch=200,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss')]\n",
        ")\n",
        "\n",
        "testing_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    directory=testing_dir,\n",
        "    image_data_generator=None)\n",
        "\n",
        "predictions = model.predict(testing_image_iterator)\n",
        "\n",
        "# Higher threshold below\n",
        "predicted_classes = [int(prediction > 0.6) for prediction in predictions.flatten()]\n",
        "# Higher threshold above\n",
        "\n",
        "actual_classes = testing_image_iterator.classes\n",
        "\n",
        "f1_score(actual_classes, predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41h_6roAEfZb",
        "colab_type": "text"
      },
      "source": [
        "Plot the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLQvuFBhEg8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNKF6BsQEhsE",
        "colab_type": "text"
      },
      "source": [
        "And loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipIGG3SwEif8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))),\n",
        "         history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5U4jTP4D0jH",
        "colab_type": "text"
      },
      "source": [
        "Re-score our best model against the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZY8R9dB7pnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256, 256 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "train_data_gen = ImageDataGenerator().flow_from_directory(\n",
        "    directory=training_dir)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=200,\n",
        "    steps_per_epoch=200,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss')]\n",
        ")\n",
        "\n",
        "# Using validation data below instead of test\n",
        "validation_image_iterator = tf.keras.preprocessing.image.DirectoryIterator(\n",
        "    directory=validation_dir,\n",
        "    image_data_generator=None)\n",
        "\n",
        "predictions = model.predict(validation_image_iterator)\n",
        "predicted_classes = [int(prediction > 0.6) for prediction in predictions.flatten()]\n",
        "\n",
        "actual_classes = validation_image_iterator.classes\n",
        "# Using validation data above instead of test\n",
        "\n",
        "f1_score(actual_classes, predicted_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxe8Dyi0D_Mb",
        "colab_type": "text"
      },
      "source": [
        "We then plot the training accuracy one last time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xug904PrB8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['accuracy']))),\n",
        "         history.history['accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdY3pTygEGUq",
        "colab_type": "text"
      },
      "source": [
        "We plot the training loss one last time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urygmy1E6Elh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(range(len(history.history['loss']))),\n",
        "         history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD659K7PENp7",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    }
  ]
}