{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T03-06 [00] Regression Quality [Colab] - SOLUTIONS",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1",
        "kvzJqzO0Zxmq"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vnxEkIngTvDE",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9x3myQjxtiaT"
      },
      "source": [
        "# Regression Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jfaowiejr34"
      },
      "source": [
        "When we build a regression model we need some way to measure the quality of the model. In this Colab we will examine a few of the ways that we can measure and graph results of a regression model in order to better understand the quality of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uUgJOOQGT30b"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hRcJ0iUKT6QK"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Extract quantitative measurements of a regression models predictions.\n",
        "* Perform qualitative judgements of a regression models predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GTODJhcyUBU6"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Intermediate Python\n",
        "* Introduction to Pandas\n",
        "* Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ROs7OzD7UEcv"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "30 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9F5K8vDTUHGi"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Attempted exercise, but code does not run |\n",
        "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
        "| 3      | Exercise completed successfully |\n",
        "\n",
        "There are 3 exercises in this Colab so there are 9 points available. The grading scale will be 9 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpMw1wUayDuO",
        "colab_type": "text"
      },
      "source": [
        "## A Toy Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiioKUOUyHne",
        "colab_type": "text"
      },
      "source": [
        "We are about to talk about regression quality, but we haven't actually created a regression model yet!\n",
        "\n",
        "Don't worry, this is actually a good thing. We will take this opportunity to reinforce our [NumPy](http://www.numpy.org/) skills by creating some artificial datasets. This will also allow us to focus on the details of grading model quality without having to also spend mental cycles on learning new regression model toolkits.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKHnU1b6zQ_H",
        "colab_type": "text"
      },
      "source": [
        "Start by importing [NumPy](http://numpy.org) and setting a random seed so that we get reproducible results.\n",
        " \n",
        "Remember: **Do not set a random seed in non-toy code!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDe_GHXFz08q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0xFACADE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgR1_rQNzP5M",
        "colab_type": "text"
      },
      "source": [
        "Recall from our discussions about linear regressions that we are trying to fit a straight line through a set of data points. The equation for a straight line is:\n",
        "\n",
        "> $y = m*x + b$\n",
        "\n",
        "where `m` is the slope of the line, `b` is the intercept of the line on the y-axis, and `x` is the feature.\n",
        "\n",
        "But at this point we don't even have `x` values!\n",
        "\n",
        "We can use [NumPy's random.uniform](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.uniform.html) function to generate x-values. In this case we'll choose 50 random numbers between 0 and 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1GbL97E0an3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.random.uniform(low=0, high=200, size=50)\n",
        "\n",
        "print(f'min: {np.min(X)}')\n",
        "print(f'max: {np.max(X)}')\n",
        "print(f'mean: {np.mean(X)}')\n",
        "print(f'count: {np.size(X)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUrlpwQw3x8W",
        "colab_type": "text"
      },
      "source": [
        "You should see:\n",
        "\n",
        "  * minimum value near, but not below 0\n",
        "  * max value near, but not above 200\n",
        "  * mean value somewhere near 100\n",
        "  * count value of exactly 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vhj5pXD4wnY",
        "colab_type": "text"
      },
      "source": [
        "So far, the numbers look good, but let's visualize the x-values just to get some idea of the distribution of the values in the range of 0 through 200.\n",
        " \n",
        "We only have one list of values, which isn't too exciting and actually doesn't display well in two-dimensional space, which is what we need for a graph.\n",
        " \n",
        "*How do we plot a one-dimensional list of values in two-dimensional space?*\n",
        " \n",
        "We plot it against itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46h-Zhn5WSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X, X, 'g.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okVippyp8rEj",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we have a straight line of x-values that span from roughly 0 to 200. Let's now create some y-values by defining a linear function with a slope of 4 and an intercept of 10.\n",
        "\n",
        "We'll call the new variable `Y_PRED` since it equates to what our model would predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxxq56Sa827e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SLOPE = 4\n",
        "INTERCEPT = 10\n",
        "\n",
        "Y_PRED = SLOPE * X + INTERCEPT\n",
        "\n",
        "plt.plot(X, Y_PRED, 'b.')\n",
        "plt.plot(X, X, 'g.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwLnVg-k9wlT",
        "colab_type": "text"
      },
      "source": [
        "We still have a straight line of green dots for X and now we also have a line of blue dots for the y-values generated off of X. We know that there is a constant linear relationship between the lines:\n",
        "\n",
        "> $y = 4 * x + 10$\n",
        "\n",
        "The green dots are just our X values plotted against themselves and the blue dots are the y-values that our linear model would have predicted. At this point we can drop the X-to-X plot and just plot X-to-Y with both the Y data points and the regression line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRKNeOxpEU8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_PRED = (SLOPE * X) + INTERCEPT\n",
        "\n",
        "plt.plot(X, Y_PRED, 'b.')\n",
        "plt.plot(X, Y_PRED, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lvGtzEjFljz",
        "colab_type": "text"
      },
      "source": [
        "What a great regression line! If only we could have this perfect of a fit in the real world. Unfortunately this is never the case. There is always some variability.\n",
        " \n",
        "Let's add some variability into our y-values to get a more realistic dataset, but keep our original y-values in order to remember our base regression line.\n",
        " \n",
        "To do this we'll recreate our original y-values and store them in `Y_PRED` and the calculate y-values stored in `Y` with random coefficient multipliers between -200 and 200 for variability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX8YZU4YF632",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_PRED = (SLOPE * X) + INTERCEPT\n",
        "\n",
        "Y = SLOPE * X + np.random.uniform(low=-200, high=200, size=50) + INTERCEPT\n",
        "\n",
        "plt.plot(X, Y, 'b.')\n",
        "plt.plot(X, Y_PRED, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZa4VEpwAIr4",
        "colab_type": "text"
      },
      "source": [
        "That plot looks nice. We have the line that was used to generate the data plotted in red and the randomly displaced data points in blue. The dots, though definitely not close to the line, at least follow the trend in the range of values that we have graphed. This seems like a reasonable linear regression dataset.\n",
        " \n",
        "Remember that we have a few important pieces of data at the moment, some of which would be known to a model beforehand and some not:\n",
        " \n",
        "* X: the x-values that we used to \"train\" the model\n",
        "* Y: the y-values that represent the actual values that correlate to `x`\n",
        "* Y_PRED: the y-values that the model would predict for each x-value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXka6VEAgb88",
        "colab_type": "text"
      },
      "source": [
        "## Coefficient of Determination\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBHq0fVmCnDt",
        "colab_type": "text"
      },
      "source": [
        "The \"Coefficient of Determination\" is 1 minus the ratio of the residual sum of squares over the total sum of squares.\n",
        " \n",
        "A **residual** is a target value minus a predicted value. The residual sum of squares is the summation of the squares of every residual in the prediction set.\n",
        " \n",
        "> $$ SS_{res} = \\sum_{i}(y_{i} - f_{i})^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajpg_LjzXlfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss_res = ((Y - Y_PRED) ** 2).sum(axis=0,  dtype=np.float64)\n",
        "print(ss_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txBMdrddXuLT",
        "colab_type": "text"
      },
      "source": [
        "The total sum of squares is the sum of the squares of the mean value of Y subtracted from each y-value.\n",
        "\n",
        "Let's first determine the mean value of Y:\n",
        "\n",
        "> $$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_{i}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4fgXukDaRc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_mean = np.average(Y, axis=0)\n",
        "print(y_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpUTRCcoanJ4",
        "colab_type": "text"
      },
      "source": [
        "And now we can calculate the total sum of squares:\n",
        "\n",
        "> $$SS_{tot} = \\sum_{i}(y_{i}-\\bar{y})^2$$ [link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ5bBjDjbNur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss_tot = ((Y - y_mean)**2).sum(axis=0, dtype=np.float64)\n",
        "print(ss_tot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVxzNIVAbaDE",
        "colab_type": "text"
      },
      "source": [
        "Given the total sum of squares and the residual sum of squares, we can calculate r-squared:\n",
        "\n",
        ">  $$R^{2} = 1 - \\frac{SS_{res}}{SS_{tot}}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAfSpJGcDff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2 = 1 - (ss_res/ss_tot)\n",
        "print(r2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKdi_0xGe2IV",
        "colab_type": "text"
      },
      "source": [
        "And now we have a quality score!\n",
        " \n",
        "If you just ran the cells in this Colab from top to bottom you probably got a score of `0.8461541953202785`.\n",
        " \n",
        "Is this good? Bad? Other?\n",
        " \n",
        "r-squared score measures how well the actual variance from x-values to y-values is represented in the variance between the x-values and the predicted y-values.\n",
        " \n",
        "Typically this score ranges from 0 to 1, where 0 is bad and 1 is a perfect mapping. However, the score can also be negative... can you guess why?\n",
        " \n",
        "If you could draw a horizontal line through the data points that did a better job than your regression then the r-squared score would be negative. If you see this, try again... your model doesn't work!\n",
        " \n",
        "The >0 through 1 values are more subjective though. The closer to 0 the \"worse\" your model is. The closer to 1 the better typically, but you also don't want to overfit. This is where testing, observation, and domain knowledge come into play.\n",
        " \n",
        "---\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJZnpcHagxCC",
        "colab_type": "text"
      },
      "source": [
        "To reinforce the point we will illustrate a perfectly fitting model and a horribly fitting model.\n",
        " \n",
        "But first we will first learn how to calculate the coefficient of determination easier than all of the NumPy math we did above.\n",
        " \n",
        "It turns out that scikit-learn can calculate r-squared for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpEhA5Njhl9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "print(r2_score(Y, Y_PRED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZTuYycChyVt",
        "colab_type": "text"
      },
      "source": [
        "Knowing that we don't have to manually do all of the math again, let's now see the perfect and a very imperfect case of a regression fitting a dataset.\n",
        "\n",
        "To begin with we'll show a perfect fit. What happens if our predictions and our actuals are identical?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY_YUP5riHt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(r2_score(Y, Y))\n",
        "print(r2_score(Y_PRED, Y_PRED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTVw_ljAiNrx",
        "colab_type": "text"
      },
      "source": [
        "`1.0`... just what we thought! A perfect fit.\n",
        "\n",
        "Now let's see if we can pull r-squared into the negative.\n",
        "\n",
        "In this case we just need to make our predicted data look different than our actuals. To do this we'll negate our predictions and save them into a new variable called `Y_PRED_WTF`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ8k2wTXigmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_PRED_WTF = -Y_PRED\n",
        "plt.plot(X, Y, 'y.')\n",
        "plt.plot(X, Y_PRED_WTF, 'r-')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SSxTRBzkKb7",
        "colab_type": "text"
      },
      "source": [
        "That prediction line looks horrible! Indeed, a horizonal line would perform better in multiple places.\n",
        "\n",
        "Let's check the r-squared score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsRgZmePjk5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(r2_score(Y, Y_PRED_WTF))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H5ilPeOkZNb",
        "colab_type": "text"
      },
      "source": [
        "Negative. A rare site in practice, but an easy signal to read if seen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-i-5MvVkuFa",
        "colab_type": "text"
      },
      "source": [
        "## Predicted vs. Actual Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d9FGT_2kx7T",
        "colab_type": "text"
      },
      "source": [
        "We have now seen a quantitative way to examine our regressions, the coefficient of determination. We know that if we see negative numbers that our model is very broken and if we see numbers approaching 1, the model is probably decent.\n",
        " \n",
        "But what about the in-between?\n",
        " \n",
        "This is where qualitative observations based on expert opinion needs to come into play.\n",
        " \n",
        "There are numerous ways to visualize regression predictions, but one of the most basic is the \"predicted vs. actual\" plot.\n",
        " \n",
        "To create this plot you scatter-plot the actual y-values used to train your model against the predicted y-values generated off the the training features. You then draw a line on the plot from the lowest prediction to the largest.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP-6LYKf9A3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(Y_PRED, Y, 'b.')\n",
        "plt.plot([Y_PRED.min(), Y_PRED.max()], [Y_PRED.min(), Y_PRED.max()], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP4Kv5ei-ard",
        "colab_type": "text"
      },
      "source": [
        "Does this graph look okay? Actually, it does. The data points scatter pretty evenly around the prediction-to-actual line.\n",
        "\n",
        "So what does a bad plot look like? Let's experiment with some."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me3c2Erb_X2O",
        "colab_type": "text"
      },
      "source": [
        "Let's first negate all of our predictions, making them exactly the opposite of what they should be. This creates the exact opposite of a good actual-vs-predicted line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRTjN69E-xim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_BAD = -Y_PRED\n",
        "\n",
        "plt.plot(Y, Y_BAD, 'b.')\n",
        "plt.plot([Y_BAD.min(), Y_BAD.max()], [Y_BAD.min(), Y_BAD.max()], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhhr0S92DOA5",
        "colab_type": "text"
      },
      "source": [
        "In this case we made a very contrived example where the predictions are exactly opposite of what the actual values are. When you see this case, you have a model predicting roughly opposite what it should be predicting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGOGmkemJnCX",
        "colab_type": "text"
      },
      "source": [
        "Let's look at another case where we add a large positive bias to every prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed32rF6x_zMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_BAD = Y_PRED + 200\n",
        "\n",
        "plt.plot(Y, Y_BAD, 'b.')\n",
        "plt.plot([Y_BAD.min(), Y_BAD.max()], [Y_BAD.min(), Y_BAD.max()], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXVkiilyET2d",
        "colab_type": "text"
      },
      "source": [
        "Now we have a situation where there is an obvious bias. All predictions are high, so the model needs to be adjusted to make smaller predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ansCNhhYKNw1",
        "colab_type": "text"
      },
      "source": [
        "There are cases that won't be quite so obvious. In the chart below you can see that the predictions are okay for low values but tend to underpredcit for larger target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK6O49mNJwOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_BAD = Y_PRED - Y_PRED / 4\n",
        "\n",
        "plt.plot(Y, Y_BAD, 'b.')\n",
        "plt.plot([Y_BAD.min(), Y_BAD.max()], [Y_BAD.min(), Y_BAD.max()], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5xH6zg4Kjgn",
        "colab_type": "text"
      },
      "source": [
        "Predicted vs. Actual charts are a useful tool for giving you a visual cue as to how your model is performing across it's range of predicted values. While single measures like r-squared give you an aggregated signal, charts allow you to see if there is a trend or odd spot where your model isn't performing well.\n",
        "\n",
        "Once you have identified problem areas, you can work on retraining your model or take different actions on different ranges of predictions based on your knowledge of how the model performs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkw2D-iaEhmk",
        "colab_type": "text"
      },
      "source": [
        "## Residual Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhvs7DF4Eltq",
        "colab_type": "text"
      },
      "source": [
        "Another helpful visualization is a plot of residuals. As mentioned earlier, residuals are actual minus predicted values.\n",
        " \n",
        "We plot residuals on the y-axis against the predicted values on the x-axis and draw a horizontal line through y=0.\n",
        " \n",
        "Cases where our predictions were too low are above the line. Cases where our predictions were too high fall below the line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xryYLARW2UdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESIDUALS = Y - Y_PRED\n",
        "plt.plot(Y_PRED, RESIDUALS, 'b.')\n",
        "plt.plot([0, Y_PRED.max()], [0, 0], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlWKb7TxPA29",
        "colab_type": "text"
      },
      "source": [
        "In the \"Predicted vs. Actual\" plots above we plotted a case were there was a large positive bias in our predictions. Plotting the same data as a residual plot shows all of the residuals below the zero line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RGaU1vKOxHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESIDUALS = Y - (Y_PRED + 200)\n",
        "\n",
        "plt.plot(Y_PRED, RESIDUALS, 'b.')\n",
        "plt.plot([0, Y_PRED.max()], [0, 0], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BZWwqiPPoZr",
        "colab_type": "text"
      },
      "source": [
        "Again taking from the \"Predicted vs. Actual\" examples, when we reduced our predictions by an amount proportional to the scale of the predictions, we can see the under-prediction trend in the residual chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzcQwgHdPUNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RESIDUALS = Y - (Y_PRED - Y_PRED / 4)\n",
        "\n",
        "plt.plot(Y_PRED, RESIDUALS, 'b.')\n",
        "plt.plot([0, Y_PRED.max()], [0, 0], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrSCeh9kCwCy",
        "colab_type": "text"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlLLhik8CzIq",
        "colab_type": "text"
      },
      "source": [
        "* [Coefficient of Determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
        "* [Interpreting Residual Plots](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#gallery)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xj-D3cpPK-bR"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lVRIsmu7LAO0"
      },
      "source": [
        "The [Interpreting Residual Plots](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#gallery) resource gives examples of patterns in different residual plots and what those patterns might mean about your model.\n",
        " \n",
        "Each exercise below contains code that generates an image. Run the code to view then image and then find the corresponding pattern name in [Interpreting Residual Plots](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#gallery), note the name of the pattern in the answer cell and provide a one or two sentence explanation of what this could signal about your model's predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CcD-4FQALDGS"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqArWSCLFk8"
      },
      "source": [
        "Run the code below to generate an image. Identify the corresponding residual plot pattern and write a sentence or two about what this could signal about the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSDFGtHFWlcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "x = np.linspace(-10.0, 10.0, 100)\n",
        "y = np.linspace(-10.0, 10.0, 100)\n",
        "f = x**2 + y**2 + np.random.uniform(low=-14, high=14, size=100)\n",
        "plt.plot(x, f, 'b.')\n",
        "plt.plot([x.min(), x.max()], [0, 0], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xp2Nb65QLHp2"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzRwd-OSXAwb",
        "colab_type": "text"
      },
      "source": [
        "*Which [plot pattern](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#gallery)? And what might it mean about the model?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rJP8dwizLK_n"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCUi_uJ-XXC7",
        "colab_type": "text"
      },
      "source": [
        "[Nonlinear](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#nonlinear-header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zyiw5EoBLXWw"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jx9dv3DFYAkq",
        "colab": {}
      },
      "source": [
        "# N/A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FmdVEMObLahP"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BgUTg70ULf14"
      },
      "source": [
        "Run the code below to generate an image. Identify the corresponding residual plot pattern and write a sentence or two about what this could signal about the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUaR6zDyXmeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "x = np.linspace(0.0, 10.0, 100)\n",
        "y = np.concatenate([\n",
        "    np.random.uniform(low=-5, high=5, size=90),\n",
        "    np.random.uniform(low=50, high=55, size=10)\n",
        "])\n",
        "plt.plot(x, y, 'b.')\n",
        "plt.plot([x.min(), x.max()], [0, 0], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MjMuMUpmLjpv"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6l1tsCXLyZO"
      },
      "source": [
        "*Which [plot pattern](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#gallery)? And what might it mean about the model?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a5nF6HLY96M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h6YK3ES0LoaC"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pEUr180mLrUv"
      },
      "source": [
        "[Outliers](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#outlier-header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LMlUqEAYLp2K"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XRTez9_lU17J",
        "colab": {}
      },
      "source": [
        "# N/A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTYAV7aXY8Y4",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K62c7ShmY_S4",
        "colab_type": "text"
      },
      "source": [
        "Run the code below to generate an image. Identify the corresponding residual plot pattern and write a sentence or two about what this could signal about the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBZ40HiTZBxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "x = np.concatenate([\n",
        "    np.random.uniform(low=0, high=2, size=90),\n",
        "    np.random.uniform(low=4, high=10, size=10)\n",
        "])\n",
        "y = np.random.uniform(low=-5, high=5, size=100)\n",
        "plt.plot(x, y, 'b.')\n",
        "plt.plot([x.min(), x.max()], [0, 0], 'r-')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Residual')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciCms7duZrtO",
        "colab_type": "text"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OihReV6ZvGb",
        "colab_type": "text"
      },
      "source": [
        "*Which [plot pattern](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#gallery)? And what might it mean about the model?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvzJqzO0Zxmq",
        "colab_type": "text"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu7nOv_RZzns",
        "colab_type": "text"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcAQT6VxZ4Ej",
        "colab_type": "text"
      },
      "source": [
        "[X-axis unbalanced](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/#x-unbalanced-header)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gg5WqQJZ7YP",
        "colab_type": "text"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t51wvIxqZ8yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N/A"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}