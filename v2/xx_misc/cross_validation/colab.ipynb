{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7PLP9Q30PKtv"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f5W9rkuBmBu9"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zIykBQbYXrXA"
      },
      "source": [
        "In past colabs we have practiced dividing our data into testing and training sets in order to evaluate the performance of our models. In some cases, especially when there is limited data available, we can't be too sure that our model isn't overfitting.\n",
        "\n",
        "Cross validation is a [resampling](https://en.wikipedia.org/wiki/Resampling_(statistics)) technique that we use in machine learning to measure the quality of our model while by running multiple iterations of training and testing using different subsets of the data.\n",
        "\n",
        "The most common algorithm used for cross validation in machine learning is k-fold cross validation. This colab will focus primarily on k-fold cross validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSwFn8YlaDL2"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHVHPJhSaEEM"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Understand cross validation and how it is different from simple test/train splits.\n",
        "* Build a synthetic column.\n",
        "* Use k-fold cross validation libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGrUipVEawYy"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Linear Regression with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0bExBYnwa7i2"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "60 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SavoD7IUa-vY"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Attempted exercise, but code does not run |\n",
        "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
        "| 3      | Exercise completed successfully |\n",
        "\n",
        "There are 2 exercises in this Colab so there are 6 points available. The grading scale will be 3 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G8u2lYRWbE37"
      },
      "source": [
        "## Obtain and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "arLJPRv3eYjz"
      },
      "source": [
        "### Obtain the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Vi3O347bIWz"
      },
      "source": [
        "Montgomery County Maryland provides [salary data](https://catalog.data.gov/dataset?tags=salary-and-gender) for government employees by year. For this colab we will use the 2017 dataset.\n",
        "\n",
        "The code box below downloads the dataset and saves it in a file called 'Employee_Salaries_-_2017.csv'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "n87ISSI-35TO"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "url = 'https://data.montgomerycountymd.gov/api/views/2qd6-mr43/rows.csv?accessType=DOWNLOAD'\n",
        "file_name = 'Employee_Salaries_-_2017.csv'\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "if file_name not in os.listdir('./'):\n",
        "  raise Exception(f'{file_name} was not downloaded to the correct directory')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3NJibNoWb3Mo"
      },
      "source": [
        "Once the file is downloaded we can read it into a `DataFrame` and take a peek at the first bit of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ieizllDrgh2Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "salary_data = pd.read_csv(file_name)\n",
        "salary_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dsBw6st2ecgV"
      },
      "source": [
        "### Build a Synthetic Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3T3ixyJ0cTOl"
      },
      "source": [
        "Let's take a look at just the column names and data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bJjriCTbopbz"
      },
      "outputs": [],
      "source": [
        "salary_data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4HOfHX1FciIm"
      },
      "source": [
        "The only numeric columns are related to pay, but there is one other column that looks like it might could be converted to a number and predictive of pay: 'Date First Hired'. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QOFp62zIcyTl"
      },
      "outputs": [],
      "source": [
        "salary_data['Date First Hired'].sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rDMqYgm0c95M"
      },
      "source": [
        "We can convert the dates from a string to a date using Panda's `to_datetime` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uCAW1g-ndCkb"
      },
      "outputs": [],
      "source": [
        "pd.to_datetime(salary_data['Date First Hired']).sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oat00QaUdOBj"
      },
      "source": [
        "It would be useful to convert this data to a numeric variable. Since we know we are working with data from 2017 we can choose some date in 2017 and subtract the first hire date from it creating a 'Tenure' column.\n",
        " \n",
        "Since some employees were likely hired in 2017 we don't want to use the first of the year. For simplicity's sake we will simply subtract the first hired date from January 1st 2018."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5KnqX_v_d1Xu"
      },
      "outputs": [],
      "source": [
        "salary_data['Tenure'] = ((pd.to_datetime('01/01/2018') - pd.to_datetime(salary_data['Date First Hired'])).apply(lambda td: td.days)).astype('int64')\n",
        "salary_data[['Date First Hired', 'Tenure']].sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YatcCzKgf3di"
      },
      "source": [
        "Let's also describe the data and check out the distribution of our new 'Tenure' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DegGkLNhfsPR"
      },
      "outputs": [],
      "source": [
        "salary_data['Tenure'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jjBrAB-FgTIn"
      },
      "source": [
        "We can see that the minimum tenure is 6 days and that the 50th percentile is 4263 days, which is just over 11.5 years. That doesn't seem too crazy for a government job.\n",
        " \n",
        "Check out that max value though! 19086 days, which is just over 52 years.\n",
        " \n",
        "Let's look closer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DnWPUoGrggyq"
      },
      "outputs": [],
      "source": [
        "salary_data[salary_data['Tenure'] == 19086]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KUOaMhL7hOIp"
      },
      "source": [
        "A quick search on the internet brings up [meeting minutes](https://www.montgomerycountymd.gov/HHS-Program/Resources/Files/PHSDocs/COH/June%202016%20approved%20COH%20Minutes--FINAL.pdf) from 2016 where our outlier is being congratulated for 50 years of service to Montgomery County.\n",
        " \n",
        "Our new column seems to be legit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xhblVcZB2ipY"
      },
      "source": [
        "### Visualize the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UbwuVzyM2ln7"
      },
      "source": [
        "Our dataset contains salary data for every government employee. This includes a wide range of job roles, each with their own competitive pay ranges.\n",
        "\n",
        "Let's look at a visualization of salary and tenure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D7Rl9q9c3CBK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(salary_data['Tenure'], salary_data['Current Annual Salary'], 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "abQA-1bR3MkV"
      },
      "source": [
        "### Narrow the Problem Scope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vdeTHiyj3GAz"
      },
      "source": [
        "This data would be impossible to predict reliably using a linear function. Let's explore the data and see what the most common job roles are. We can then just build a model for that job role."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j-0Aq4vx3eBF"
      },
      "outputs": [],
      "source": [
        "salary_data.groupby('Employee Position Title')['Tenure'].count().sort_values(ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DIdajQXL3gLi"
      },
      "source": [
        "'Police Officer III' seems to be the clear winner with 'Firefighter/Rescuer III' and 'Bus Operator' not far behind.\n",
        " \n",
        "We will limit our model to predict the pay of people with 'Police Officer III' roles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DEt74YZu3x7c"
      },
      "outputs": [],
      "source": [
        "police_officers = salary_data[salary_data['Employee Position Title'] == 'Police Officer III']\n",
        "\n",
        "police_officers.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i39TlYbv30gL"
      },
      "source": [
        "And visualizing that data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SmXZNxDh32RU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(police_officers['Tenure'], police_officers['Current Annual Salary'], 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RszwFzgN3-64"
      },
      "source": [
        "This data looks much better and might be a good fit for a linear model. There do seem to be some obvious pay bands and an overall salary cap just over $90,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xOdxRVZv4gs-"
      },
      "source": [
        "Another interesting salary-related datapoint is the actual gross pay that the officer received over the course of the year. Where the salary is promised pay, the gross salary is actual pay including overtime and subtracting days of unpaid leave and days before the officer started work (if the officer started in 2017)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K_XlhVUl4OXh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(police_officers['Tenure'], police_officers['2017 Gross Pay Received'], 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GLLDHI7t5Vdb"
      },
      "source": [
        "Here we can see more pronounced bands, but they aren't pay bands. The bands are groups of officers with the same tenure. Likely this is a class of officers starting at the same time. Also, most people start a new job on Mondays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5z5s-V86Tnq"
      },
      "source": [
        "So which do we want to try to predict? Salary is likely more predictable since gross pay can be affected by an individual's willingness to perform overtime work.\n",
        "\n",
        "A quick look at a correlation matrix indicates that we'd have better luck predicting salary also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3Vu3G9SZ6FgH"
      },
      "outputs": [],
      "source": [
        "police_officers[['Tenure', 'Current Annual Salary', '2017 Gross Pay Received']].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R8QzVgnS8TaD"
      },
      "source": [
        "## k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1nCwZ9OH9HCB"
      },
      "source": [
        "### Create a Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U22EqeuC8WAB"
      },
      "source": [
        "For this lab we are going to use the [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) to find our regression line. Before we do that it is a good idea to scale our feature data using the [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
        "\n",
        "Since we'll be using k-fold cross validation for exploring our model we can make it easier for ourselves to perform the data preprocessing and model fitting by using a `Pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QlODYvMB8uy1"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['regressor', SGDRegressor(random_state=562)],\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-arCV4o4-6O9"
      },
      "source": [
        "### Shuffle the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dZCwsoEA-lHr"
      },
      "source": [
        "We will also want to shuffle our data before sending it into the cross validation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ARx5w57w-qNu"
      },
      "outputs": [],
      "source": [
        "police_officers = police_officers.sample(frac=1.0, random_state=324)\n",
        "police_officers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uo3cNIUl_L1F"
      },
      "source": [
        "### Calculate Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "28vKYwD3-2kj"
      },
      "source": [
        "Now we can calculate our cross validation scores. We'll use the `cross_val_score` function which uses k-Fold cross validation by default.\n",
        "\n",
        "We pass the function:\n",
        "\n",
        "1. Estimator (it will be trained k-times)\n",
        "1. Feature data\n",
        "1. Target data\n",
        "1. The number of folds.\n",
        "\n",
        "In the case below we choose 5 folds, which holds out 20% of our data for testing and trains on 80% of the data. Other common values are 10 folds and even 4 folds. There isn't really a correct answer here as to the number of folds to use. The more folds, the more iterations of training and scoring, so your data size and cost of processing might dictate less folds. Above 10 folds isn't very beneficial because of the chances of your testing data for any given fold being very different from your training data increases, so you might not get an accurate view of your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hYig4u5N_FPm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    police_officers[['Tenure']],\n",
        "    police_officers['Current Annual Salary'],\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BETD4I2yARd3"
      },
      "source": [
        "You can see after scoring the model with 5 folds we get 5 scores. Since we used an [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) the score is a r-squared score. Different models return different scores.\n",
        "\n",
        "We can now take the mean of the scores to get a more balanced view of our model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zuWWW7rpAmCl"
      },
      "outputs": [],
      "source": [
        "scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g4sbs9j4ArdW"
      },
      "source": [
        "### Comparing to Standard Test/Train Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5vuNIwLjAvkU"
      },
      "source": [
        "Let's compare our mean r-squared score to the score that we would have gotten from a standard test/train split of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "srau2d7GA5WF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['regressor', SGDRegressor(random_state=343)],\n",
        "  ]\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    police_officers[['Tenure']], \n",
        "    police_officers['Current Annual Salary'], \n",
        "    test_size=0.2, \n",
        "    random_state=1234\n",
        ")\n",
        "\n",
        "estimator.fit(X_train, y_train)\n",
        "estimator.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O1cbwWpICIZy"
      },
      "source": [
        "In this case, at least when this colab was created, the mean cross validation score was actually higher than the individual test score. This won't always be the case and depending on the random states and number of times that you ran each code cell, might not be true.\n",
        " \n",
        "What does the difference between the cross validation score and hold-out score tell us?\n",
        " \n",
        "If the cross validation score is higher, then it means that our model probably performs better on unknown/new data than we would have thought by simply doing holdout.\n",
        " \n",
        "If the cross validation score is lower than our model is likely to just be too well adjusted to the single set of holdout test data.\n",
        " \n",
        "The cross validation score gives us a better idea of how our model would actually perform that the single hold-out score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "976w_h81Cv7W"
      },
      "source": [
        "### Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fG_LZBdhC0gZ"
      },
      "source": [
        "We now have a mean cross validation score and have some idea of how our model will perform, so what's next?\n",
        " \n",
        "There are a few options:\n",
        " \n",
        "* Train the model on the entire dataset.\n",
        "* Train the model on a subset of the dataset.\n",
        " \n",
        "The first option isn't too bad, but it does still expose you to a slight risk that your model will end up overfitting. Since you are training with all of the data there is no way to go back and do one last check to ensure that your model is sane.\n",
        " \n",
        "The second option is preferred. In this case, you still do a train-test split first. Then you perform cross validation on just the training data. Once you get the cross validation score you then train a new model on just the training data and do one final sanity check using the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kCOTnR4DEaTR"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['regressor', SGDRegressor(random_state=343)],\n",
        "  ]\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    police_officers[['Tenure']], \n",
        "    police_officers['Current Annual Salary'], \n",
        "    test_size=0.2, \n",
        "    random_state=1234\n",
        ")\n",
        "\n",
        "scores = cross_val_score(estimator, X_train, y_train, cv=5)\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['regressor', SGDRegressor(random_state=343)],\n",
        "  ]\n",
        ")\n",
        "\n",
        "estimator.fit(X_train, y_train)\n",
        "score = estimator.score(X_test, y_test)\n",
        "\n",
        "print(f'cross validation score (min): {scores.min()}')\n",
        "print(f'cross validation score: {scores.mean()}')\n",
        "print(f'final score {score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sql9qeCFCKq"
      },
      "source": [
        "In this case again the cross validation score differs quite a bit from our cross validation score. This hints that we still might be overfitting to our training data and not generalizing well despite our cross validation score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5WFLU7hWbO8_"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* [scikit-learn Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Swt2fxm-fG_B"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWq38ASlb2aY"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWq38ASlb2aX"
      },
      "source": [
        "`cross_val_score` isn't limited to k-fold validation. It can perform many other splits on the data.\n",
        " \n",
        "Use the [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit) in `cross_val_score` instead of k-fold.\n",
        " \n",
        "Set the parameters to:\n",
        " \n",
        "* 5 splits\n",
        "* 30% test size\n",
        "* 56789 random state\n",
        " \n",
        "Calculate the mean of the returned scores and store the mean in a variable called `mean_score`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYZEXNK1VDIJ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TI_WxOyjcfNu"
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AKb-7oqrcfox"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['regressor', SGDRegressor(random_state=343)],\n",
        "  ]\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    police_officers[['Tenure']], \n",
        "    police_officers['Current Annual Salary'], \n",
        "    test_size=0.2, \n",
        "    random_state=1234\n",
        ")\n",
        "\n",
        "scores = cross_val_score(estimator, X_train, y_train, cv=ShuffleSplit(n_splits=5, test_size=0.3, random_state=56789))\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['regressor', SGDRegressor(random_state=343)],\n",
        "  ]\n",
        ")\n",
        "\n",
        "estimator.fit(X_train, y_train)\n",
        "score = estimator.score(X_test, y_test)\n",
        "\n",
        "print(f'cross validation score (min): {scores.min()}')\n",
        "print(f'cross validation score: {scores.mean()}')\n",
        "print(f'final score {score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5EndkJMJVKjw"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SgzIrUK1dFdQ"
      },
      "outputs": [],
      "source": [
        "# If the solution can be auto-graded, perform the autograding here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gX7pcRI9zcJF"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FCBbOxDwzfx1"
      },
      "source": [
        "In classification problems we may have unbalanced classes and want an even distribution of those classes in our training and testing data. This is called *stratification* and for classification problems scikit-learn provides the [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) splitter. This balances our target data across folds.\n",
        "\n",
        "Using the [digits dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) create an [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) and run stratified cross validation over the digit targets.\n",
        "\n",
        "Cross validate over 5 folds. Save the mean validation score in a variable called `mean_score`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NC5SEjRGzsY-"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_xv0Nal-zuBB"
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zdZpsqEGzvpX"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X9yn8kpNzwvH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jgfNqqYpzy55"
      },
      "outputs": [],
      "source": [
        "# TODO(joshmcadams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GqzZqaA6z0Pe"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xQ_fS839z2ci"
      },
      "outputs": [],
      "source": [
        "# TODO(joshmcadams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW7nvc3IYL-w"
      },
      "source": [
        "## Exercise 3: Challenge (Ungraded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9tQFydIzYPYf"
      },
      "source": [
        "There are times when we have insights about our data that we can feed our model. In some cases we can are aware of tranches in the data that have different characteristics and we'd like those characteristics reflected in our testing and training data.\n",
        " \n",
        "In classification problems we may have unbalanced classes and want an even distribution of those classes in our training and testing data. This is called *stratification* and for classification problems scikit-learn provides the [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) splitter. This balances our target data across folds.\n",
        " \n",
        "However, there are other times when we need to balance our feature data across folds. Thinking about the salary data we have dealt with in this colab, the [gender pay gap](https://en.wikipedia.org/wiki/Gender_pay_gap) comes to mind.\n",
        " \n",
        "Let's see if we can find any evidence of a gap. First let's see the distribution of female and male officers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6N0H1j_-ZOUX"
      },
      "outputs": [],
      "source": [
        "police_officers.groupby(by='Gender')['Gender'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5cpsOB4-ZTWZ"
      },
      "source": [
        "We have about 26% females.\n",
        "\n",
        "Now we can calculate an average salary by years tenure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4iEXPEe7Zcqp"
      },
      "outputs": [],
      "source": [
        "max_years = int(police_officers['Tenure'].max() / 365) + 1\n",
        "\n",
        "bins = list(range(0, 365*max_years+1, 365))\n",
        "\n",
        "labels = list(range(0, max_years))\n",
        "\n",
        "police_officers['Tenure Years'] = pd.cut(police_officers['Tenure'], bins=bins, labels=labels)\n",
        "\n",
        "police_officers.sample(10)[['Tenure', 'Tenure Years']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QHhcZW2SZguM"
      },
      "source": [
        "And finally, we can see on average if there is a gap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DU06MU6nZjDD"
      },
      "outputs": [],
      "source": [
        "females = police_officers[police_officers['Gender'] == 'F'].groupby(by='Tenure Years')['Current Annual Salary'].mean()\n",
        "males = police_officers[police_officers['Gender'] == 'M'].groupby(by='Tenure Years')['Current Annual Salary'].mean()\n",
        "(females-males).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dKcxDyN1ZkB6"
      },
      "source": [
        "In this case we see that there is over a $1000 gap in average salary based on years tenure.\n",
        " \n",
        "If we want this reflected in our model we need to split the data in each of our folds. Unfortunately, this isn't quite as easy as stratifying target data.\n",
        " \n",
        "There are a few approaches. One is to pre-split the data and use the [PredefinedSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit) class to identify test folds per iteration of cross validation.\n",
        " \n",
        "Another is to write a custom [CV Splitter](https://scikit-learn.org/stable/glossary.html#term-cv-splitter) and implement `split` and `get_n_splits`.\n",
        " \n",
        "In this challenge you are tasked with creating a 5-split CV Splitter or PredefinedSplit that keeps the feature data roughly 3:1 male:female."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P1Hhvstmbntb"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HocfVWZVbph6"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Z6DcXjSbrn_"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FEypVEsYbtXn"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LROu3HhGbv2p"
      },
      "outputs": [],
      "source": [
        "# TODO(joshmcadams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v70dVPbZbxEq"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mZZgMOLjbyg7"
      },
      "outputs": [],
      "source": [
        "# TODO(joshmcadams)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "zdZpsqEGzvpX",
        "6Z6DcXjSbrn_"
      ],
      "name": "Cross Validation",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
