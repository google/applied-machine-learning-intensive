{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forests",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oXbDqPstu1RM",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yLFFlvePlEsJ"
      },
      "source": [
        "# Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Qm3o8i5lnAH"
      },
      "source": [
        "Random forests are a simple yet powerful machine learning tool based on decision trees. Random forests are easy to understand, yet they touch upon many advanced machine learning concepts such as ensemble learning and bagging. These models can be used for both classification and regression. Also, they are not sensitive to unscaled data.\n",
        "\n",
        "In this unit we will learn about random forests and apply them to machine learning problems. We will touch on ensemble learning techniques and work with random forest hyperparameters to tune models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qlxCUdTql0aW"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Let's start by loading some data. We'll use the familiar iris dataset from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oyP6DVIEjQZL",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_bunch = load_iris()\n",
        "\n",
        "feature_names = iris_bunch.feature_names\n",
        "target_name = 'species'\n",
        "\n",
        "iris_df = pd.DataFrame(\n",
        "    iris_bunch.data,\n",
        "    columns=feature_names\n",
        ")\n",
        "\n",
        "iris_df[target_name] = iris_bunch.target\n",
        "\n",
        "iris_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E_ZO5q4xmOMU"
      },
      "source": [
        "## Create a Decision Tree\n",
        "\n",
        "Now that we have the data loaded, we can create a decision tree. Remember that if this were a real application we'd keep some data to the side for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PjkabO7nkCjt",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(\n",
        "    iris_df[feature_names],\n",
        "    iris_df[target_name]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K24b3sUdmj17"
      },
      "source": [
        "## Visualize the Tree\n",
        "\n",
        "We now have a decision tree and can use it to make predictions. But before we do that, let's take a look at the tree itself.\n",
        "\n",
        "To do this we create a `StringIO` object that we can export dot-data to. The dot data is a graph description language that what we can plot with Python graphing utilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xmPNDQvKkeOd",
        "colab": {}
      },
      "source": [
        "import pydotplus\n",
        "\n",
        "from IPython.display import Image  \n",
        "from sklearn.externals.six import StringIO  \n",
        "\n",
        "dot_data = StringIO()  \n",
        "\n",
        "tree.export_graphviz(\n",
        "    dt,\n",
        "    out_file=dot_data,  \n",
        "    feature_names=feature_names\n",
        ")  \n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "\n",
        "Image(graph.create_png())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f2ipXFP7n8Xg"
      },
      "source": [
        "That tree looks pretty complex. Many branches in the tree is a sign that we may have overfit the model. Let's create the tree again, only this time we'll limit the depth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WA0lUiePoIuZ",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "dt = tree.DecisionTreeClassifier(max_depth=2)\n",
        "\n",
        "dt.fit(\n",
        "    iris_df[feature_names],\n",
        "    iris_df[target_name]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LOU_tzOyoO6A"
      },
      "source": [
        "And plot to see the branching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plW0crKvoSY6",
        "colab": {}
      },
      "source": [
        "import pydotplus\n",
        "\n",
        "from IPython.display import Image  \n",
        "from sklearn.externals.six import StringIO  \n",
        "\n",
        "dot_data = StringIO()  \n",
        "\n",
        "tree.export_graphviz(\n",
        "    dt,\n",
        "    out_file=dot_data,  \n",
        "    feature_names=feature_names\n",
        ")  \n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "\n",
        "Image(graph.create_png())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67yJDrz9oUo6"
      },
      "source": [
        "This tree is less likely to be overfitting, since we forced it to have a depth of 2. Holding out a test sample and performing validation would be a good way to check."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_2J1CZ4uohf2"
      },
      "source": [
        "## Create a Random Forest\n",
        "\n",
        "Another way to help prevent overfitting and to create a better overall model is to use a random forest. You can think of a random forest as an average of a number of decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZH9xJB4ikyfv",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=10, max_depth=5)\n",
        "rf.fit(\n",
        "    iris_df[feature_names],\n",
        "    iris_df[target_name]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PIoGwH2Lp2F4"
      },
      "source": [
        "You can look at different trees in the random forest to see how their decision branching differs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XI_DkBXSpKDl",
        "colab": {}
      },
      "source": [
        "import pydotplus\n",
        "\n",
        "from IPython.display import Image  \n",
        "from sklearn.externals.six import StringIO  \n",
        "\n",
        "dot_data = StringIO()  \n",
        "\n",
        "tree_to_view = 5\n",
        "\n",
        "tree.export_graphviz(\n",
        "    rf.estimators_[tree_to_view],\n",
        "    out_file=dot_data,  \n",
        "    feature_names=feature_names\n",
        ")  \n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "\n",
        "Image(graph.create_png())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i_xl-Et8qjTA"
      },
      "source": [
        "## Make Predictions\n",
        "\n",
        "And now we can make predictions, either with our decision tree or our random forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ll4flhAWqA4W",
        "colab": {}
      },
      "source": [
        "print(dt.predict([iris_df.iloc[121][feature_names]]))\n",
        "print(rf.predict([iris_df.iloc[121][feature_names]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xH5baOS2q0up"
      },
      "source": [
        "# Exercises\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FLf1S7Hirvyy"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2lToTdAbJA-M"
      },
      "source": [
        "scikit-learn also has a [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) class that can be used to make regression predictions using decision trees. Download data about [suicide rates around the world](https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016) and build a model to predict those rates.\n",
        "\n",
        "You'll needed to:\n",
        "\n",
        "*   [Download](https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016) the data\n",
        "*   Load the data in Colab\n",
        "*   Convert the string features into numbers (decision trees like to work in numbers)\n",
        "*   Shuffle the data and split off some for testing\n",
        "*   Train a model using the training data\n",
        "*   Visualize the tree\n",
        "*   Test the model\n",
        "*   Find the RMSE\n",
        "\n",
        "If you have time, try adjusting the depth and other parameters of the tree. Also try replacing the decision tree with a [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and see what effect that has on your RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NlOyoIK8r6kc"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNdrDofHr_XQ",
        "colab": {}
      },
      "source": [
        "# Your solution goes here."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "leYC_-Q1sB07",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Qeh4l9pJEPs"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWBF4HE_JFlU",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}