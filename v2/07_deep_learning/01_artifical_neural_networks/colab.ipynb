{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WIP Deep Neural Networks in Tensorflow",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "KdK6a5-KL6GE",
        "exercise-9-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdK6a5-KL6GE",
        "colab_type": "text"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC70yXqNKJjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX8dvKugMBst",
        "colab_type": "text"
      },
      "source": [
        "# Deep Neural Networks in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQJaGKZVMWhr",
        "colab_type": "text"
      },
      "source": [
        "In this lesson, we will train a deep neural network to interpret sign language from images of hands forming sign language shapes.\n",
        "\n",
        "The [dataset](https://www.kaggle.com/datamunge/sign-language-mnist) contains images of sign language symbols. The 'j' and 'z' are not included in the dataset since these letters require not just a hand form, but also a motion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y15pYY9p8uGD",
        "colab_type": "text"
      },
      "source": [
        "## Acquire the Data\n",
        "\n",
        "Load the zipped sign language folder into Colab. The file should be named `sign-language-mnist.zip`.\n",
        "\n",
        "After the file is uploaded, you can unzip the file, as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIX2s_XTMEn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('sign-language-mnist.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYCvlOIS84FJ",
        "colab_type": "text"
      },
      "source": [
        "The unzipped data contains many different files. There is an overview image of American Sign Language (ASL), a few example images, and two CSV files. The dataset is already split into testing and training data.\n",
        "\n",
        "## Load and Examine the Training Data\n",
        "\n",
        "Let's load the data and describe it. As we can see there are 27,455 rows of data. Each row starts with a label signifying the letter in the image, and 784 pixels that contain the data for a 28x28 image.\n",
        "\n",
        "The label contains values 0.0 through 24.0 and the pixels contain data between 0.0 and 255.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJAEVNF4Maij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('sign_mnist_train.csv')\n",
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caoyLBoy-Ae3",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the distribution of the letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PvhLL_C9xCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.groupby('label')['label'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98tD50QQ-HeX",
        "colab_type": "text"
      },
      "source": [
        "We can see that letter 9 ('j') and letter 25 ('z') are missing, as expected. There seems to be a relatively even number of training samples for each letter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK0-35fj-avZ",
        "colab_type": "text"
      },
      "source": [
        "Just to get an idea of the images that we are working with, let's take a look at a sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw2UgbAEXYts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_to_view = 100\n",
        "\n",
        "plt.imshow(\n",
        "  train_df.iloc[image_to_view][train_df.columns.values[1:]].values.reshape(28, 28),\n",
        "  cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viCOocFR-ZE-",
        "colab_type": "text"
      },
      "source": [
        "## Load and Examine the Test Data\n",
        "\n",
        "We can see that there are 7,172 test records, which is roughly a 20% sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqpafaX69WA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('sign_mnist_test.csv')\n",
        "test_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMDRS_m5BS9X",
        "colab_type": "text"
      },
      "source": [
        "Let's see the distribution of the labels in the test data. The test labels are also pretty evenly distributed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQHcuRxqM7rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.groupby('label')['label'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx30ZwzuCNx-",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "Since our pixel values range from 0 through 255, their values might not work well in a neural network. It is best to scale down the data if possible. For this pixel data scaling is as easy as dividing by 255. We should also convert our label to an integer value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dod09xZEWZ1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[train_df.columns.values[0]] = train_df[train_df.columns.values[0]].astype(int)\n",
        "train_df[train_df.columns.values[1:]] = train_df[train_df.columns.values[1:]]/255.0\n",
        "train_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N9W3rSJCeoA",
        "colab_type": "text"
      },
      "source": [
        "We need to scale the test data too, and convert it to the right type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAUeQr9gWwkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df[test_df.columns.values[0]] = test_df[test_df.columns.values[0]].astype(int)\n",
        "test_df[test_df.columns.values[1:]] = test_df[test_df.columns.values[1:]]/255.0\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxNjoIQNCt0N",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train the Model\n",
        "\n",
        "We now have some data ready to train and test our model. Let's begin by creating feature columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW-fY1fXOFkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.feature_column import numeric_column\n",
        "\n",
        "pixel_features = []\n",
        "\n",
        "for column_name in train_df.columns[1:]:\n",
        "  pixel_features.append(numeric_column(column_name))\n",
        "\n",
        "len(pixel_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKPyZSv-GWvA",
        "colab_type": "text"
      },
      "source": [
        "Creating a deep neural network classifier is as simple as creating an instance of a `DNNClassifier` class, declaring the number of classes, and choosing the number of hidden units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTyqhoaqNKDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.estimator import DNNClassifier\n",
        "\n",
        "classifier = DNNClassifier(feature_columns=pixel_features,\n",
        "                           hidden_units=[392, 196], n_classes=26)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR5gvu1KDTQw",
        "colab_type": "text"
      },
      "source": [
        "We can now create an input function to feed the data to the model for training. The input function will create a dataset containing the feature and label columns. We'll shuffle the dataset, process it in batches, and repeat it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "twNUGFQBQu2G",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "def training_input():\n",
        "  features = {}\n",
        "  for i in range(1, len(pixel_features)+1):\n",
        "    column_name = 'pixel'+str(i)\n",
        "    features[column_name] = train_df[column_name]\n",
        " \n",
        "  labels = train_df['label']\n",
        "\n",
        "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "classifier.train(training_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enk4WdmCDv63",
        "colab_type": "text"
      },
      "source": [
        "## Test the Model\n",
        "\n",
        "We can now create an input function to feed our testing data into the model to make predictions. We'll use the model to make predictions and save them in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJiUNn4fRS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing_input():\n",
        "  features = {}\n",
        "  for i in range(1, len(pixel_features) + 1):\n",
        "    column_name = 'pixel' + str(i)\n",
        "    features[column_name] = test_df[column_name]\n",
        "  return Dataset.from_tensor_slices((features)).batch(1)\n",
        "\n",
        "predictions = list(classifier.predict(testing_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLROG-_GEDFC",
        "colab_type": "text"
      },
      "source": [
        "We can now take a look at one of the predictions to see what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag7dp0tKEBSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7YTLR0uEv1j",
        "colab_type": "text"
      },
      "source": [
        "We see the predicted class, as well as the logits and probabilities for the class.\n",
        "\n",
        "Let's look at the actual label for our first bit of test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r8AndxaFPmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.iloc[0]['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz2ItpkAFVtl",
        "colab_type": "text"
      },
      "source": [
        "We can also see if the image looks like the symbol we predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6PHrKWEFfOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_to_view = 0\n",
        "\n",
        "plt.imshow(\n",
        "  test_df.iloc[image_to_view][test_df.columns.values[1:]].values.reshape(28, 28),\n",
        "  cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dGW5wLGFrR1",
        "colab_type": "text"
      },
      "source": [
        "We should now extract all of the class IDs from our predictions and calculate the F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9hfI7ZmD_AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = [p['class_ids'][0] for p in predictions]\n",
        "predicted_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEtG03pNHkHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(test_df['label'], predicted_classes, average='micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc_rUZ3WG5nU",
        "colab_type": "text"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKPpxFZU7LqH",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9YNTDgIyTs2",
        "colab_type": "text"
      },
      "source": [
        "The F1 score for this model is pretty poor. Check out the [documentation for the DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) and see what parameters you can change.\n",
        "\n",
        "Experiment with different numbers and widths of hidden layers. Consider trying different optimizers and activation functions.\n",
        "\n",
        "Record the parameters that you set and your F1 score for those parameters below. Try to get an F1 above 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QK1tz626LjZU"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LThfFHrSI9cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Run 1\n",
        "# Batch Size: 100\n",
        "# Data Set Repeats: 5\n",
        "# Layers: [392, 196]\n",
        "# Activation Function: relu\n",
        "# Loss Reduction: losses.Reduction.SUM\n",
        "# Optimizer: Adagrad\n",
        "# F1 Score: ???\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Run 2\n",
        "# Batch Size: \n",
        "# Data Set Repeats: \n",
        "# Layers: []\n",
        "# Activation Function: \n",
        "# Loss Reduction: \n",
        "# Optimizer: \n",
        "# F1 Score: \n",
        "\n",
        "# ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-9-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-9-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "thpPZba4CCtP",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}