{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification with Keras",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pDv-M1JQH0nc",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CVmV0M74xwm7"
      },
      "source": [
        "# Image Classification with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sdfkasjfskjf"
      },
      "source": [
        "Another common Machine Learning task is [classification](https://en.wikipedia.org/wiki/Statistical_classification) where one tries to categorize items into buckets.  In this lab, we will specifically explore classification as an instance of [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning).  Out of scope for this lab is unsupervised learning methods, like clustering, etc.\n",
        "\n",
        "Recently you learned about Linear Regression model, and used [Scikit Learn](https://scikit-learn.org/stable/) and [TensorFlow](https://www.tensorflow.org) as framework to build and train machine learning models.  We will now introduce you to [tf.keras](https://www.tensorflow.org/guide/keras) which is a high-level API to build and train models in TensorFlow.\n",
        "\n",
        "<img height=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg\" align=\"left\" hspace=\"10px\">\n",
        "\n",
        "This lab is developed based on a [tutorial](https://www.tensorflow.org/tutorials/keras/basic_classification) from [TensorFlow.org](http://www.tensorflow.org)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "overview"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rY7emKinFRCr"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "  * Review the tf.keras APIs\n",
        "  * How to load a dataset containing images and associated labels\n",
        "  * Use Python module(s) to manipulate images\n",
        "  * Configure, train, validate, and test a neural network model for supervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VZe4Xj9tyQRD"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Introduction to Neural Networks\n",
        "* Artificial Neural Networks\n",
        "* Image Manipulation with Python\n",
        "* Introduction to Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "duration"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "90 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X5aROOaCU-Gd"
      },
      "source": [
        "## Problem Framing\n",
        "\n",
        "Image Classification is a process of identifying to which of a set of categories a new image belongs.  The identification task can be accomplished using either supervised or unsupervised machine learning techniques.\n",
        "\n",
        "Questions we should ask ourselves might include:\n",
        "\n",
        " * How many training images will be needed to produce reasonably good model?\n",
        " * Will image size or resolution impact model quality?\n",
        " * What metrics are we using to define success and what are the acceptable values?\n",
        " * Is there a non-ML way to solve this problem?\n",
        " * What are some of the limitations of this model?\n",
        " * What variability in an image that might lead to incorrect prediction by the model?\n",
        " * Which approach - supervised or unsupervised learning method should be used?\n",
        " \n",
        "The list of questions is boundless. Eventually you'll need to move on, but understanding the problem and the solution space is vital.\n",
        "\n",
        "---\n",
        "\n",
        "For this problem we'll further define the problem by saying:\n",
        "\n",
        "\n",
        "> Since the images come with associated labels, thus we will focus on a supervised learning exercise.  We have less than 100,000 low resolution images that will be used as training data.  We would like to use the trained model to predict labels for new set of images.  Given the short amount of training time, we'll accept an average accuracy on the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "## Data\n",
        "\n",
        "The dataset we'll use for this Colab is the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories.  Fashion MNIST is an alternative to the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc) in an identical format to the articles of clothing we'll use here.\n",
        "\n",
        "The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "As this is a supervised machine learning exercise, besides the images we will also have labels associated with each image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "Now that we have a rough understanding of the data that we are going to use in our model, let's load it into this Colab.  The Fashion MNIST dataset is conveniently available from [Keras Datasets repository](https://keras.io/datasets/) along with a utility function for downloading and loading the data into Numpy arrays.\n",
        "\n",
        "__Note:__ Working with other dataset may require you to build your own or use the available tools to download the data and load it to the appropriate data structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download datasets and upload them to Numpy arrays using the readily available\n",
        "# load_data() utility function\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j5gG9S5Wb6cM"
      },
      "source": [
        "Reading the output of load_data(), the Fashion MNIST dataset consists of 4 data files which belong to 2 datasets:\n",
        "\n",
        "  * __Training dataset__ which consists of 60,000 images and labels to be used for model evaluation\n",
        "  * __Test dataset__ which consists of 10,000 images and labels to be used for model evaluation\n",
        "  \n",
        "Do you recall the reason for splitting a dataset into separate training and test datasets?  Having a separate training dataset allows us to independently evaluate the quality of the model.\n",
        "\n",
        "---\n",
        "\n",
        "Great!  At this point, you have 2 NumPy arrays for each of the training and test datasets, and they named as following:\n",
        "\n",
        "  * `train_images` and `train_labels`\n",
        "  * `test_images` and `test_labels`\n",
        "  \n",
        "Let's take a closer look at the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "### Examine the data\n",
        "\n",
        "You should always look at your data and statistics about that data before you begin modelling it.  Since the data is stored in NumPy arrays, let's start by examining the shape of the arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "zW5k_xz1CaWX",
        "colab": {}
      },
      "source": [
        "# Get the dimension of the data in the NumPy arrays\n",
        "\n",
        "print('Training images:', train_images.shape)\n",
        "print('Training labels:', train_labels.shape)\n",
        "print('Test images:', test_images.shape)\n",
        "print('Test labels:', test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgPxBAdY1uX-"
      },
      "source": [
        "As expected, the training set has 60,000 data points and the test set has 10,000 data points.  And as you can see from the output above, the images arrays are 3d arrays, while the labels arrays are 1d arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Doat5-gY3rPw"
      },
      "source": [
        "We know that each image contains 28 by 28 pixels which is represented in 28x28 Numpy array, with pixel values ranging between 0 and 255.  Let's examine a sample of the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "H1ElPRCNQTTH",
        "colab": {}
      },
      "source": [
        "# Show data for the first image in the training dataset\n",
        "\n",
        "train_images[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQ5bD98-5Cbd"
      },
      "source": [
        "Those pixel values represent an image.  Let's plot the image to see what the image looks like.  We will use matplotlib which you have used in previous Colabs.  What you'll see is 28x28 pixel image and a legend bar on the right of the image with how each pixel will look like for each of the 0 to 255 values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i91acaJB5aZV",
        "colab": {}
      },
      "source": [
        "# Plot the first image from training dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(train_images[0])\n",
        "\n",
        "# Plot the colorbar legend\n",
        "plt.colorbar()\n",
        "\n",
        "# Do not plot grid lines\n",
        "plt.grid(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Now, let's examine the image labels.  The labels are an array of integers, ranging from 0 to 9.  Each integer value corresponds to the __class of clothing__ the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td> \n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label.\n",
        "\n",
        "---\n",
        "\n",
        "Let's take a quick look at what a training label may look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "XKnCTHz4CaWg",
        "colab": {}
      },
      "source": [
        "# Show the first 25 training labels\n",
        "\n",
        "train_labels[:25]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ix6oro_8iid"
      },
      "source": [
        "Did you learn any insight from peeking at the actual data?  Can you tell what the first image of the training data represents?\n",
        "\n",
        "Well, the image is a low resolution one and hard to see it clearly.  If you guess it's some type of a boot then you're correct as the first label of the training data is `9` which mapped an `Ankle boot`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "### Preparing the data\n",
        "\n",
        "A considerable amount of time is spent working with the dataset when creating a machine learning solution. In this case, we have looked at the data and it actually seems to be relatively clean.\n",
        "\n",
        "Before using it, we'll do a couple of minor steps:\n",
        "\n",
        " 1.   Scale the pixel values from 0 to 255 to a range from 0 to 1\n",
        " 2.   Since the class names are not included with the dataset, we'll create a mapping array to use later when plotting the images.\n",
        " \n",
        "__Note:__ It's important that the __training set__ and the __testing set__ are preprocessed in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "bW5WzIPlCaWv",
        "colab": {}
      },
      "source": [
        "# Scale the image pixel values from a range of 0 to 255 to a range of 0 to 1\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "IjnLH5S2CaWx",
        "colab": {}
      },
      "source": [
        "# Create an array to hold the clothing class names\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "That's the extent of the data preparation needed as the dataset is fairly clean and the dataset provider has taken great care to ensure that all the images have a uniform size, and has an associated label.  If you gather your own images as dataset, you'll need to ensure the consistency of the images.\n",
        "\n",
        "Let's plot the first 25 images from the training set and display the class name below each image. Verify that the data is in the correct format and we're ready to build and train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "oZTImqg_CaW1",
        "colab": {}
      },
      "source": [
        "# Plot the first 25 images and associated labels from the training dataset\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(25):\n",
        "  \n",
        "    # Set up 5x5 grid and plot sequentially from index 1 to 25\n",
        "    plt.subplot(5,5,i+1)\n",
        "    \n",
        "    # Do not plot x and y axis and their associated tick marks\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    # Do not plot grid lines\n",
        "    plt.grid(False)\n",
        "    \n",
        "    # Plot the image\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    \n",
        "    # Plot the label of the image on x axis\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "Building the neural network model requires configuring the layers of the model, followed by compiling the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Configure the Model\n",
        "\n",
        "The basic building block of a neural network is the *layer*. Layers extract representations from the data fed into them. And, hopefully, these representations are more meaningful for the problem at hand.\n",
        "\n",
        "Most of deep learning consists of chaining together simple layers. Most layers, like `tf.keras.layers.Dense`, have parameters that are learned during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "9ODch-OFCaW4",
        "colab": {}
      },
      "source": [
        "# Define the model by specifying a neural network layers\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    # Layer 1\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    \n",
        "    # Layer 2\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    \n",
        "    # Layer 3\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e7dr4SzLULr6"
      },
      "source": [
        "Let's deconstruct the model to understand the neural network.  The model is made up from a sequence of 3 layers:\n",
        "\n",
        " * The first layer in this network, `tf.keras.layers.Flatten`, transforms the format of the images from a 2d-array (of 28 by 28 pixels), to a 1d-array of 28 * 28 = 784 pixels. Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\n",
        " \n",
        " * After the pixels are flattened, the network consists of a sequence of two `tf.keras.layers.Dense` layers. These are densely-connected, or fully-connected, neural layers.\n",
        " \n",
        "  * The first `Dense` layer has 128 nodes (or neurons).\n",
        "  * The second (and last) layer is a 10-node *softmax* layer—this returns an array of 10 probability scores that sum to 1. Each node in this last layer contains a score that indicates the probability that the current image belongs to one of the 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "### Compile the Model\n",
        "\n",
        "Before the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n",
        "\n",
        "* *Loss function* —This measures how well the model is  doing during training. We want to minimize this function to \"steer\" the model in the right direction. A large loss would indicate the model is performing poorly in classification tasks, meaning it is not matching input images to the correct class names (it might classify a boot as a coat for example).\n",
        "* *Optimizer* —This is how the model is updated based on the data it sees and its loss function.\n",
        "* *Metrics* —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "# Set model's settings, including loss function, optimizer, and metrics\n",
        "\n",
        "model.compile(\n",
        "    \n",
        "    # Specify loss function\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    \n",
        "    # Specify optimizer\n",
        "    optimizer=tf.train.AdamOptimizer(),\n",
        "    \n",
        "    # Specify metrics\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        "1. Feed the training data to the model—in this example, the `train_images` and `train_labels` arrays.\n",
        "2. The model learns to associate images and labels.\n",
        "3. We ask the model to make predictions about a test set—in this example, the `test_images` array. We verify that the predictions match the labels from the `test_labels` array. \n",
        "\n",
        "To start training,  call the `model.fit` method—the model is \"fit\" to the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "xvwvpA64CaW_",
        "colab": {}
      },
      "source": [
        "# Start model training\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.88 (or 88%) on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "Model is trained, let's graph how the training accuracy and loss improved as the training progressed.  We can do that because the `model.fit()`` returns a `History` object that contains the information.  Use the following code to create charts of the data from the `History` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XBiwqqWlNXzY",
        "colab": {}
      },
      "source": [
        "# Set the overall dimension of the chart area\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "\n",
        "# Set plot to go to first grid of a 1x2 grid\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "\n",
        "# Plot training set accuracy values for each training iteration\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.title('Training Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy'], loc='best')\n",
        "\n",
        "# Set subplot to go to second grid of a 1x2 grid\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "\n",
        "# Plot training set loss values for each training iteration\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss'], loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qXPCKkb3egUx"
      },
      "source": [
        "What questions come to mind as you examine the charts above?\n",
        "\n",
        "  *  Are you surprised that the accuracy to be this high for the first iteration?\n",
        "  *  What do you think might contribute to that?\n",
        "  *  How will a smaller size training data, say 40,000 images impact the accuracy of the model?\n",
        "  *  Will the model continue to improve with epochs > 5?\n",
        "  \n",
        "  ---\n",
        "  \n",
        "  Now let's evaluate the model using an independent test data set, and see if the model quality holds up.  We'll use `model.evaluate()` and pass in the test dataset.  `model.evaluare()` returns a `test_loss` and `test_acc`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "VflXLEeECaXC",
        "colab": {}
      },
      "source": [
        "# Use test dataset to evaluate model accuracy\n",
        "\n",
        "(test_loss, test_acc) = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "Well, it turns out, the accuracy on the test dataset is a little less than the accuracy on the training dataset.  This gap between training accuracy and test accuracy is an example of __overfitting__. Overfitting is when a machine learning model performs worse on new data than on their training data.  There are many reasons for overfitting which we'll discuss in more detail in the coming week, but one reason may be that the training dataset is not diverse enough to cover the range of possible images that we want to use the model to predict in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Make Predictions using the Trained Model\n",
        "\n",
        "With the model trained, it's time to make predictions on images and see what label the image suggests.  For simplicity, let's use the test images as input to the model.  We'll use the `model.predict()` and:\n",
        "  * Pass in `test_images` NumPy array as input\n",
        "  * Get predicted labels for all input images back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "Gl91RPhdCaXI",
        "colab": {}
      },
      "source": [
        "# Use the trained model to predict labels of training images\n",
        "\n",
        "predictions = model.predict(test_images)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C7Z21UdulbIg"
      },
      "source": [
        " So, what does the predicted label data look like?\n",
        " \n",
        "  * For each image, the prediction result is in the form of 10 numbers - one for each possible label\n",
        "  * In turn, each number represents the level of confidence that a label is the correct label for the particular image\n",
        "  * All 10 numbers should add up to the sum of 1\n",
        "  \n",
        "  ---\n",
        "  \n",
        "  Let's examine the predictions array, and inspect the values for the first image in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "zlpNm_89fSYn",
        "colab": {}
      },
      "source": [
        "# Show the dimension of predictions result\n",
        "\n",
        "predictions.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "abMisXJ9frWi"
      },
      "source": [
        "After confirming that the predictions results contain one set of 10 numbers for each of the images in the test_image dataset, let's examine the prediction result for the first image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "3DmJEUinCaXK",
        "colab": {}
      },
      "source": [
        "# Print out the prediction scores for the first image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "predictions[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBinsBmWme0r",
        "colab": {}
      },
      "source": [
        "# Check that the 10 numbers adds up to sum of 1\n",
        "\n",
        "predictions[0].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "Let's find out which label has the highest predicted number and whether it matches with the actual test label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "qsqenuPnCaXO",
        "colab": {}
      },
      "source": [
        "# Show label with the highest confidence value\n",
        "import numpy as np\n",
        "\n",
        "print('Label with the highest confidence: {predicted_label}'.format(\n",
        "    predicted_label = np.argmax(predictions[0])))\n",
        "\n",
        "\n",
        "print('Actual label: {actual_label}'.format(actual_label = test_labels[0]))\n",
        "\n",
        "\n",
        "print('Clothing class: {clothing_class}'.format(\n",
        "    clothing_class = class_names[test_labels[0]]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So the model is most confident that this image is an ankle boot, or `class_names[9]` and it matches the actual test label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Let's take a look at the image, as well as the bar chart of the prediction values.  In order to do so, please use the following utility functions `plot_image()` and `plot_value_array`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "DvYmmrpIy6Y1",
        "colab": {}
      },
      "source": [
        "# Utility function to plot image and actual label\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  \n",
        "  predictions_array = predictions_array[i]\n",
        "  true_label = true_label[i]\n",
        "  img = img[i]\n",
        "\n",
        "  # Remove grid, x and y axis ticks from the chart\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  # Plot the image\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  # Set predicted_label to the highest value from the prediction result\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  # Set color to blue on a correct prediction, otherwise set color to red\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  # Print the predicted label, confidence number, and actual label\n",
        "  plt.xlabel(\"{} ({:2.0f}%) vs {}\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "  \n",
        "# Utility function to plot the prediction numbers\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "\n",
        "  predictions_array = predictions_array[i]\n",
        "  true_label = true_label[i]\n",
        "  \n",
        "  # Don't print chart grid and both axis, and prepare a bar chart\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  \n",
        "  # Set predicted_label to the highest value from the prediction result\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "  # Set color to blue on a correct prediction, otherwise set color to red\n",
        "  \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "azfmgYrT3Guj",
        "colab": {}
      },
      "source": [
        "image_number = 0\n",
        "print('Prediction result for image number: ' + str(image_number) + '\\n')\n",
        "\n",
        "# Use the utility functions to show the image and the bar chart\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(image_number, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "So, looking at the bar chart shows that by far the model think it's an ankle boot, and the only other much less significant number is for sneaker (the gray bar).\n",
        "\n",
        "---\n",
        "\n",
        "Now that you are familiar with how to examine and visualize the prediction result for a particular image, let's look at 32 images.  You'll notice a variety of results including:\n",
        "\n",
        "  * High confidence and correct label\n",
        "  * High confidence and incorrect label\n",
        "  * Less confidence number on multiple labels\n",
        "  \n",
        "Anything stood out in cases where incorrect label is predicted, or where the model did not assign a high confidence number on any one label?  What do you think can be changed to improve model performance in these cases?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "hQlnbqaw2Qu_",
        "colab": {}
      },
      "source": [
        "# Plot the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "\n",
        "num_rows = 8\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OQtNqsqy0mlD"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hnGiLoNs09qH"
      },
      "source": [
        "## Exercise 1: Size of training set vs Model quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z3EXIATplaGU"
      },
      "source": [
        "This model above was trained with 60,000 images and `epochs=5`, and achieved training accuracy of 88% in a relatively short amount of training time.\n",
        "\n",
        "Your exercise is to experiment with smaller training datasets and answer the following questions:\n",
        "\n",
        "  * How the accuracy of the trained model impacted by smaller training datasets?\n",
        "  * How do the training accuracy and loss charts look like for the different size training datasets?\n",
        "  * Can you still achieve 88% accuracy on training dataset given a smaller dataset?  If so, how do you achieve that?\n",
        "  \n",
        "Write a short report on the answers to the questions above, including the supporting data, and your code below.  Optional: include any notes or other insights you come into during the experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Upws2T057QKJ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0TfVTHZj2urm"
      },
      "source": [
        "__Your Analysis:__\n",
        "\n",
        "Add your exploration notes, thought process, things you learned, conclusion (if any) and supporting data here.\n",
        "\n",
        "*   \n",
        "*   \n",
        "* \n",
        "* \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8OQxOnsy2ri2",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sidg-YMMYNS7",
        "colab": {}
      },
      "source": [
        "# Load training and test data\n",
        "import tensorflow as tf\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Scale the image pixel values from a range of 0 to 255 to a range of 0 to 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Retrain the model by a subset of images and labels which size is defined by\n",
        "# divide_data_by.  Return model and history objects.\n",
        "def retrainModel(divide_data_by, num_epochs):\n",
        "\n",
        "  endIndex = len(train_images) // divide_data_by\n",
        "\n",
        "  new_train_images = train_images[: endIndex ]\n",
        "  new_train_labels = train_labels[: endIndex ]\n",
        "\n",
        "  # Configure the model\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      optimizer=tf.train.AdamOptimizer(),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  history = model.fit(new_train_images, new_train_labels, epochs=num_epochs)\n",
        "  \n",
        "  return model, history\n",
        "\n",
        "# Evaluate the model with the test images and labels\n",
        "def evaluateModel(model):\n",
        "  \n",
        "  (test_loss, test_acc) = model.evaluate(test_images, test_labels)\n",
        "  print('Test accuracy:', test_acc)\n",
        "  print('Test loss:', test_loss)\n",
        "  \n",
        "# Plot accuracy and loss charts for the model training history object\n",
        "def plotAccuracyAndLoss(history):\n",
        "  \n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.figure(figsize=(16,5))\n",
        "\n",
        "  # Plot training set accuracy values for each training iteration\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('Training Accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train_accuracy'], loc='best')\n",
        "\n",
        "  # Plot training set loss values for each training iteration\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('Training Loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train_loss'], loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XJWYbFUcxXR",
        "colab": {}
      },
      "source": [
        "# Train with full set of data\n",
        "model, history = retrainModel(1, 5)\n",
        "evaluateModel(model)\n",
        "plotAccuracyAndLoss(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C3Z_J_j2cxPL",
        "colab": {}
      },
      "source": [
        "# Question: How the accuracy of the trained model impacted by smaller training\n",
        "#           datasets?\n",
        "# Question: How do the training accuracy and loss charts look like for the\n",
        "#           different size training datasets?\n",
        "\n",
        "# Train with half of data\n",
        "model, history = retrainModel(2, 5)\n",
        "evaluateModel(model)\n",
        "plotAccuracyAndLoss(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZyvemWIVcxGk",
        "colab": {}
      },
      "source": [
        "# Train with a quarter of data\n",
        "model, history = retrainModel(4, 5)\n",
        "evaluateModel(model)\n",
        "plotAccuracyAndLoss(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s30g-g-Tcw56",
        "colab": {}
      },
      "source": [
        "# Train with 1/8th of data\n",
        "model, history = retrainModel(8, 5)\n",
        "evaluateModel(model)\n",
        "plotAccuracyAndLoss(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3d1FXa54gkfu",
        "colab": {}
      },
      "source": [
        "# Question: Can you still achieve 88% accuracy on training dataset given a\n",
        "#           smaller dataset? If so, how do you achieve that?\n",
        "\n",
        "# Train with 1/8th of data, but double the epochs\n",
        "model, history = retrainModel(8, 10)\n",
        "evaluateModel(model)\n",
        "plotAccuracyAndLoss(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3f-D09Gc7ac9"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfOGETQE7btO",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ztv_I66BWfVQ"
      },
      "source": [
        "## Exercise 2: Challenge (Ungraded) - Predict Your Own Images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Y2Zsw7jldEH"
      },
      "source": [
        "Evaluating the model's quality with test images is a good practice as it's an independent dataset from the training dataset.  However, in practice you'll eventually want to use the model to predict incoming new images in the future.  That's the ultimate evaluation whether the model you built and trained is going to assist you classify new images.\n",
        "\n",
        "Think about the following tasks:\n",
        "\n",
        "  * Find one or more clothing item images, eg: Google Image search, your favorite online clothing store, a picture of your own clothing, etc.\n",
        "  * Manipulate the image(s) to fit the same criteria for the images in the training and test dataset, ie: dimension, etc.\n",
        "  * Convert the image(s) data into an input form for the model\n",
        "  * Predict the label using the model\n",
        "  \n",
        "So, what happened?  Did you run into challenges and roadblocks?  Any insight that is useful for future image classification projects?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ljmETuI7sEu"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KPKH3tEfYSYX"
      },
      "source": [
        "__Your Analysis:__\n",
        "\n",
        "Add your exploration notes, thought process, things you learned, conclusion (if any) and supporting data here.\n",
        "* \n",
        "*\n",
        "*\n",
        "*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cg2ekSgEYmH8",
        "colab": {}
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_mp6WxO7wug",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CGI11gYR7xm3"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJ5zF0jL7y2o",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}