{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression Project",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "UjAIOHZN1f_3",
        "ZsBn8Wj04QZv",
        "A40Ftvlb5UJd",
        "IPzk0QUD8KVX",
        "exercise-2-key-1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/03_regression/09_regression_project/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSdG7cSNFro-",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_FdRu8E0F6EJ"
      },
      "source": [
        "# Regression Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mm5d3zEpKE00"
      },
      "source": [
        "We have learned about regression and how to build regression models using both scikit-learn and TensorFlow. We will now build a regression model from start to finish. We will acquire data and perform exploratory data analysis and data preprocessing. We will build and tune our model and measure how well our model generalizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2iIQ-XduKJZz"
      },
      "source": [
        "## Framing the Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY3OnPx1zGWa",
        "colab_type": "text"
      },
      "source": [
        "### Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JbgK7HnzJD_",
        "colab_type": "text"
      },
      "source": [
        "*Friendly Insurance, Inc.* has requested that we do a study for them to help predict the cost of their policyholders. They have provided us with sample [anonymous data](https://www.kaggle.com/mirichoi0218/insurance) about some of their policyholders for the previous year. The dataset includes the following information:\n",
        "\n",
        "Column   | Description\n",
        "---------|-------------\n",
        "age      | age of primary beneficiary\n",
        "sex      | gender of the primary beneficiary (male or female)\n",
        "bmi      | body mass index of the primary beneficiary\n",
        "children | number of children covered by the plan\n",
        "smoker   | is the primary beneficiary a smoker (yes or no)\n",
        "region   | geographic region of the beneficiaries (northeast, southeast, southwest, or northwest)\n",
        "charges  | costs to the insurance company\n",
        "\n",
        "We have been asked to create a model that, given the first six columns, can predict the charges the insurance company might incur.\n",
        "\n",
        "The company wants to see how accurate we can get with our predictions. If we can make a case for our model, they will provide us with the full dataset of all of their customers for the last ten years to see if we can improve on our model and possibly even predict cost per client year over year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqKI2KIe02wc",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1: Thinking About the Data\n",
        "\n",
        "Before we dive in to looking closely at the data, let's think about the problem space and the dataset. Consider the questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjnbH6vp1PEK",
        "colab_type": "text"
      },
      "source": [
        "#### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhcs4Keh1Shq",
        "colab_type": "text"
      },
      "source": [
        "Is this problem actually a good fit for machine learning? Why or why not?\n",
        "\n",
        "##### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhYunBlz1ZMn",
        "colab_type": "text"
      },
      "source": [
        "> *Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJgwg-dL1cKm",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjAIOHZN1f_3",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpAYxMFE1lbD",
        "colab_type": "text"
      },
      "source": [
        "There are valid arguments for and against using machine learning for this scenario. Some examples are:\n",
        "\n",
        "**Yes**\n",
        "\n",
        "> This problem is likely a good fit for machine learning. We have a consistent set of input data that we can get from the insurance company. If we can make a reasonable model with this sample of data, we will get access to a decade of data for all of their clients, which should really help us build a powerful model.\n",
        ">\n",
        "> Regression is also a well-proven task of machine learning. There are strong mathematical models for linear regression and impressive cutting-edge deep learning models.\n",
        "\n",
        "**No**\n",
        "\n",
        "> Insurance companies invest heavily in well-trained actuaries to make these predictions. We'd be showing quite a bit of hubris to think we could completely replace their work. We might be able to create a model that could supplement their research, but there is already a lot of science around insurability and costs.\n",
        ">\n",
        "> Also, the data that we have isn't actually very comprehensive. We know information about the primary person covered by the insurance, but we know very little about their children and nothing about their spouse. We also don't know if the covered persons have other insurance that might be first in line to cover costs. There is so much data we don't have that it seems risky to make a model using this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sew8L-C1kUq",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q9C-k7o4A2g",
        "colab_type": "text"
      },
      "source": [
        "#### Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4F3Ezrc4DRb",
        "colab_type": "text"
      },
      "source": [
        "If we do build the machine learning model, what biases might exist in the data? Is there anything that might cause the model to have trouble generalizing to other data? If so, how might we make the model more resilient?\n",
        "\n",
        "##### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grZRXJkr4Myz",
        "colab_type": "text"
      },
      "source": [
        "> *Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMk4NdcZ4PyG",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsBn8Wj04QZv",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLIN3qXH4SFW",
        "colab_type": "text"
      },
      "source": [
        "An example answer might be:\n",
        "\n",
        "> There are many potential sources of bias in the data that we have been given. For instance, was the sample pulled randomly from the pool of the insured? Is it actually representative of the entire population of insured? Was there some large-scale medical event (or non-event) in the year that we were given data for that might make our model not generalize well to other years? Are BMI and smoking status really the appropriate health information to partially base our model on?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT-J12Av4T-N",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LtrUiMk4wIg",
        "colab_type": "text"
      },
      "source": [
        "#### Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHHdnVjS446h",
        "colab_type": "text"
      },
      "source": [
        "We have been asked to take input features about people who are insured and predict costs, but we haven't been given much information about how these predictions will be used. What effect might our predictions have on decisions made by the insurance company? How might this affect the insured?\n",
        "\n",
        "##### **Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6tiq72L5Q11",
        "colab_type": "text"
      },
      "source": [
        "> *Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LojR01P5TYf",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A40Ftvlb5UJd",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEVaAzoM5cFn",
        "colab_type": "text"
      },
      "source": [
        "An example answer might be:\n",
        "\n",
        "> Insurance companies need to make predictions about costs in order to set prices for insurance, and in some countries like the United States, to decide if they will insure a person or not. It is likely our predictions will be used by the insurance company to set plan premiums and to make decisions about who to insure.\n",
        ">\n",
        "> Given that our data will likely be used to determine plan costs and possibly even who gets insured, this model will have a very direct and dramatic effect on many people. The data might have an underlying bias against people with certain conditions and might be able to target those people without even knowing that they have the condition.\n",
        ">\n",
        "> This model could have large and damaging effects for the insurance company and for consumers. Great care must be taken when building this type of model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJUv-9y05WcZ",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVqj4S4tytvn",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAr2H2CJ60WX",
        "colab_type": "text"
      },
      "source": [
        "Now that we have considered the societal implications of our model, we can start looking at the data to get a better understanding of what we are working with.\n",
        "\n",
        "The data we'll be using for this project can be [found on Kaggle](https://www.kaggle.com/mirichoi0218/insurance). Upload your `kaggle.json` file and run the code block below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NiXw-ACkKlCT",
        "colab": {}
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYSfwuT8N3B",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 2: EDA and Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgjffxoV7kxc",
        "colab_type": "text"
      },
      "source": [
        "Using as many code and text blocks as you need, download the dataset, explore it, and do any model-independent preprocessing that you think is necessary. Feel free to use any of the tools for data analysis and visualization that we have covered in this course so far. Be sure to do individual column analysis and cross-column analysis. Explain your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIfb22Iq8Asx",
        "colab_type": "text"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk3q6P7q8D_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add code and text blocks to explore the data and explain your work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUo4DgfD8T7B",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPzk0QUD8KVX",
        "colab_type": "text"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guG_mKzr8X5R",
        "colab_type": "text"
      },
      "source": [
        "*There are many possible solutions for this exercise. An example solution follows.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Uh6RJy8fcl",
        "colab_type": "text"
      },
      "source": [
        "First things first, we need to download the data from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNhe7ASp8mdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download mirichoi0218/insurance\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eerh44oj8rOB",
        "colab_type": "text"
      },
      "source": [
        "Next, we load that data into a `DataFrame` and see the columns and data types that we'll be working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIemPo9h8w1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('insurance.zip')\n",
        "\n",
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2VLhtNp8zXo",
        "colab_type": "text"
      },
      "source": [
        "Looks like we have both objects (strings) and numbers. Let's describe the data. We pass the `include=\"all\"` argument so we can see the string column statistics, too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI1gq1ik86L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe(include=\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsmY5Nwc9RaU",
        "colab_type": "text"
      },
      "source": [
        "At a glance, it doesn't look like we have any missing data.\n",
        "\n",
        "Next we can look at each of our columns. (In our examples we just use the `.hist()` method. You might have used a package like Matplotlib or seaborn.)\n",
        "\n",
        "We can create a histogram for 'age'. The histogram shows that this dataset seems to be somewhat biased toward a younger crowd."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_QLTyM29Gez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = df['age'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dporqmuT9gyT",
        "colab_type": "text"
      },
      "source": [
        "'sex' is a string column. Let's see what values we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QptpytHf9qHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = df['sex'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bNTB6sv9unV",
        "colab_type": "text"
      },
      "source": [
        "Looks like there are only two values: 'male' and 'female'. This matches the documentation. The values are also relatively evenly distributed.\n",
        "\n",
        "Next we'll look at 'bmi', which is the body mass index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBguhfgm96za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = df['bmi'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QegTOQdj-rhK",
        "colab_type": "text"
      },
      "source": [
        "We get a somewhat normal distribution centered around `30`. Upon [further research](https://www.cdc.gov/healthyweight/assessing/bmi/adult_bmi/index.html) we find that a BMI of 30 is considered obese, so many of our insured are considered obese. Let's see how many."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtPMn4zD-v7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(df['bmi'] >= 30).sum() / df['bmi'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY4Oq8vW_QkL",
        "colab_type": "text"
      },
      "source": [
        "Wow, more than half of our dataset is considered obese (53%). With a little research we find that 40% of the adult US population is considered obese, so our dataset skews quite a bit heavier. Putting our ethics hat back on, we might want to double-check what the insurance company is planning on doing with this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlexQELDADK-",
        "colab_type": "text"
      },
      "source": [
        "Moving on to the 'children' column, we can see a pretty unsurprising histogram. Many of our insured were in their 20s, so seeing 0 children being such a large value isn't shocking. Likewise, we expect fewer United States families to have 3 or more children."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DWHAYYAAGKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['children'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swh615SsAgwu",
        "colab_type": "text"
      },
      "source": [
        "'Smoker' is the next column. We can see that we have two values: 'yes' and 'no'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJjzj_edAd65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['smoker'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g_aZyn-AuvA",
        "colab_type": "text"
      },
      "source": [
        "'Region' is our final feature column. We can see that our insured are fairly evenly distributed across each of the four regions. It would be interesting to know if this was representative of the entire client base for the company."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljnoFp5MAr5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['region'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCWaeyTWBo6h",
        "colab_type": "text"
      },
      "source": [
        "Finally we can look at 'charges', which is our target column. In doing so, we can see a long tail of charges that range from around `0` to around `60000`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMLvB5GqA-bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['charges'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSpkhm3KCATE",
        "colab_type": "text"
      },
      "source": [
        "There are many cross-column analyses that can be performed. In the example below, we calculate average charges per region to see if any region stands out. No region seems to stand out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNZPTJ3jBbpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "charges_per_region = df.groupby('region').agg({'charges': ['sum', 'count']})\n",
        "charges_per_region['charges']['sum'] / charges_per_region['charges']['count']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeDqIokYCTMs",
        "colab_type": "text"
      },
      "source": [
        "We could also create a correlation matrix to see if there are any strong correlations. There aren't any at this stage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbiY6wERCMD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R--2Yrjf8Co7",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac-YMzcBy1yM",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mp3TkmalNcR-"
      },
      "source": [
        "Now that we understand our data a little better, we can build a model. We are trying to predict 'charges', which is a continuous variable. We'll use a regression model to predict 'charges'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlwZpbUIHQZ",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 3: Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnc7Y47bIQG5",
        "colab_type": "text"
      },
      "source": [
        "Using as many code and text blocks as you need, build a model that can predict 'charges' given the features that we have available. To do this, feel free to use any of the toolkits and models that we have explored so far.\n",
        "\n",
        "You'll be expected to:\n",
        "1. Prepare the data for the model (or models) that you choose. Remember that some of the data is categorical. In order for your model to use it, you'll need to convert the data to some numeric representation.\n",
        "1. Build a model or models and adjust parameters.\n",
        "1. Validate your model with holdout data. Hold out some percentage of your data (10-20%), and use it as a final validation of your model. Print the root mean squared error. We were able to get an RMSE between `3500` and `4000`, but your final RMSE will likely be different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjSCGA7HryJh",
        "colab_type": "text"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sm-HIs5IL3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add code and text blocks to build and validate a model and explain your work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITsTAJgWIJVT",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZUTJ4sbCKi8E"
      },
      "source": [
        "We chose to create a neural network using TensorFlow 2's Keras API.\n",
        "\n",
        "The first step for our model was to one-hot encode our categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecyf_0-M5owS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_features = []\n",
        "\n",
        "df['is_female'] = df['sex'].apply(lambda x: int(x == 'female'))\n",
        "df['is_male'] = df['sex'].apply(lambda x: int(x == 'male'))\n",
        "one_hot_features.extend(['is_female', 'is_male'])\n",
        "\n",
        "df['is_smoker'] = df['smoker'].apply(lambda x: int(x == 'yes'))\n",
        "df['is_nonsmoker'] = df['smoker'].apply(lambda x: int(x == 'no'))\n",
        "one_hot_features.extend(['is_smoker', 'is_nonsmoker'])\n",
        "\n",
        "df['region_sw'] = df['region'].apply(lambda x: int(x == 'southwest'))\n",
        "df['region_se'] = df['region'].apply(lambda x: int(x == 'southeast'))\n",
        "df['region_nw'] = df['region'].apply(lambda x: int(x == 'northwest'))\n",
        "df['region_ne'] = df['region'].apply(lambda x: int(x == 'northeast'))\n",
        "one_hot_features.extend(['region_sw', 'region_se', 'region_nw', 'region_ne'])\n",
        "\n",
        "df[one_hot_features].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6GHiJZdLoxp",
        "colab_type": "text"
      },
      "source": [
        "Next, we normalized our numeric features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qmeKTsa0r6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = ['age', 'bmi', 'children']\n",
        "\n",
        "df.loc[:, numeric_features] = (\n",
        "    (df[numeric_features] - df[numeric_features].min()) /\n",
        "    (df[numeric_features].max() - df[numeric_features].min()))\n",
        "\n",
        "df[numeric_features].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXnEmY5cMCVP",
        "colab_type": "text"
      },
      "source": [
        "We then set our target and features. Since our target has a minimum value near zero, we didn't scale it at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REeHbV_BTCpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'charges'\n",
        "features = numeric_features + one_hot_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQUgrI1OMN68",
        "colab_type": "text"
      },
      "source": [
        "We then split out training and testing data. We shuffled our data before splitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4bAgfaG1wpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "record_count = df['charges'].count()\n",
        "\n",
        "test_size = int(record_count * .2)\n",
        "\n",
        "df = df.sample(frac=1.0)\n",
        "\n",
        "test_df, train_df = df[:test_size], df[test_size:]\n",
        "\n",
        "test_df['charges'].count(), train_df['charges'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-pDywU7MWzB",
        "colab_type": "text"
      },
      "source": [
        "We loaded TensorFlow 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3srzTsU-3SzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVmxI_gEMaPD",
        "colab_type": "text"
      },
      "source": [
        "And then built a sequential model that inputs our features and outputs a single value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwAdtmsj30pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "feature_count = len(numeric_features + one_hot_features)\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(128, input_shape=[feature_count], activation='relu'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(32, activation='relu'),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1, activation='relu')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyaUaE5lMtUv",
        "colab_type": "text"
      },
      "source": [
        "We then compiled the model and trained it for `2500` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3gsvls0T9O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "  loss='mse',\n",
        "  optimizer='Adam',\n",
        "  metrics=['mse'],\n",
        ")\n",
        "\n",
        "EPOCHS = 2500\n",
        "\n",
        "history = model.fit(\n",
        "  df[features],\n",
        "  df[target],\n",
        "  epochs=EPOCHS,\n",
        "  verbose=0,\n",
        "  validation_split=0.1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTKqtRHUM0AA",
        "colab_type": "text"
      },
      "source": [
        "We printed the mean squared error per epoch. In many of our runs the mean squared error, and validation mean squared error crossed as we began to overfit on our training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkdd7LCNUUx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "errors = history.history['mse']\n",
        "validation_errors = history.history['val_mse']\n",
        "epochs = np.arange(0, len(errors))\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "sns.lineplot(epochs, errors)\n",
        "sns.lineplot(epochs, validation_errors)\n",
        "_ = plt.legend(['Mean Squared Error', 'Validation Mean Squared Error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dTCaKx_NLdk",
        "colab_type": "text"
      },
      "source": [
        "And printed our root mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Muk7AsUe_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_df[features])\n",
        "\n",
        "root_mean_squared_error = math.sqrt(\n",
        "    metrics.mean_squared_error(\n",
        "      predictions,\n",
        "      test_df[target]\n",
        "))\n",
        "\n",
        "print(\"Root Mean Squared Error (on training data): %0.3f\" % \n",
        "  root_mean_squared_error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkFrvNOzNPJe",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    }
  ]
}
