{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/02_data/05_exploratory_data_analysis/colab-part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright"
   },
   "source": [
    "#### Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHUQ8PUGZh8y"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQswfu6M_ZBR"
   },
   "source": [
    "# Exploratory Data Analysis: Part 2 - Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "invE35z3n2Yn"
   },
   "source": [
    "In this second part of our [Exploratory Data Analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis) journey, we will build upon the cleaned up dataset that we created in part 1.\n",
    "\n",
    "In part 2 we will use visualization libraries to look closer at individual columns and to see how different columns relate to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIxZkNQzBiyc"
   },
   "source": [
    "## Part 1 Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4nDJfscDH9o"
   },
   "source": [
    "### The Dataset: Chocolate Bar Ratings\n",
    "\n",
    "You should remember that in this lab we are using a [chocolate bar ratings dataset](https://www.kaggle.com/rtatman/chocolate-bar-ratings) from the [Flavors of Cacao](http://flavorsofcacao.com/flavor.html) data. On the [Kaggle page for the dataset](https://www.kaggle.com/rtatman/chocolate-bar-ratings) we can find the documentation for the columns:\n",
    "\n",
    "Column | Data Type | Description\n",
    "-------|-----------|-------------\n",
    "Company (Maker-if known) | String | Name of the company manufacturing the bar.\n",
    "Specific Bean Origin or Bar Name | String | The specific geo-region of origin for the bar.\n",
    "REF | Number | A value linked to when the review was entered in the database. Higher = more recent.\n",
    "Review Date | Number | Date of publication of the review.\n",
    "Cocoa Percent | String | Cocoa percentage (darkness) of the chocolate bar being reviewed.\n",
    "Company Location | String | Manufacturer base country.\n",
    "Rating | Number | Expert rating for the bar.\n",
    "BeanType | String | The variety (breed) of bean used, if provided.\n",
    "Broad Bean Origin | String | The broad geo-region of origin for the bean.\n",
    "\n",
    "In part 1 of this unit we modified the columns to be:\n",
    "\n",
    "Column | Data Type | Description\n",
    "-------|-----------|------------\n",
    "Company | String  | Name of the company manufacturing the bar.\n",
    "Company Location | String | Manufacturer base country.\n",
    "Bean Type | String | The variety (breed) of bean used, if provided.\n",
    "Specific Bean Origin | String | The specific geo-region of origin for the bar.\n",
    "Broad Bean Origin | String | The broad geo-region of origin for the bean.\n",
    "Cocoa Percent | Number | Cocoa percentage (darkness) of the chocolate bar being reviewed.\n",
    "REF | Number |A value linked to when the review was entered in the database. Higher = more recent.\n",
    "Review Date | Number | Date of publication of the review.\n",
    "Rating | Number | Expert rating for the bar. Number between 1.0 and 5.0, inclusive.\n",
    "Grade | Number | Expert rating for the bar. 'A' - 'Q'. Maps to distinct ratings.\n",
    "\n",
    "Let's download the dataset again and apply the changes that we made in part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GP-kRR_72562"
   },
   "source": [
    "### Acquiring the Data\n",
    "\n",
    "The data is hosted on Kaggle, so we can use our Kaggle credentials to download the data into the lab. The dataset is located at [https://www.kaggle.com/rtatman/chocolate-bar-ratings](https://www.kaggle.com/rtatman/chocolate-bar-ratings). We can use the `kaggle` command line utility to do this.\n",
    "\n",
    "First off, upload your `kaggle.json` file into the lab now.\n",
    "\n",
    "Next, run the following command to get the credential files set to the right permissions and located in the correct spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UuViqN232cr"
   },
   "outputs": [],
   "source": [
    "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCMEX2915D1Y"
   },
   "source": [
    "Now we can run the `kaggle` command to actually download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo1mS1Jp4c5W"
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download rtatman/chocolate-bar-ratings\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PytnXVWU7Lom"
   },
   "source": [
    "We now have our data downloaded to our virtual machine and stored in the file `chocolate-bar-ratings.zip`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8pOhe8_7YOt"
   },
   "source": [
    "### Prepping the `DataFrame`\n",
    "\n",
    "We will now load the data into a `DataFrame` and apply the data preprocessing that was done in part 1 of this unit. Run the hidden code block below to fill a `DataFrame` called `df` with preprocessed data.\n",
    "\n",
    "Run this block again if you need to reset the `df` `DataFrame`. After you run the code block, there will also be a function that you can use to reset `df`:\n",
    "\n",
    "```python\n",
    "  df = reload_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "dEDlbe_L7LEl"
   },
   "outputs": [],
   "source": [
    "#@title Part 1 Code: Press Run To Load Preprocessed Data Frame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def reload_data():\n",
    "  df = pd.read_csv('chocolate-bar-ratings.zip')\n",
    "\n",
    "  df.columns = [\n",
    "    'Company',\n",
    "    'Specific Bean Origin',\n",
    "    'REF',\n",
    "    'Review Date',\n",
    "    'Cocoa Percent',\n",
    "    'Company Location',\n",
    "    'Rating',\n",
    "    'Bean Type',\n",
    "    'Broad Bean Origin'\n",
    "  ]\n",
    "\n",
    "  df = df[[\n",
    "    'Company',\n",
    "    'Company Location',\n",
    "    'Bean Type',\n",
    "    'Specific Bean Origin',\n",
    "    'Broad Bean Origin',\n",
    "    'Cocoa Percent',\n",
    "    'REF',\n",
    "    'Review Date',\n",
    "    'Rating',\n",
    "  ]]\n",
    "\n",
    "  column = 'Company'\n",
    "  for broken, fixed in {\n",
    "    'Shattel': 'Shattell',\n",
    "    'Cacao de Origin': 'Cacao de Origen',\n",
    "  }.items():\n",
    "    df.loc[df[column] == broken, column] = fixed\n",
    "\n",
    "  column = 'Company Location'\n",
    "  for broken, fixed in {\n",
    "    'Domincan Republic': 'Dominican Republic',\n",
    "    'Niacragua': 'Nicaragua',\n",
    "    'Eucador': 'Ecuador',\n",
    "    'Amsterdam': 'Holland',\n",
    "    'U.K.': 'England',\n",
    "  }.items():\n",
    "    df.loc[df[column] == broken, column] = fixed\n",
    "\n",
    "  column = 'Bean Type'\n",
    "  df.loc[df[column].isna(), column] = 'Unknown'\n",
    "  df.loc[df[column] == chr(0xa0), column] = 'Unknown'\n",
    "\n",
    "  column = 'Specific Bean Origin'\n",
    "  for broken, fixed in {\n",
    "    'Ambolikapkly P.': 'Ambolikapiky P.',\n",
    "    'Dominican Republicm, rustic': 'Dominican Republic, rustic',\n",
    "    'Nicaraqua': 'Nicaragua',\n",
    "  }.items():\n",
    "    df.loc[df[column] == broken, column] = fixed\n",
    "\n",
    "  column = 'Broad Bean Origin'\n",
    "  df.loc[(df['Specific Bean Origin'] == 'Madagascar') &\n",
    "        (df[column].isna()), column] = 'Madagascar'\n",
    "  df.loc[df[column] == chr(0xa0), column] = 'Unknown'\n",
    "\n",
    "  column = 'Cocoa Percent'\n",
    "  df[column] = df[column].apply(lambda s: float(s[:-1]))\n",
    "\n",
    "  def grade(rating):\n",
    "    letter_grade = 'A'\n",
    "    numeric_rating = 5.0\n",
    "    while rating < numeric_rating:\n",
    "      letter_grade = chr(ord(letter_grade) + 1)\n",
    "      numeric_rating -= 0.25\n",
    "    return letter_grade\n",
    "\n",
    "  column = 'Grade'\n",
    "  df[column] = df['Rating'].apply(grade)\n",
    "  \n",
    "  return df\n",
    "\n",
    "df = reload_data()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmbCYQJu9SJp"
   },
   "source": [
    "## Data Analysis\n",
    "\n",
    "We have looked at each column in isolation in order to ensure that the data in that column is complete and seems to make sense. In this section we will take that newly-cleaned data and look at it in a little more depth. We will examine some columns individually. We'll also see how columns might relate to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrNet1xDAF-W"
   },
   "source": [
    "### Visualizing Ratings\n",
    "\n",
    "Ratings are very important to our dataset. One interesting visualization might be a line chart of counts of each rating. To do that we can extract a `Series` containing the ratings, group by that `Series`, and plot the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdX5BpD3-gFM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ratings = df['Rating'].groupby(df['Rating']).count()\n",
    "\n",
    "plt.plot(ratings.index, ratings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NsS3asnJAWRX"
   },
   "source": [
    "This shows that ratings seem to mostly be in the 3s with a reasonable tail higher and lower.\n",
    "\n",
    "We can also put these values in a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C59We7HvAD3U"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grades = df['Rating'].groupby(df['Rating']).count()\n",
    "\n",
    "plt.bar(grades.index, grades)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-w4w1FacBECK"
   },
   "source": [
    "This changes the visualization's form quite a bit. Instead of using 'Rating' for the chart, let's use our 'Grade' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwjzLAC4BRPR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grades = df['Grade'].groupby(df['Grade']).count()\n",
    "\n",
    "plt.bar(grades.index, grades)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jq0Ap-dBUfE"
   },
   "source": [
    "Overall, that's looking better. The sorting is opposite of 'Rating', so our best chocolates are to the left instead of the right. And you can see that we are missing 'B', 'C' and other values, which is not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijMD7xpmBnrr"
   },
   "source": [
    "#### Exercise 1: Grade Bar Chart\n",
    "\n",
    "Improve on the bar chart of Grade values by having the chart include all letter grades, with counts or not, between 'A' and 'Q'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGD88y2fBxMg"
   },
   "outputs": [],
   "source": [
    "df = reload_data()\n",
    "\n",
    "# Your Solution Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IaXHefe6BQ7m"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8U_spjA2FLPP"
   },
   "source": [
    "### Visualizing Cocoa Percentage\n",
    "\n",
    "Cocoa percentage is another value that might be interesting in our data analysis. For instance, does a higher or lower cocoa percentage seem to correlate with the rating in any manner?\n",
    "\n",
    "We'll get to questions like this, but first let's just create a simple plot.\n",
    "\n",
    "First let's see if 'Cocoa Percent' is an actual continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_YFI7jilF5ud"
   },
   "outputs": [],
   "source": [
    "sorted(df['Cocoa Percent'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCGxvCKBF8fU"
   },
   "source": [
    "This does seem much more like a continuous variable than 'Rating' did. In this case we will want to use some sort of continuous plot.\n",
    "\n",
    "For this particular visualization, we will pull out a new tool, the [`seaborn.distplot`](https://seaborn.pydata.org/generated/seaborn.distplot.html). This plot combines a line chart of kernel density and a histogram to show the distribution of values in the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "Z1ZVr0efD0dV"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "_ = sns.distplot(df['Cocoa Percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9bQCTf0nz0ek"
   },
   "source": [
    "As we can tell from this plot, a very large proportion of chocolate bars rated have around 70% cocoa. We may want to ask whether this sample is representative of chocolate bars on the market in general or whether reviewers favor such bars because they expect them to be more enjoyable. (i.e. Is our sample representative of the population?) This, of course, would require research outside of our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FwaxnlLYLAR"
   },
   "source": [
    "#### Exercise 2: What Is a Distplot?\n",
    "\n",
    "We plotted a \"distplot\" above but didn't get too specific on what was actually being shown. The values on the x-axis make sense; they are the percentage of cocoa used in the bar. But there are some other aspects of the chart that are a little less clear at first.\n",
    "\n",
    "Using the [`seaborn.distplot` documentation](https://seaborn.pydata.org/generated/seaborn.distplot.html) and other resources, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HX1p6Ul3ZRPd"
   },
   "source": [
    "**Student Solution**\n",
    "\n",
    "1. What do the columns on the chart represent?\n",
    "> *Your Answer Goes here*\n",
    "1. What does the continuous line on the chart represent?\n",
    "> *Your Answer Goes here*\n",
    "1. What is the y-value of the `sns.distplot`?\n",
    "> *Your Answer Goes here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0kNJE7HZN_D"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0e6LcTBhTZN"
   },
   "source": [
    "### Visualizing Ratings by Bean Type\n",
    "\n",
    "Sometimes it is useful to visualize our target, in this case, 'Rating', by different features. One way to do this with a continuous variable like 'Rating' is with a box plot.\n",
    "\n",
    "Box plots (a.k.a., box and whisker plots) show the distribution across categories. These plots are quite informative, as they display a five-statistic summary of a dataset, including:\n",
    "\n",
    "1. Minimum\n",
    "1. First quartile (about 25% of the numbers in the dataset lie below it)\n",
    "1. Median (splits the dataset in half)\n",
    "1. Third quartile (about 75% of the numbers in the dataset lie below it)\n",
    "1. Maximum\n",
    "\n",
    "In the example below, we create our box plot using [`seaborn.boxplot()`](https://seaborn.pydata.org/generated/seaborn.boxplot.html). We pass the function our `DataFrame`, the y-value which determines the number of box plots, and the x-value which is what the statistics are gathered from.\n",
    "\n",
    "Remember that `seaborn` is based on `matplotlib`, so we can still use features of `matplotlib` like the figure size to increase the size of `seaborn` charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "3eCG0Z6RiIbz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "plt.figure(figsize=[10, 16])\n",
    "ax = sns.boxplot(\n",
    "    data=df,\n",
    "    y='Bean Type',\n",
    "    x='Rating',\n",
    ")\n",
    "_ = ax.set_title('Rating Distribution by Bean Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PkbuxBKdTLH"
   },
   "source": [
    "This is a nice chart, but it is difficult to get a snapshot view of the data. Sometimes sorting is important.\n",
    "\n",
    "As an example, let's look at a chart that is sorted alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dPdRuSsdoEg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "plt.figure(figsize=[10, 16])\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    data=df,\n",
    "    y='Bean Type',\n",
    "    x='Rating',\n",
    "    order=sorted(df['Bean Type'].unique()),\n",
    ")\n",
    "\n",
    "_ = ax.set_title('Rating Distribution by Bean Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEJc9XTOdwZh"
   },
   "source": [
    "That might be even worse!\n",
    "\n",
    "What sort order might give some meaning to this chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cSKVrR0IemDS"
   },
   "source": [
    "#### Exercise 3: Building Boxplots\n",
    "\n",
    "Boxplots are useful, but without curated sorting, the message can get lost in the noise. Experiment with different sorting strategies for the boxplot and make an argument for why you find value in your plot.\n",
    "\n",
    "Below is an example of plots sorted by the mean rating. Look at it and see why sorting by mean might bring value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V84L80dnamgQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "plt.figure(figsize=[10, 16])\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    data=df,\n",
    "    y='Bean Type',\n",
    "    x='Rating',\n",
    "    order=sorted(df['Bean Type'].unique(), \n",
    "                 key=lambda bt: df[df['Bean Type'] == bt]['Rating'].mean()),\n",
    ")\n",
    "\n",
    "_ = ax.set_title('Rating Distribution by Bean Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24EN2gtaiMQh"
   },
   "source": [
    "Some thoughts:\n",
    "\n",
    "* Even sorting by mean, the max ratings can still be held by beans near the median.\n",
    "* Beans with a low median rating are actually widespread on ratings.\n",
    "* Quality tightens with beans with higher median rankings.\n",
    "\n",
    "These observations may lead us to ask: what are the sample sizes? Are the top-median beans just single samples while more popular beans are weighted down by large sample sizes? Regardless of which sorting criteria we use, we should take a closer look at our bean types. Some of the types with fewer samples might need to be rolled into a larger grouping.\n",
    "\n",
    "For this exercise, try different statistics for sorting. Find one that you can interpret and explain why the specific sorting is meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGxgg4GTiw1T"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kY1VXhtGizfO"
   },
   "outputs": [],
   "source": [
    "# Your Solution Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06vfzCqFi2qT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nf-9ooG5zzsR"
   },
   "source": [
    "### Visualizing Ratings by Cocoa Percent\n",
    "\n",
    "Let's take a moment to also look at the spread of ratings by 'Cocoa Percent'. A natural way to do this might be a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvneTVU74Xzf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "plt.figure(figsize=[10, 10])\n",
    "ax = sns.scatterplot(\n",
    "    data=df,\n",
    "    x='Cocoa Percent',\n",
    "    y='Rating',\n",
    ")\n",
    "\n",
    "_ = ax.set_title('Ratings by Cocoa Percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZVb_w8H4wB0"
   },
   "source": [
    "This is a somewhat unfulfilling scatter plot. Since ratings aren't really continuous, we see \"lines\" of dots for the ratings tranches. There are also some lines formed vertically; though 'Cocoa Percent' is continuous, some percentages are more common than others.\n",
    "\n",
    "Maybe a boxplot would work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5fILyKl5R3e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "plt.figure(figsize=[10, 10])\n",
    "ax = sns.boxplot(\n",
    "    data=df,\n",
    "    x='Cocoa Percent',\n",
    "    y='Rating',\n",
    ")\n",
    "\n",
    "_ = ax.set_title('Ratings by Cocoa Percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WAAgMT-g5Yic"
   },
   "source": [
    "That is better. Given this box plot, we can see some trends in the data. However, there are enough different 'Cocoa Percent' values to make this chart a little cluttered.\n",
    "\n",
    "We can clean it up a bit by **binning** the 'Cocoa Percent' values.\n",
    "\n",
    "Binning is the process of taking a large set of continuous values and dividing them into a fixed number of bins where each bin contains a range of values. Each bin typically has the same sized range.\n",
    "\n",
    "To bin data we can use [`NumPy.histogram_bin_edges`](https://numpy.org/devdocs/reference/generated/numpy.histogram_bin_edges.html) to find the edges of our bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhn-2WHa7AEZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "edges = np.histogram_bin_edges(df['Cocoa Percent'])\n",
    "\n",
    "for i in range(len(edges) - 1):\n",
    "  print(f'{edges[i]:.{1}f} - {edges[i+1]:.{1}f} ({edges[i+1]-edges[i]:.{1}f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VhIGlaFS7Zh7"
   },
   "source": [
    "In the code above we asked `histogram_bin_edges()` to find the edges of our bins for 'Cocoa Percent'. We then printed the edges for each bin and the size of the range for each bin. You can see that each is 5.8.\n",
    "\n",
    "Given these bin edges, we can now use another handy `NumPy` function: `digitize`.  `digitize` will examine our 'Cocoa Percent' values and return the bin that each value belongs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8KmuyS486ZL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "edges = np.histogram_bin_edges(df['Cocoa Percent'])\n",
    "bins = np.digitize(df['Cocoa Percent'], edges)\n",
    "np.unique(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ggWQzVV-anp"
   },
   "source": [
    "Wait, there are 11 bins when there were only supposed to be 10. What happened?\n",
    "\n",
    "It turns out that `histogram_bin_edges` and `digitize` think differently about the list of edges. `histogram_bin_edges` returns `bin_count + 1` values (in this case, 11), so that each bin has a defined stop and start. The final edge serves as an upper limit (in this case, 100).\n",
    "\n",
    "On the other hand, `digitize` lets the final bin accept any data larger than the start of the bin (or smaller if you are creating decreasing order bins), so there's no need for an edge to define the outside boundary. For that reason, we have to not pass digitize the final edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97ZSYL3z_DGd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "edges = np.histogram_bin_edges(df['Cocoa Percent'])\n",
    "bins = np.digitize(df['Cocoa Percent'], edges[:-1])\n",
    "np.unique(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wEmsn0H69Ja-"
   },
   "source": [
    "That is better. We can now bring it all together and create a binned boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQmOh6j6zCtx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = reload_data()\n",
    "\n",
    "edges = np.histogram_bin_edges(df['Cocoa Percent'], bins=10)\n",
    "bins = np.digitize(df['Cocoa Percent'], edges[:-1])\n",
    "\n",
    "plt.figure(figsize=[16, 10])\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    x=bins,\n",
    "    y=df['Rating'],\n",
    ")\n",
    "\n",
    "labels = [f'{edges[i]:.{1}f} - {edges[i+1]:.{1}f}'\n",
    "            for i in range(len(edges) - 1)]\n",
    "_ = plt.xticks(list(range(10)), labels)\n",
    "_ = ax.set_title('Ratings by Cocoa Percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsHtYfWeAa5K"
   },
   "source": [
    "#### Exercise 4: Interpreting Box Plots\n",
    "\n",
    "We've now created a boxplot that shows the range of ratings for different bins of percentages of cocoa. Use the plot to answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJaSYdApBA-E"
   },
   "source": [
    "**Student Solution**\n",
    "\n",
    "1. Which bin of cocoa percentages tends to be the lowest rated?\n",
    "> *Your Answer Goes Here*\n",
    "1. Which bin (or bins) of cocoa percentages tend to get the most consistent ratings?\n",
    "> *Your Answer Goes Here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQOj4HWkBwuc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WGACfglohPS"
   },
   "source": [
    "### Finding Correlations\n",
    "\n",
    "Another important check is to see if there are any correlations in your dataset. Correlation is a measure of how well two continuous variables track together.\n",
    "\n",
    "Pandas provides `DataFrame.corr()`, which provides a correlation matrix for all of the numeric values in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02yE24S1ok5H"
   },
   "outputs": [],
   "source": [
    "df = reload_data()\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJ3XC7Z8tnQK"
   },
   "source": [
    "#### Exercise 5: Heatmap Correlations\n",
    "\n",
    "It is common for correlations to be shown in a heatmap. In this exercise we will create a heatmap and then attempt to interpret the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSD0W-5Dt7_g"
   },
   "source": [
    "**Student Solution**\n",
    "\n",
    "Uses `seaborn` or `matplotlib` to create a heatmap representing the correlations in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGun9IjKt5tX"
   },
   "outputs": [],
   "source": [
    "# Your Solution Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZhg482nuj4a"
   },
   "source": [
    "1. Which columns have the strongest correlation?\n",
    "> *Your answer goes here.*\n",
    "1. Why do you think they have such a strong correlation?\n",
    "> *Your answer goes here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9HSXHrFuFlZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzECzbj_tcSz"
   },
   "source": [
    "### Visualizing Ratings Across the Globe\n",
    "\n",
    "This dataset seems to really emphasize the source of the cocoa beans used to make a chocolate bar. It would be interesting to see if there was a correlation with the geographical source of the beans and the perceived quality of the resulting chocolate.\n",
    "\n",
    "In order to do this, we need to take one of our columns of location data and turn it into geographical coordinates that we can then use to attempt to identify a pattern.\n",
    "\n",
    "The alleged geographical columns that we have in our data are:\n",
    "\n",
    "Column | Data Type | Description\n",
    "-------|-----------|------------\n",
    "Company Location | String | Manufacturer base country.\n",
    "Specific Bean Origin | String | The specific geo-region of origin for the bar.\n",
    "Broad Bean Origin | String | The broad geo-region of origin for the bean.\n",
    "\n",
    "But we know from our earlier analysis of the data that both of the bean origin columns are pretty messy. We could possibly tie most of the data points down to a geographical location, but it would be a huge undertaking. Also, the bean origins can have multiple locations for mixed blends. Ultimately this would be an interesting undertaking, but not for the scope of this course. \n",
    "\n",
    "'Company Location' offers more promise though. We have verified that it contains country information. It doesn't necessarily relate to the source of the bean, but we can at least try to see where the best bars are created!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYe9Ov7_Ie0f"
   },
   "source": [
    "Since the 'Company Location' values are all countries, we went ahead and created a `DataFrame` below that contains the latitude and longitude values for the countries that we have company data for. We have also merged the lat/long data into `df`.\n",
    "\n",
    "Run the hidden code cell below to update `df` with latitude and longitude data. After you run this cell a function called `reload_data_plus_latlong()` will be available to you to restore `df` to its original state at any time. To use it in your code write:\n",
    "\n",
    "```python\n",
    "df = reload_data_plus_latlong()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "wyUIAdfavtRV"
   },
   "outputs": [],
   "source": [
    "#@title Lat Long Addition: Press Run To Load `df`\n",
    "\n",
    "def reload_data_plus_latlong():\n",
    "  df = reload_data()\n",
    "\n",
    "  country_df = pd.DataFrame([\n",
    "    ['Argentina', -36.3, -60.0],\n",
    "    ['Australia', -35.15, 149.08],\n",
    "    ['Austria', 48.12, 16.22],\n",
    "    ['Belgium', 50.51, 4.21],\n",
    "    ['Bolivia', -16.2, -68.1],\n",
    "    ['Brazil', -15.47, -47.55],\n",
    "    ['Canada', 45.27, -75.42],\n",
    "    ['Chile', -33.24, -70.4],\n",
    "    ['Colombia', 4.34, -74.0],\n",
    "    ['Costa Rica', 9.55, -84.02],\n",
    "    ['Czech Republic', 50.05, 14.22],\n",
    "    ['Denmark', 55.41, 12.34],\n",
    "    ['Dominican Republic', 18.74, -70.16],\n",
    "    ['Ecuador', -0.15, -78.35],\n",
    "    ['England', 52.36, -1.17],\n",
    "    ['Fiji', -18.06, 178.3],\n",
    "    ['Finland', 60.15, 25.03],\n",
    "    ['France', 48.5, 2.2],\n",
    "    ['Germany', 52.3, 13.25],\n",
    "    ['Ghana', 5.35, -0.06],\n",
    "    ['Grenada', 12.12, -61.68],\n",
    "    ['Guatemala', 14.4, -90.22],\n",
    "    ['Holland', 52.13, 5.29],\n",
    "    ['Honduras', 14.05, -87.14],\n",
    "    ['Hungary', 47.29, 19.05],\n",
    "    ['Iceland', 64.1, -21.57],\n",
    "    ['India', 28.37, 77.13],\n",
    "    ['Ireland', 53.21, -6.15],\n",
    "    ['Israel', 31.71, -35.1],\n",
    "    ['Italy', 41.54, 12.29],\n",
    "    ['Japan', 36.2, 138.25],\n",
    "    ['Lithuania', 54.38, 25.19],\n",
    "    ['Madagascar', -18.55, 47.31],\n",
    "    ['Martinique', 14.36, -61.02],\n",
    "    ['Mexico', 19.2, -99.1],\n",
    "    ['Netherlands', 52.23, 4.54],\n",
    "    ['New Zealand', -41.19, 174.46],\n",
    "    ['Nicaragua', 12.06, -86.2],\n",
    "    ['Peru', -12.0, -77.0],\n",
    "    ['Philippines', 14.4, 121.03],\n",
    "    ['Poland', 52.13, 21.0],\n",
    "    ['Portugal', 38.42, -9.1],\n",
    "    ['Puerto Rico', 18.28, -66.07],\n",
    "    ['Russia', 61.52, 105.32],\n",
    "    ['Sao Tome', 0.19, 6.61],\n",
    "    ['Scotland', 56.49, 4.2],\n",
    "    ['Singapore', 1.35, 103.82],\n",
    "    ['South Africa', -25.44, 28.12],\n",
    "    ['South Korea', 35.91, 127.77],\n",
    "    ['Spain', 40.25, -3.45],\n",
    "    ['St. Lucia', 13.91, -60.98],\n",
    "    ['Suriname', 5.5, -55.1],\n",
    "    ['Sweden', 59.2, 18.03],\n",
    "    ['Switzerland', 46.57, 7.28],\n",
    "    ['U.S.A.', 39.91, -77.02],\n",
    "    ['Venezuela', 10.3, -66.55],\n",
    "    ['Vietnam', 14.06, 108.28],\n",
    "    ['Wales', 52.13, -3.78],\n",
    "  ], columns=['Country', 'Latitude', 'Longitude'])\n",
    "\n",
    "  df = pd.merge(df, country_df, left_on='Company Location', right_on='Country')\n",
    "  return df\n",
    "\n",
    "df = reload_data_plus_latlong()\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RtPDGc3I-KH"
   },
   "source": [
    "Given this new geographical data, we can now scatter plot the mean ratings data for each country onto the country's latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1pnKKrsEGiE"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = reload_data_plus_latlong()\n",
    "\n",
    "mean_ratings_df = df.groupby(['Latitude', 'Longitude'],\n",
    "                             as_index=False).mean()\n",
    "mean_ratings_df = mean_ratings_df[['Latitude', 'Longitude', 'Rating']]\n",
    "\n",
    "_ = sns.scatterplot(x='Longitude', y='Latitude', data=mean_ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmTsMt-KKRB5"
   },
   "source": [
    "#### Exercise 6: More Meaningful Scatter Plots\n",
    "\n",
    "We just added in geographical data in order to scatter plot our ratings onto a \"map\", but the plot isn't very meaningful. From the plots we can somewhat make out Europe and South America, but we don't really know if they produce high-quality chocolates.\n",
    "\n",
    "In this exercise you will add visual cues to the scatter plot to indicate the relative quality of chocolate produced by each country. Check out the [`seaborn.scatterplot()` documentation](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) and find arguments that you can pass to `seaborn.scatterplot()` that will call out the good chocolate from the bad by changing the size and color of the dots on the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E12id18ZLFGe"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYmAzq1CMFNi"
   },
   "outputs": [],
   "source": [
    "# Your Solution Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2a4Lrg3MG_I"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7N2EuunjyJ5n"
   },
   "source": [
    "### Finding Facts About the Data\n",
    "\n",
    "We've created some nice visualizations to explore our data. Sometimes, you might just want textual information. In this section we'll use `Pandas` to answer a few questions about our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mYFUFJT5ECIH"
   },
   "source": [
    "We might want to find the companies with the highest average ratings. To do this we can group our data by 'Company', find the mean rating, and print out only the top rated companies. We'll do this just using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFwZizQfETbM"
   },
   "outputs": [],
   "source": [
    "df.groupby('Company')[['Rating']].mean().sort_values(by='Rating').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRfvCCnuJPsq"
   },
   "source": [
    "We can use grouping and index selection to answer questions like: *How many companies produce, on average, worse than the overall mean rated chocolates?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQ-ZM7zAEvZt"
   },
   "outputs": [],
   "source": [
    "# Find the overall mean rating\n",
    "mean_rating = df['Rating'].mean()\n",
    "\n",
    "# Find each company's mean rating\n",
    "mean_ratings_by_company = df.groupby('Company',\n",
    "                                     as_index=False)[['Rating']].mean()\n",
    "\n",
    "# See how many of those ratings are below the mean\n",
    "mean_ratings_by_company[mean_ratings_by_company['Rating'] < mean_rating]['Company'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBV-0VPlKQka"
   },
   "source": [
    "#### Exercise 7: Highest Rated Companies With Many Reviews\n",
    "\n",
    "Earlier we found the companies with the highest mean rating, but some of those companies only have one or two reviews. For this exercise find five highest-mean rated companies with at least five reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJP0GqHHNiC0"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQTPDtqwNkyX"
   },
   "outputs": [],
   "source": [
    "# Your Code Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cFocDu5NnI4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qZbZgDNoOqFC"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "blB7c1ZpOsKY"
   },
   "source": [
    "Congratulations. You have now taken a dataset with missing and messy values, cleaned it up, and examined the data through visualization and through Pandas queries.\n",
    "\n",
    "This exploratory data analysis and data preprocessing is a very important step in data science and machine learning. Knowing how to use machine learning models is important, but if you want to model data properly, it is just as important that you understand your data well."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "copyright",
    "6PECS1ohB0r6",
    "8S_TJhJuBujB",
    "vu0HqS7duv2l",
    "zuNhoRa6MHyZ"
   ],
   "include_colab_link": true,
   "name": "Exploratory Data Analysis: Part 2 - Analysis and Visualizations",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
