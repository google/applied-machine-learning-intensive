{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/google/applied-machine-learning-intensive/blob/master/content/02_data/02_intermediate_pandas/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRh9gZN5NnoA"
   },
   "source": [
    "####Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqxbnlgPNozU"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZtwR4AUmERg"
   },
   "source": [
    "# Intermediate Pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a powerful Python library for working with data. For this lab, you should already know what a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) and [Series](https://pandas.pydata.org/pandas-docs/stable/reference/series.html) are and how to do some simple analysis of the data contained in those structures.\n",
    "\n",
    "In this lab we'll look at some more advanced capabilities of Pandas, such as filtering, grouping, merging, and sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSPe_A_RQIPU"
   },
   "source": [
    "## DataFrame Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBbMQ-Mnl_ys"
   },
   "source": [
    "`DataFrame` objects are rich containers that allow us to explore and modify data. In this lab we will learn powerful techniques for working with the data contained in `DataFrame` objects.\n",
    "\n",
    "To begin, let's create a `DataFrame` containing information about populations and airports in a few select cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xy6gwtEvJhuj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airport_df = pd.DataFrame.from_records((\n",
    "  ('Atlanta', 498044, 2),\n",
    "  ('Austin', 964254, 2),\n",
    "  ('Kansas City',  491918, 8),\n",
    "  ('New York City', 8398748, 3),\n",
    "  ('Portland', 653115, 1),\n",
    "  ('San Francisco', 883305, 3),\n",
    "  ('Seattle', 744955, 2),\n",
    "), columns=(\"City Name\", \"Population\", \"Airports\"))\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9xkHrhvirQZ"
   },
   "source": [
    "If you aren't familiar with the `from_records()` method, it is a way to create a `DataFrame` from data formatted in a tabular manner. In this case we have a tuple-of-tuples where each inner-tuple is a row of data for a city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiJbWvWlplO7"
   },
   "source": [
    "### Shape\n",
    "\n",
    "One interesting fact about a `DataFrame` is its shape. What is shape?\n",
    "\n",
    "Shape is the number of rows and columns contained in the dataframe.\n",
    "\n",
    "Let's find the shape of the `airport_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uogKNp6YnQuN"
   },
   "outputs": [],
   "source": [
    "airport_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nacr3tyxp-KN"
   },
   "source": [
    "The `DataFrame` has a shape of `(7, 3)`.\n",
    "\n",
    "This means that the `DataFrame` has seven rows and three columns.\n",
    "\n",
    "If you are familiar with [NumPy](http://numpy.org), you probably are also familiar with `shape`. `NumPy` arrays can have n-dimensional shapes while `DataFrame` objects tend to stick to two dimensions: rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvXVgSZh_AyF"
   },
   "source": [
    "#### Exercise 1: Finding Shape\n",
    "\n",
    "Download the California housing data referenced below into a `DataFrame`, and print out the shape of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZYNh_sk_cgj"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WB0AE8Cb-0Cx"
   },
   "outputs": [],
   "source": [
    "url = \"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\"\n",
    "\n",
    "# Download the housing data\n",
    "\n",
    "# Print the shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Pw1Aw7jXAwZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgAd9Zo83sWQ"
   },
   "source": [
    "### Columns\n",
    "\n",
    "Speaking of columns, it's possible to ask a `DataFrame` what columns it contains using the `columns` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tam4t-l8nsZk"
   },
   "outputs": [],
   "source": [
    "airport_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzTuZeWV35hu"
   },
   "source": [
    "Notice that the columns are contained in an `Index` object. An `Index` wraps the list of columns. For basic usage, like loops, you can just use the `Index` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1d4Cn6f-3_Sj"
   },
   "outputs": [],
   "source": [
    "for c in airport_df.columns:\n",
    "  print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GphYBOj3-hD"
   },
   "source": [
    "If you do need the columns in a lower level format, you can use `.values` to get a `NumPy` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGqGoVhq4MeV"
   },
   "outputs": [],
   "source": [
    "type(airport_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bt0CLEp04hVS"
   },
   "source": [
    "If you need a basic Python list, you can then call `.tolist()` to get the core Python list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iztav3ht4oxn"
   },
   "outputs": [],
   "source": [
    "type(airport_df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Kq758-PABWw"
   },
   "source": [
    "#### Exercise 2: Pretty Print Columns\n",
    "\n",
    "The columns in the California housing dataset are not necessarily easy on the eyes. Columns like `housing_median_age` would be easier to read if they were presented as `Housing Median Age`.\n",
    "\n",
    "In the code block below, download the California housing dataset. Then find the names of the columns in the dataset and convert them from \"snake case\" to regular English.  For instance `housing_median_age` becomes `Housing Median Age` and `total_rooms` becomes `Total Rooms`. Print the human-readable names one per line. You can find Python string methods that might be helpful [here](https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str).\n",
    "\n",
    "Write your code in a manner that it could handle any column name in \"snake case\": Underscores should be replaced by spaces. The first letter of each word should be capitalized.\n",
    "\n",
    "Be sure to get the column names from the `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PTP9f0xA-7I"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8-9eI3oBBQj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Your Code Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LuijNhGgXGgH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcHixEI54DPi"
   },
   "source": [
    "### Missing Values\n",
    "\n",
    "It is common to find datasets with missing data. When this happens it's good to know that the data is missing so you can determine how to handle the situation.\n",
    "\n",
    "Let's recreate our city data but set some values to `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1x2RigRT4Kqv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airport_df = pd.DataFrame.from_records((\n",
    "  ('Atlanta', 498044, 2),\n",
    "  (None, 964254, 2),\n",
    "  ('Kansas City',  491918, 8), \n",
    "  ('New York City', None, 3),\n",
    "  ('Portland', 653115, 1),\n",
    "  ('San Francisco', 883305, None),\n",
    "  ('Seattle', 744955, 2),\n",
    "), columns=(\"City Name\", \"Population\", \"Airports\"))\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-KRSoq7e4nxA"
   },
   "source": [
    "You can see that the population of New York and the number of airports in San Francisco are now represented by `NaN` values. This stands for 'Not a Number', which means that the value is an unknown numeric value. You'll also see that where 'Austin' once was, we now have a `None` value. This means that we are missing a non-numeric value.\n",
    "\n",
    "If we want to ask the `DataFrame` what values are present or missing, we can use the `isna()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoDDdI6c5P16"
   },
   "outputs": [],
   "source": [
    "airport_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI0SXsne5SWp"
   },
   "source": [
    "Here we get `True` values where a data point is missing and `False` values where we have data.\n",
    "\n",
    "Using this, we can do powerful things like select all columns with populations or airports that have missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyDD_HWY5eri"
   },
   "outputs": [],
   "source": [
    "airport_df[airport_df['Population'].isna() | airport_df['Airports'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlDu7LZl5zqk"
   },
   "source": [
    "Now that we know that we are missing the population of New York and the number of airports in San Francisco, we can look up that data and manually fix it.\n",
    "\n",
    "Sometimes the fixes aren't so easy. The data might be impossible to find, or there might be so many missing values that you can't individually fix them all.\n",
    "\n",
    "In these cases you have two options: completely remove the offending rows or columns or patch the data in some way. Throughout this course we will work with many datasets that have missing or obviously invalid values, and we will discuss mitigation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdciSvRDqcEk"
   },
   "source": [
    "## Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EaUx6GAreMu"
   },
   "source": [
    "Filtering is an important concept in data analysis and processing. When you think of filtering in the real world, you likely think of an object that blocks undesired things while allowing desired things to pass through.\n",
    "\n",
    "Imagine a coffee filter. It stops the coffee grounds from getting into the coffee pot, but it allows the water bound to coffee's chemical compounds to pass through into your perfect brew.\n",
    "\n",
    "Filtering a `DataFrame` is similar. A `DataFrame` contains rows of data. Some of these rows might be important to you, and some you might want to discard. Filtering allows you select only the data that you care about and put that data in a new `DataFrame`.\n",
    "\n",
    "In the example below, we filter our `airport_df` to select only cities that have more than two airports. In return we get a `DataFrame` that contains only information about cities that have more than two airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG9MD0F2sQ1K"
   },
   "outputs": [],
   "source": [
    "airport_df[airport_df['Airports'] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLw910vesx28"
   },
   "source": [
    "Let's deconstruct this statement. At its core we have:\n",
    "\n",
    "```python\n",
    "airport_df['Airports'] > 2\n",
    "```\n",
    "\n",
    "This expression compares every 'Airports' value in the `airport_df` `DataFrame` and returns `True` if there are more than two airports, `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwYDdc8bMewA"
   },
   "outputs": [],
   "source": [
    "airport_df['Airports'] > 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3LGIAKDMxta"
   },
   "source": [
    "This data is returned as a Pandas `Series`. The series is then used as a boolean index for the `airport_df` the `DataFrame`.\n",
    "\n",
    "**Boolean index** is just a term used to refer to a `Series` (or other list-like structure) of boolean values used in the index operator, `[]`, for the `DataFrame`. Ideally the boolean index length should be equal to the number of rows in the `DataFrame` being indexed. `DataFrame` rows that map to `True` values in the index are retained, while rows that map to `False` values are filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7aul282NAMH"
   },
   "outputs": [],
   "source": [
    "has_many_airports = airport_df['Airports'] > 2\n",
    "\n",
    "airport_df[has_many_airports]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toPxH8YUOLDC"
   },
   "source": [
    "If you are familiar with Boolean logic and Python, you probably know that you can create compound expressions using the `or` and `and` keywords. You can also use the keyword `not` to reverse an expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF6tfJQCtMRr"
   },
   "outputs": [],
   "source": [
    "print(True and False)\n",
    "print(True or False)\n",
    "print(not True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bj8LEytmwBAU"
   },
   "source": [
    "You can do similar things in Pandas with boolean indices. However, `and`, `or`, and `not` don't work as expected. Instead you need to use the `&`, `|`, and `!` operators.\n",
    "\n",
    "- `and` changes to `&`\n",
    "- `or` changes to `|`\n",
    "- `not` changes to `!`\n",
    "\n",
    "For normal numbers in Python, these are actually the 'bitwise logical operators'. When working on Pandas objects, these operators don't perform bitwise calculations but instead perform Boolean logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTft1GCVPOoz"
   },
   "source": [
    "Let's see this in action with an example. Imagine we want to find all cities with more than two airports and less than a million inhabitants. First, let's find the rows with more than two airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uoFFVmGXPVZ1"
   },
   "outputs": [],
   "source": [
    "has_many_airports = airport_df['Airports'] > 2\n",
    "has_many_airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETWeK941P-9p"
   },
   "source": [
    "Now we can find the rows that represent a city with less than a million residents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inVE7JULQRR7"
   },
   "outputs": [],
   "source": [
    "small_cities = airport_df['Population'] < 1000000\n",
    "small_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvUSkBt3QdhP"
   },
   "source": [
    "We can then combine `has_many_airports` with `small_cities` to find small cities with a large number of airports.\n",
    "\n",
    "To do this we first need to use the `&` operator to combine the two Boolean tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vxs4Y8IwtT0"
   },
   "outputs": [],
   "source": [
    "small_but_flighty = has_many_airports & small_cities\n",
    "small_but_flighty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrLRsLeXQy2M"
   },
   "source": [
    "We can use this boolean index to select the rows from the original `DataFrame` that contain data about cities with fewer than one million residents and more than two airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkKcM5NPRLLk"
   },
   "outputs": [],
   "source": [
    "airport_df[small_but_flighty]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWQJW8xPQ_No"
   },
   "source": [
    "In this example we broke the filter down into many steps. It could actually be performed in one expression as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Mhp076pQv0b"
   },
   "outputs": [],
   "source": [
    "airport_df[(airport_df['Airports'] > 2) & (airport_df['Population'] < 1000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aiPlnHeORWKE"
   },
   "source": [
    "Notice the need for parenthesis around each Boolean expression. This is because `&` has a higher precedence than `>` and `<`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YkFnQx9Kw6oL"
   },
   "source": [
    "The term 'filtering' is typically used when talking about rows of data. However, it is possible to filter out columns of a dataset. To filter columns simply list the columns that you do want to keep in a `list` and pass it to the `DataFrame` selector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFqGfRRJQ7Kp"
   },
   "outputs": [],
   "source": [
    "population_df = airport_df[['City Name', 'Population']]\n",
    "\n",
    "population_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unUW_uDUZ-0q"
   },
   "source": [
    "If a dataset has many columns, it might be easier to exclude a column using a list expansion instead of explicitly listing many columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiBtFKUWZXSV"
   },
   "outputs": [],
   "source": [
    "population_df = airport_df[\n",
    "  [col for col in airport_df.columns if col is not 'Airports']]\n",
    "\n",
    "population_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b4Pw5dYad9e"
   },
   "source": [
    "This works for multiple columns also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mi5bmUWoagX8"
   },
   "outputs": [],
   "source": [
    "population_df = airport_df[\n",
    "  [col for col in airport_df.columns if col not in {'Airports', 'Population'}]]\n",
    "\n",
    "population_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIP0T0ZdX-o3"
   },
   "source": [
    "### Exercise 3: SoCal\n",
    "\n",
    "Using the California housing `DataFrame` from the previous unit, make a new `DataFrame` that only contains data from the southern part of California. What is 'southern'? For the purpose of this exercise, let's say that southern California includes everything below 36 degrees latitude. \n",
    "\n",
    "Create a new `DataFrame` called `socal_df` containing only data points below the 36 latitude. Then print out the shape of that `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgmmbVmmcK17"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoyOJDagZRRp"
   },
   "outputs": [],
   "source": [
    "url = \"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\"\n",
    "cali_df = pd.read_csv(url)\n",
    "\n",
    "# Your Code Goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_G3TvXRXLjY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRBFJi0qS38z"
   },
   "source": [
    "##Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nv1ObGUeS6OB"
   },
   "source": [
    "We can also aggregate `DataFrame` objects by grouping rows of data together.\n",
    "\n",
    "For our examples we will create a `DataFrame` containing the ages, heights, and weights of a sample of children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOOJZjqDUNYb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "body_measurement_df = pd.DataFrame.from_records((\n",
    "  (2, 83.82, 8.4),\n",
    "  (4, 99.31, 16.97),\n",
    "  (3, 96.52, 14.41),\n",
    "  (6, 114.3, 20.14),\n",
    "  (4, 101.6, 16.91),\n",
    "  (2, 86.36, 12.64),\n",
    "  (3, 92.71, 14.23),\n",
    "  (2, 85.09, 11.11),\n",
    "  (2, 85.85, 14.18),\n",
    "  (5, 106.68, 20.01),\n",
    "  (4, 99.06, 13.17),\n",
    "  (5, 109.22, 15.36),\n",
    "  (4, 100.84, 14.78),\n",
    "  (6, 115.06, 20.06),\n",
    "  (2, 84.07, 10.02),\n",
    "  (7, 121.67, 28.4),\n",
    "  (3, 94.49, 14.05),\n",
    "  (6, 116.59, 17.55),\n",
    "  (7, 121.92, 22.96),\n",
    "), columns=(\"Age (yrs)\", \"Height (cm)\", \"Weight (kg)\"))\n",
    "\n",
    "body_measurement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-CJqrV2usfEw"
   },
   "source": [
    "As you can see, we have a fairly low-level dump of data. It is unsorted and is generally difficult to gain any insight from. We could group the data by age and find metrics such as the count, max, min, mean, median, and more. This information might be more easy to analyze.\n",
    "\n",
    "In order to do this grouping, we use the `groupby` method on the `DataFrame`.\n",
    "\n",
    "For instance, if we wanted to know the mean values for the columns for each year of age, we could run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwdzP6gTWT_h"
   },
   "outputs": [],
   "source": [
    "body_measurement_df.groupby('Age (yrs)').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-JbY4OzW5Ds"
   },
   "source": [
    "We get a `DataFrame` sorted by the column that we chose to group by. The 'Height (cm)' and 'Weight (kg)' columns now represent the mean height and weight for each age represented in our dataset.\n",
    "\n",
    "Looking at this data, you can now see a steady increase in height and weight as age increases, which is what you are likely to expect.\n",
    "\n",
    "You might notice here that the 'Age (yrs)' column looks a little different. It is now not a regular column, but is instead an index column.\n",
    "\n",
    "Let's see what this means by saving the grouped data into a new `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bME3NRjzdskw"
   },
   "outputs": [],
   "source": [
    "mean_body_measurement_df = body_measurement_df.groupby('Age (yrs)').mean()\n",
    "\n",
    "mean_body_measurement_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QE7b6thod1vo"
   },
   "source": [
    "You'll notice that 'Age (yrs)' is no longer listed as a column. In order to access the age you instead have to use the `.index` property of the `DataFrame`.\n",
    "\n",
    "Note that we get an `Int64Index` object back and not a `Series` as we would if we referenced a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyV4hb42eBhf"
   },
   "outputs": [],
   "source": [
    "mean_body_measurement_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ySz5KfpdbBx"
   },
   "source": [
    "\n",
    "We aren't restricted to just using `mean()`. There are many other aggregate functions that we could use, including `max()`, which gives us the largest sample in each grouping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWWI17h5cKGy"
   },
   "outputs": [],
   "source": [
    "body_measurement_df.groupby('Age (yrs)').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpOjED6FcNFA"
   },
   "source": [
    "And `min()` which gives the smallest value in each grouping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En439mp5cQ8y"
   },
   "outputs": [],
   "source": [
    "body_measurement_df.groupby('Age (yrs)').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBy8K-w4cTvU"
   },
   "source": [
    "There are many other aggregate functions. You can see the entire list in the [`GroupBy` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRSPayIbP5b1"
   },
   "source": [
    "Sometimes performing a single aggregation across all columns is limiting. What if you want the mean of one column and the max of another? What if you want to perform multiple aggregations on one column?\n",
    "\n",
    "You can perform different and multiple aggregations using the `agg()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S76LCG4eQXKr"
   },
   "outputs": [],
   "source": [
    "body_measurement_df.groupby('Age (yrs)').agg({\n",
    "    'Height (cm)': 'mean',\n",
    "    'Weight (kg)': ['max', 'min'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKN9RN8SpyYV"
   },
   "source": [
    "As you can see, `agg()` accepts a dictionary. The keys are the columns that you want to aggregate. The values are either a single aggregation function name or lists of aggregation function names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ye5dnYuqBY0"
   },
   "source": [
    "### Exercise 4: Grouping\n",
    "\n",
    "Given the body measurement dataset in a `DataFrame`, group the data by 'Age (yrs)' and find the following aggregations using the `agg()` function:\n",
    "\n",
    "* 'Age (yrs)' count\n",
    "* 'Height (cm)' min\n",
    "* 'Height (cm)' max\n",
    "* 'Height (cm)' mean\n",
    "* 'Height (cm)' standard deviation\n",
    "* 'Weight (kg)' min\n",
    "* 'Weight (kg)' max\n",
    "* 'Weight (kg)' mean\n",
    "* 'Weight (kg)' standard deviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnP-BOCMrS3j"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVEHgjt_rVro"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "body_measurement_df = pd.DataFrame.from_records((\n",
    "  (2, 83.82, 8.4),\n",
    "  (4, 99.31, 16.97),\n",
    "  (3, 96.52, 14.41),\n",
    "  (6, 114.3, 20.14),\n",
    "  (4, 101.6, 16.91),\n",
    "  (2, 86.36, 12.64),\n",
    "  (3, 92.71, 14.23),\n",
    "  (2, 85.09, 11.11),\n",
    "  (2, 85.85, 14.18),\n",
    "  (5, 106.68, 20.01),\n",
    "  (4, 99.06, 13.17),\n",
    "  (5, 109.22, 15.36),\n",
    "  (4, 100.84, 14.78),\n",
    "  (6, 115.06, 20.06),\n",
    "  (2, 84.07, 10.02),\n",
    "  (7, 121.67, 28.4),\n",
    "  (3, 94.49, 14.05),\n",
    "  (6, 116.59, 17.55),\n",
    "  (7, 121.92, 22.96),\n",
    "), columns=(\"Age (yrs)\", \"Height (cm)\", \"Weight (kg)\"))\n",
    "\n",
    "body_measurement_df\n",
    "\n",
    "# Your Solution Goes Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fkrClixratI"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ad_H5eYvTDba"
   },
   "source": [
    "##Merging Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cW4jfRDgTn-T"
   },
   "source": [
    "It is common for related data to be stored in different locations. When this happens you sometimes need to merge the data into a single `DataFrame` in order to work with all of the data in an easy manner.\n",
    "\n",
    "Let's take a look at some data about popular desserts. First, we have nutritional information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtgzWRngsvjy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nutrition_information_df = pd.DataFrame.from_records((\n",
    "  ('Cupcake', 178, 5.26, 32.54, 1.37),\n",
    "  ('Donut', 190, 10.51, 21.62, 2.62),\n",
    "  ('Eclair', 267, 16.01, 24.68, 6.53),\n",
    "  ('Froyo', 214, 2.94, 39.24, 9.4),\n",
    "  ('Gingerbread', 130, 5, 19, 2),\n",
    "  ('Honeycomb', 190, 13, 23, 2),\n",
    "  ('Ice Cream Sandwich', 143, 5.6, 21.75, 2.61),\n",
    "  ('Jelly Bean', 100, 0, 25, 0),\n",
    "  ('KitKat', 210, 11, 27, 3),\n",
    "  ('Lollipop', 110, 0, 28, 0),\n",
    "  ('Marshmallow', 100, 0, 24, 1),\n",
    "  ('Nougat', 56, 0.23, 12.93, 0.47),\n",
    "  ('Oreo', 160, 7, 25, 1),\n",
    "  ('Pie', 356, 16.5, 51, 2.85),\n",
    "), columns=('Name', 'Calories', 'Fat (g)', 'Carbs (g)', 'Protein (g)'))\n",
    "\n",
    "nutrition_information_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10ezmFWFx5Tf"
   },
   "source": [
    "We also have data about the manufacturing costs and the retail price of each of the desserts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f032gQPx54K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "costs_df = pd.DataFrame.from_records((\n",
    "  ('Cupcake', 1.24, 4.50),\n",
    "  ('Donut', 0.17, 0.99),\n",
    "  ('Eclair', 0.54, 2.50),\n",
    "  ('Froyo', 0.78, 3.50),\n",
    "  ('Gingerbread', 0.45, 0.99),\n",
    "  ('Honeycomb', 1.25, 3.00),\n",
    "  ('Ice Cream Sandwich', 1.21, 2.99),\n",
    "  ('Jelly Bean', 0.04, 0.99),\n",
    "  ('KitKat', 0.33, 1.50),\n",
    "  ('Lollipop', 0.11, 1.10),\n",
    "  ('Marshmallow', 0.03, 0.50),\n",
    "  ('Nougat', 0.75, 1.50),\n",
    "  ('Oreo', 0.78, 2.00),\n",
    "  ('Pie', 0.66, 2.25),\n",
    "), columns=('Name', 'Manufacturing (USD)', 'Retail (USD)'))\n",
    "\n",
    "costs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azvf4DpSzZTJ"
   },
   "source": [
    "If we want to combine the data into a single `DataFrame`, we can merge the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wI3fvRedzglL"
   },
   "outputs": [],
   "source": [
    "pd.merge(nutrition_information_df, costs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPX3cFqSzf_N"
   },
   "source": [
    "[Pandas](https://pandas.pydata.org) searches for columns with the same name and uses those columns to match rows of data. The result is a single `DataFrame` with columns from the merged `DataFrame` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBUwl36Lz667"
   },
   "source": [
    "What if we have yet another `DataFrame` that contains the inventory of desserts that we have in stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPu2L2zjPIcE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inventory_df = pd.DataFrame.from_records((\n",
    "  ('Marshmallow', 1004),\n",
    "  ('Nougat', 563),\n",
    "  ('Oreo', 789),\n",
    "  ('Pie', 33),\n",
    "), columns=('Name', '# In Stock'))\n",
    "\n",
    "inventory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkjR0rgT0SGJ"
   },
   "source": [
    "If we want to join our inventory with our cost data to see how much earning potential we have in stock, we can join the `costs_df` with the `inventory_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SFLiozsz0j5n"
   },
   "outputs": [],
   "source": [
    "pd.merge(costs_df, inventory_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AST2N2HAWao_"
   },
   "source": [
    "If we wanted we could then sum up our retail prices multiplied by inventory to see how much gross revenue potential we currently have.\n",
    "\n",
    "Notice that we only have four desserts. What happened?\n",
    "\n",
    "By default when merging `DataFrame` objects only rows that match across `DataFrame` objects are returned. Non-matching rows are filtered out.\n",
    "\n",
    "We can change this by telling `merge` to do an *outer* join. This will keep all of the data in the first `DataFrame` passed to `merge()` and fill in any missing data with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eDf58qQ1JNS"
   },
   "outputs": [],
   "source": [
    "pd.merge(costs_df, inventory_df, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9d6GZp8_1c44"
   },
   "source": [
    "There are many options for merging data. You have options available to keep rows in specific `DataFrames`, to use different columns to join on, and much more. Check out the [`merge` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKfkT-3b11MP"
   },
   "source": [
    "### Exercise 5: Merging `DataFrame` Objects\n",
    "\n",
    "In this exercise we will answer a few questions about our dessert-making operation. In order to answer these questions, you are provided with the `costs_df` `DataFrame`, which contains names of treats and costs related to them.\n",
    "\n",
    "The columns are:\n",
    "  * **Name**: The name of the treat.\n",
    "  * **Manufacturing (USD)**: The cost in United States dollars to create one saleable unit of the treat.\n",
    "  * **Retail (USD)**: The price that one serving of the treat is sold for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2cyoyBi19km"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "costs_df = pd.DataFrame.from_records((\n",
    "  ('Cupcake', 1.24, 4.50),\n",
    "  ('Donut', 0.17, 0.99),\n",
    "  ('Eclair', 0.54, 2.50),\n",
    "  ('Froyo', 0.78, 3.50),\n",
    "  ('Gingerbread', 0.45, 0.99),\n",
    "  ('Honeycomb', 1.25, 3.00),\n",
    "  ('Ice Cream Sandwich', 1.21, 2.99),\n",
    "  ('Jelly Bean', 0.04, 0.99),\n",
    "  ('KitKat', 0.33, 1.50),\n",
    "  ('Lollipop', 0.11, 1.10),\n",
    "  ('Marshmallow', 0.03, 0.50),\n",
    "  ('Nougat', 0.75, 1.50),\n",
    "  ('Oreo', 0.78, 2.00),\n",
    "  ('Pie', 0.66, 2.25),\n",
    "), columns=('Name', 'Manufacturing (USD)', 'Retail (USD)'))\n",
    "\n",
    "costs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rowTBXyvBYSt"
   },
   "source": [
    "The other `DataFrame` that we have at our disposal is the `inventory_df`. This `DataFrame` contains information about how many of each type of treat we have in stock and ready to sell.\n",
    "\n",
    "The columns are:\n",
    "  * **Name**: The name of the treat.\n",
    "  * **# In Stock**: The number of saleable units of the treat that we have.\n",
    "\n",
    "Any treats not in inventory are assumed to be out of stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzBZ_Id-BxlA"
   },
   "outputs": [],
   "source": [
    "inventory_df = pd.DataFrame.from_records((\n",
    "  ('Marshmallow', 1004),\n",
    "  ('Nougat', 563),\n",
    "  ('Oreo', 789),\n",
    "  ('Pie', 33),\n",
    "), columns=('Name', '# In Stock'))\n",
    "\n",
    "inventory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVl-zbWdB_fZ"
   },
   "source": [
    "#### Question 1: Potential Profit\n",
    "\n",
    "For this question we want to determine the potential profit that we can make with the items that we have in stock.\n",
    "\n",
    "> $profit = \\Sigma^{t}_{i=1} n * (r - m)$\n",
    "\n",
    "Where:\n",
    "\n",
    " * `t` is every type of treat in stock\n",
    " * `n` is the number of units of that treat\n",
    " * `r` is the retail price of the treat\n",
    " * `m` are the manufacturing costs for the treat\n",
    "\n",
    "Merge `inventory_df` and `costs_df` to calculate the `potential_profit`. Print out the potential profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbzRwtslDffl"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdGsNRwEDo6E"
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrame objects\n",
    "dessert_df = None\n",
    "\n",
    "# Calculate potential profit\n",
    "potential_profit = None \n",
    "\n",
    "# Print the potential profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2oQr9gO0DiLd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3iYAPQFmET5i"
   },
   "source": [
    "#### Question 2: Restocking Cost\n",
    "\n",
    "There are only four different treats available for sale. We need to get some more inventory in this shop!\n",
    "\n",
    "In this portion of the exercise we will calculate the total cost to get 100 units of each of the missing treats onto the shelves and ready to sale.\n",
    "\n",
    "The cost is calculated with:\n",
    "\n",
    "> $cost = \\Sigma^{t}_{i=1} 100 * m$\n",
    "\n",
    "Where:\n",
    "\n",
    " * `t` is every type of treat **NOT** in stock\n",
    " * `100` is the number of units of that treat that we'd like to make\n",
    " * `m` are the manufacturing costs for the treat\n",
    "\n",
    "Merge `inventory_df` and `costs_df` to calculate the `cost_to_make`. Print out the cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8Lp0EZKFSem"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fz6X8h3nFUZH"
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrame objects\n",
    "dessert_df = None\n",
    "\n",
    "# Identify the missing desserts\n",
    "missing_dessert_df = None\n",
    "\n",
    "# Calculate the cost to make 100 of each of the missing treats\n",
    "cost_to_make = None\n",
    "\n",
    "# Print the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBnaj4YXFpPS"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IPzZkHyW8G8"
   },
   "source": [
    "##Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YShTCy0DXB4o"
   },
   "source": [
    "It is often important to sort data in order to visually examine the data for patterns and anomalies. Luckily this is easy to do in Pandas.\n",
    "\n",
    "To start off, let's build a `DataFrame` to sort. For this example we will use a `DataFrame` containing information about cities, their populations, and the number of airports in-and-around the cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3A50pJfEWlYS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airport_df = pd.DataFrame.from_records((\n",
    "  ('Atlanta', 498044, 2),\n",
    "  ('Austin', 964254, 2),\n",
    "  ('Kansas City',  491918, 8),\n",
    "  ('New York City', 8398748, 3),\n",
    "  ('Portland', 653115, 1),\n",
    "  ('San Francisco', 883305, 3),\n",
    "  ('Seattle', 744955, 2),\n",
    "), columns=(\"City Name\", \"Population\", \"Airports\"))\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLvx7DVxI4ZG"
   },
   "source": [
    "The data seems to be sorted by `City Name`. If we want to sort the data by `Population` we can use the `sort_values()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZvMTrfEIj8I"
   },
   "outputs": [],
   "source": [
    "airport_df.sort_values('Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZ_hpCdCX0My"
   },
   "source": [
    "We can see that Kansas City is the smallest city in our dataset, and New York City is the largest.\n",
    "\n",
    "If you were thinking, *Why does Kansas City have so many airports?*, good for you!\n",
    "\n",
    "This is one of the benefits we can get from viewing our data in different sorting orders. We can see that the smallest city by population has the largest number of airports. This doesn't seem right.\n",
    "\n",
    "If we were going to be using this dataset for an actual data science project, we would want to investigate this further. We could:\n",
    "\n",
    " * Verify that Kansas City actually does have 8 airports\n",
    " * Verify that a few of the other cities, especially the larger ones, have so few airports\n",
    " * Look into how the data was collected to see if the count for Kansas City was collected differently:\n",
    "   * Does it contain regional airports while others do not?\n",
    "   * What counts as an airport for the city? Farm landing strips? Military bases?\n",
    "   * How close to a city does an airport need to be to be considered an airport for that city?\n",
    "\n",
    "You can probably think of many more questions to ask about the data and how it was collected.\n",
    "\n",
    "When you see something that looks odd in your data, ask questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "146W-B21Knnx"
   },
   "source": [
    "For now, let's get back to sorting. What if we wanted to sort by more than one column?\n",
    "\n",
    "For instance, we can sort by the number of airports in a city and then by population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2p-lwv-K2OY"
   },
   "outputs": [],
   "source": [
    "airport_df.sort_values(['Airports', 'Population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQMkNutAK18b"
   },
   "source": [
    "Using this we can now answer questions such as *What is the smallest city with two airports?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrmeRDWjLNe6"
   },
   "source": [
    "Notice that although we sorted the `DataFrame`, we didn't actually change the `DataFrame` itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pc9ErSKyLUbC"
   },
   "outputs": [],
   "source": [
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yURJft1iLT-D"
   },
   "source": [
    "If we do want to save the sort order we can assign the return value of `sort_values()` to another variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3hVozogaX3s"
   },
   "outputs": [],
   "source": [
    "sorted_airport_df = airport_df.sort_values(['Airports', 'Population'])\n",
    "\n",
    "sorted_airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ah3Y8joadBz"
   },
   "source": [
    "But this doesn't modify the original `DataFrame`. To do that, use the `inplace` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLbqP39Caj9F"
   },
   "outputs": [],
   "source": [
    "airport_df.sort_values(['Airports', 'Population'], inplace=True)\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3Nwr9urap49"
   },
   "source": [
    "## References and Copies\n",
    "\n",
    "Both [Python](https://python.org) and [Pandas](https://pandas.pydata.org) strive to hide lower-level programming details from you whenever they can. However, there are some cases where you do have to be aware of how your data is being managed.\n",
    "\n",
    "One place where this often happens is when Pandas is working indirectly with with a `DataFrame`.\n",
    "\n",
    "We'll walk through some examples using the airport data we have seen many times in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmmhdg7mbAcB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airport_df = pd.DataFrame.from_records((\n",
    "  ('Atlanta', 498044, 2),\n",
    "  ('Austin', 964254, 2),\n",
    "  ('Kansas City',  491918, 8),\n",
    "  ('New York City', 8398748, 3),\n",
    "  ('Portland', 653115, 1),\n",
    "  ('San Francisco', 883305, 3),\n",
    "  ('Seattle', 744955, 2),\n",
    "), columns=(\"City Name\", \"Population\", \"Airports\"))\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oq6aHv2sdmNj"
   },
   "source": [
    "We'll start simple and assign the `airport_df` to another variable, `airport_df2`. We then try to double the number of airports in `airport_df2`.\n",
    "\n",
    "What happens to `airport_df` and `airport_df2`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbqbCEzFbBsw"
   },
   "outputs": [],
   "source": [
    "airport_df2 = airport_df\n",
    "\n",
    "airport_df2.loc[:, 'Airports'] *= 2\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPoGJwMieOtH"
   },
   "source": [
    "Yikes! When we modified `airport_df2` we also modified `airport_df`.\n",
    "\n",
    "This actually has nothing to do with Pandas, but instead is a case where Python creates a **reference** to our original `DataFrame` instead of a copy.\n",
    "\n",
    "When we assign `airport_df` to `airport_df2` Python just makes `airport_df2` refer to the object that is in `airport_df`. Both refer to the same copy of the data.\n",
    "\n",
    "This is desirable in many cases. Your data might be big. Having many copies can consume a lot of memory and take a lot of time.\n",
    "\n",
    "But sometimes you need to actually copy data. Let's reset our airport `DataFrame` and do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwJe0-12bOxI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airport_df = pd.DataFrame.from_records((\n",
    "  ('Atlanta', 498044, 2),\n",
    "  ('Austin', 964254, 2),\n",
    "  ('Kansas City',  491918, 8),\n",
    "  ('New York City', 8398748, 3),\n",
    "  ('Portland', 653115, 1),\n",
    "  ('San Francisco', 883305, 3),\n",
    "  ('Seattle', 744955, 2),\n",
    "), columns=(\"City Name\", \"Population\", \"Airports\"))\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6hWyJSVfEQx"
   },
   "source": [
    "To make a copy of a `DataFrame` use the `copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTQkj4h6bRLw"
   },
   "outputs": [],
   "source": [
    "airport_df2 = airport_df.copy()\n",
    "\n",
    "airport_df2.loc[:, 'Airports'] *= 2\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2q4uwv-EfMoX"
   },
   "source": [
    "As you can see, `airport_df` did not change.\n",
    "\n",
    "But you can see below that `airport_df2` did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjbdPTi5fT-U"
   },
   "outputs": [],
   "source": [
    "airport_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHnGs4e6fWL8"
   },
   "source": [
    "Pandas adds an additional level of abstraction called **views**. Views are a way to look at the same data from a different perspective.\n",
    "\n",
    "Let's work through an example using our airport dataset.\n",
    "\n",
    "Say we wanted to filter to only rows with more than two airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OBsjMxqgdFt"
   },
   "outputs": [],
   "source": [
    "many_airports_df = airport_df[airport_df['Airports'] > 2]\n",
    "\n",
    "many_airports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgG6vaRPggtg"
   },
   "source": [
    "What is `many_airports_df`? Is it a new `DataFrame`? Does it only contain three rows of data? Are the rows separate or the same as the rows in `airport_df`? If we modify `many_airports_df` will `airports_df` be modified?\n",
    "\n",
    "Let's try and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ujuae9SvbXuz"
   },
   "outputs": [],
   "source": [
    "many_airports_df = airport_df[airport_df['Airports'] > 2]\n",
    "\n",
    "many_airports_df['City Name'] = \\\n",
    "  many_airports_df['City Name'].apply(lambda s: s.upper())\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-pXSUKChLOl"
   },
   "source": [
    "We didn't modify `airport_df`, so we must be working with a copy.\n",
    "\n",
    "We did get a warning though:\n",
    "\n",
    "> ```\n",
    "SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "```\n",
    "\n",
    "In this case Pandas created a copy of the data, but it was uncertain if we wanted to modify the copy or the original `DataFrame`.\n",
    "\n",
    "Warnings are typically a bad sign. We can get rid of the warning by being explicit about what we want to do.\n",
    "\n",
    "If we want to copy the data into a new `DataFrame`, we can use `.copy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UzzBaIKifSV"
   },
   "outputs": [],
   "source": [
    "many_airports_df = airport_df[airport_df['Airports'] > 2].copy()\n",
    "\n",
    "many_airports_df['City Name'] = \\\n",
    "  many_airports_df['City Name'].apply(lambda s: s.upper())\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70AfR0OmimGt"
   },
   "source": [
    "And if we want to not copy the data and to modify the original we need to index into `airport_df` for the modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHqD9SiZbvGn"
   },
   "outputs": [],
   "source": [
    "has_many_airports = airport_df['Airports'] > 2\n",
    "\n",
    "airport_df.loc[has_many_airports, 'City Name'] = \\\n",
    "  airport_df.loc[has_many_airports, 'City Name'].apply(lambda s: s.upper())\n",
    "\n",
    "airport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vt8vGMYVmA2G"
   },
   "source": [
    "### Exercise 6: Updating Calories\n",
    "\n",
    "We just learned that the calorie count for our candy shop's jelly beans and lollipops is 10% too low. We need to update the calorie count for these two treats.\n",
    "\n",
    "Below you'll find the `nutrition_information_df` which contains nutritional information about our treats. Write some code to increase the calories for 'Jelly Bean' and 'Lollipop' by 10%. Be sure that the data stored in `nutrition_information_df` is updated.\n",
    "\n",
    "Be sure that no warnings are issued!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjXxLMR9nord"
   },
   "source": [
    "**Student Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M7wJz3Knw9c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nutrition_information_df = pd.DataFrame.from_records((\n",
    "      ('Cupcake', 178, 5.26, 32.54, 1.37),\n",
    "      ('Donut', 190, 10.51, 21.62, 2.62),\n",
    "      ('Eclair', 267, 16.01, 24.68, 6.53),\n",
    "      ('Froyo', 214, 2.94, 39.24, 9.4),\n",
    "      ('Gingerbread', 130, 5, 19, 2),\n",
    "      ('Honeycomb', 190, 13, 23, 2),\n",
    "      ('Ice Cream Sandwich', 143, 5.6, 21.75, 2.61),\n",
    "      ('Jelly Bean', 100, 0, 25, 0),\n",
    "      ('KitKat', 210, 11, 27, 3),\n",
    "      ('Lollipop', 110, 0, 28, 0),\n",
    "      ('Marshmallow', 100, 0, 24, 1),\n",
    "      ('Nougat', 56, 0.23, 12.93, 0.47),\n",
    "      ('Oreo', 160, 7, 25, 1),\n",
    "      ('Pie', 356, 16.5, 51, 2.85),\n",
    "), columns=('Name', 'Calories', 'Fat (g)', 'Carbs (g)', 'Protein (g)'))\n",
    "\n",
    "# Update 'Lollipop' and 'Jelly Bean' calories by 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4pKePXYn9nI"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFHPt2OWoJM-"
   },
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCeN_IP2Lxac"
   },
   "source": [
    "### Exercise 7: Retail Data\n",
    "\n",
    "You have been hired to organize a small-town retail chain's data and report to them which of their stores have the most effective marketing, measured by how many dollars of merchandise are sold per visitor.\n",
    "\n",
    "To accomplish this you are given access to two tables of data.\n",
    "\n",
    "The first table keeps track of the average daily traffic to each store. We store it in `traffic_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3S3N-FlxobsD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "traffic_df = pd.DataFrame.from_records((\n",
    "      ('43 Crescent Way', 2036),\n",
    "      ('1001 Main St.', 1399),\n",
    "      ('235 Pear Lane', 1386),\n",
    "      ('199 Forest Way', 1295),\n",
    "      ('703 Grove St.', 1154),\n",
    "      ('55 Orchard Blvd.', 1022),\n",
    "      ('202 Pine Drive', 968),\n",
    "      ('98 Mountain Circle', 730),\n",
    "      ('2136 A St.', 729),\n",
    "      ('3430 17th St.', 504),\n",
    "      ('7766 Ocean Ave.', 452),\n",
    "      ('1797 Albatross Ct.', 316),\n",
    "), columns=('Location', 'Traffic'))\n",
    "\n",
    "traffic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VFzPVdstO2c"
   },
   "source": [
    "The second table contains the average revenue from each store. We store in it `locations_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TK0oZjtJMyHu"
   },
   "outputs": [],
   "source": [
    "locations_df = pd.DataFrame.from_records((\n",
    "  ('43 Crescent Way', 6832),\n",
    "  ('55 Orchard Blvd.', 13985),\n",
    "  ('98 Mountain Circle', 3956),\n",
    "  ('199 Forest Way', 572),\n",
    "  ('202 Pine Drive', 3963),\n",
    "  ('235 Pear Lane', 25653),\n",
    "  ('703 Grove St.', 496),\n",
    "  ('1001 Main St.', 38532),\n",
    "  ('1797 Albatross Ct.', 26445),\n",
    "  ('2136 A St.', 34560),\n",
    "  ('3430 17th St.', 1826),\n",
    "  ('7766 Ocean Ave.', 5124),\n",
    "), columns=('Location', 'Revenue'))\n",
    "  \n",
    "locations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lquj4BgqtalL"
   },
   "source": [
    "Given the two `DataFrame` objects mentioned above, perform the following tasks:\n",
    "\n",
    "1. Merge the two dataframes to create a single dataframe with store names: average daily traffic and average daily revenue. Call this new `DataFrame` `performance_df`.\n",
    "\n",
    "2. Make a new column in `performance_df`, showing the average daily revenue *per customer*. Call the new column 'Revenue per Customer'. Revenue per customer is defined as `rpc = revenue / traffic`.\n",
    "\n",
    "3. Print the 'Location' of the store that has the highest 'Revenue per Customer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jf_tOMgeTclO"
   },
   "outputs": [],
   "source": [
    "# Part 1: Perform merge\n",
    "performance_df = None # ...\n",
    "\n",
    "# Part 2: Create column\n",
    "# ...\n",
    "\n",
    "# Part 3: Print location of store with the most revenue per customer\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Fo9th7owvCP"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lRh9gZN5NnoA",
    "WbUl2pf6_kAR",
    "jkpqtw_5BBqP",
    "vY92fvL1ZdaT",
    "3peBvLQ7rbWZ",
    "CGCn-LJCDtc6",
    "k4zvJhq-Fmtp",
    "rhiSukylnqyD"
   ],
   "include_colab_link": true,
   "name": "Intermediate Pandas",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
