{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to scikit-learn",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1",
        "exercise-3-key-1",
        "exercise-4-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pGgUGFhfBtri",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56E1PL91CGS0"
      },
      "source": [
        "# Introduction to scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fW-s1cCLCJ8n"
      },
      "source": [
        "<img height=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/220px-Scikit_learn_logo_small.svg.png\" align=\"left\" hspace=\"10px\"> [Scikit-learn](https://scikit-learn.org) is a machine learning library for Python.\n",
        "\n",
        "Scikit-learn is an approachable library and supports a wide variety of traditional machine learning models, not just deep learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Agmd40ZSFOPN"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rY7emKinFRCr"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Demonstrate the ability to do the following in scikit-learn:\n",
        "  * load sample data\n",
        "  * generate sample data\n",
        "  * transform data\n",
        "  * train a model\n",
        "  * make predictions using a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w-9f1tPWGNPG"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "75 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXOYSL4vGQ1r"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Attempted exercise, but code does not run |\n",
        "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
        "| 3      | Exercise completed successfully |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ftyf6QX2GWPy"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3nvll9SJpVF"
      },
      "source": [
        "Scikit-learn contains methods for loading, fetching, and making (generating) data. The methods for doing this all fall under the [datasets](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) package. Most of the functions in this package have `load`, `fetch`, or `make` in the name to let you know what the method is doing under the hood.\n",
        "\n",
        "**Loading** functions bring static datasets into your program. The data comes pre-packaged with scikit-learn, so no network access is required.\n",
        "\n",
        "**Fetching** functions also bring static datasets into your program. However, the data is pulled from the internet (and cached), so if you don't have network access these functions might fail.\n",
        "\n",
        "**Generating** functions make dynamic datasets based on some equation.\n",
        "\n",
        "These pre-packaged dataset functions exist for many popular/classic datasets such as the [MNIST digits dataset](https://en.wikipedia.org/wiki/MNIST_database) and the [Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). The generation functions reference classic dataset \"shape\" formations such as [moons](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html#sklearn.datasets.make_moons) and [swiss rolls](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html#sklearn.datasets.make_swiss_roll).\n",
        "\n",
        "These datasets are great for getting introduced to machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sO11StjHLvDS"
      },
      "source": [
        "### Loading\n",
        "\n",
        "Let us first look at an example of loading data. We will load the iris flowers dataset using the [load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ky399k0ENjHA",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "iris_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1uP53SEUlNL"
      },
      "source": [
        "That's a lot to take in!\n",
        "\n",
        "Let's examine this loaded data a little more closely. First we'll see what type the data is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XItKuboUvPw",
        "colab": {}
      },
      "source": [
        "type(iris_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyLpaX9YgX7E"
      },
      "source": [
        "A `sklearn.utils.Bunch` is a class type that you'll see quite often when working with datasets built into scikit-learn. It is a dictionary-like container for feature and target data within a dataset.\n",
        "\n",
        "You won't find much documentation about `Bunch` objects though because they are not really meant for usage beyond containing data returned by scikit-learn.\n",
        "\n",
        "Let's look at the attributes of our iris data bunch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eGrbFQUmg1-o",
        "colab": {}
      },
      "source": [
        "dir(iris_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z_jc4IenhD-R"
      },
      "source": [
        "`DESCR` is a description of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "naIUF-N6hHRE",
        "colab": {}
      },
      "source": [
        "print(iris_data['DESCR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nOpF9GErhUR1"
      },
      "source": [
        "`filename` is the file where the data is stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MAMVCeH3hW4E",
        "colab": {}
      },
      "source": [
        "print(iris_data['filename'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAk8huE1henA"
      },
      "source": [
        "`feature_names` are the names of the feature columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDe49sqchg6B",
        "colab": {}
      },
      "source": [
        "print(iris_data['feature_names'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-sWrsHG9hz9m"
      },
      "source": [
        "`target_names` are not however the names of the target columns. There is only one column of targets.\n",
        "\n",
        "Instead, `target_names` are the human-readable names of the classes in the target list within the bunch. In this case they are the names of the three species of iris in this dataset.\n",
        "\n",
        "Note that the target names are in a list where:\n",
        "\n",
        "  * setosa is the 0th element\n",
        "  * versicolor is the 1st element\n",
        "  * virginica is the 2nd element"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "axZadl--hy09",
        "colab": {}
      },
      "source": [
        "print(iris_data['target_names'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6haqEFs2iXBX"
      },
      "source": [
        "We can now examine `target` and see that it contains zeros, ones, and twos. These correspond to the target names 'setosa', 'versicolor', and 'virginica'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S6DV058KiSxA",
        "colab": {}
      },
      "source": [
        "print(iris_data['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LdHpL7wxikzx"
      },
      "source": [
        "Last we look at the `data` within the bunch. The data is an array of arrays. Each sub-array contains four values. These values match up with the `feature_names`. The first item in each sub-array is 'sepal length (cm)', the next is 'sepal width (cm)', and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FGp_Zod2iovU",
        "colab": {}
      },
      "source": [
        "iris_data['data']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dwObt9fhi-e_"
      },
      "source": [
        "The number of target values should always equal the number of rows in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ce26qiH8jDOr",
        "colab": {}
      },
      "source": [
        "print(len(iris_data['data']))\n",
        "print(len(iris_data['target']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JMRCb4sFjPwE"
      },
      "source": [
        "`Bunch` objects are a perfectly fine container for data. They can be used directly to feed models.\n",
        "\n",
        "`Bunch` objects are *not* very good for analyzing and manipulating your data.\n",
        "\n",
        "We will typically convert `Bunch` objects into Pandas `DataFrame` objects to make analysis, data cleaning, and test/train splitting easier and more uniform.\n",
        "\n",
        "To do this we will take the matrix of feature data and append the target data to it to create a single matrix of data. We also take the list of feature names and append the word 'species' to represent the target classes in the matrix.\n",
        "\n",
        "An example of how to do this is below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RV9YXbofkESG",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iris_df = pd.DataFrame(\n",
        "  data=np.append(\n",
        "    iris_data['data'], \n",
        "    np.array(iris_data['target']).reshape(len(iris_data['target']), 1), \n",
        "    axis=1),\n",
        "  columns=np.append(iris_data['feature_names'], ['species'])\n",
        ")\n",
        "\n",
        "iris_df.sample(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mGJSXwWUiLAQ"
      },
      "source": [
        "You might notice that the integer representation of species got converted to a floating point number along the way. We can change that back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nIM1mPm2iYLj",
        "colab": {}
      },
      "source": [
        "iris_df['species'] = iris_df['species'].astype('int64')\n",
        "\n",
        "iris_df.sample(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SCsSQGBBi0XX"
      },
      "source": [
        "### Fetching\n",
        "\n",
        "Fetching is similar to loading. Scikit-learn will first see if it can find the dataset locally and if so will simply load the data. Otherwise, it will attempt to pull the data from the internet.\n",
        "\n",
        "We can see fetching in action with the [fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing) function below. If you run the code block once you should see a message that the data is downloading. If you run it again you won't see that message because the data is already local to your running code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IWIjnqDEjVXX",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing_data = fetch_california_housing()\n",
        "\n",
        "type(housing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sal1rRb0j1G7"
      },
      "source": [
        "The dataset is once again given to us as a `Bunch`.\n",
        "\n",
        "If you followed the link to the [fetch_california_housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing) you notice that the dataset is a **regression** dataset as opposed the iris dataset, which was a **classification** dataset.\n",
        "\n",
        "We can see the difference in the dataset by checking out the attributes of the `Bunch`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0NOhdK0gjxWS",
        "colab": {}
      },
      "source": [
        "dir(housing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CJ8bVa53kYv9"
      },
      "source": [
        "We see that four of the attributes that we expect are present, but 'target_names' is missing. This is because our target is now a home price and not a discrete value like an iris species."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ClIX_emkj9N",
        "colab": {}
      },
      "source": [
        "print(housing_data['target'][:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PUDwxxB2J8wP"
      },
      "source": [
        "Converting a `Bunch` of regression data to a `DataFrame` is no different than converting a `Bunch` of classification data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LdRWov44k3lJ",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "housing_df = pd.DataFrame(\n",
        "  data=np.append(\n",
        "    housing_data['data'], \n",
        "    np.array(housing_data['target']).reshape(len(housing_data['target']), 1), \n",
        "    axis=1),\n",
        "  columns=np.append(housing_data['feature_names'], ['price'])\n",
        ")\n",
        "\n",
        "housing_df.sample(n=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "omIwmr8QlX4W"
      },
      "source": [
        "### Generating\n",
        "\n",
        "In the example datasets we've seen so far in this colab, the data is static and loaded from a file. Sometimes it makes more sense to generate a dataset. For this we use one of the many [generator](https://scikit-learn.org/stable/modules/classes.html#samples-generator) functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tIV-WDaLnKoZ"
      },
      "source": [
        "`make_regression` is a generator that will create a dataset with an underlying regression that you can then attempt to discover using various machine learning models.\n",
        "\n",
        "In the example below we create a dataset with 10 data points. For the sake of visualization we have only one feature per datapoint, but we could ask for more.\n",
        "\n",
        "The return value are the X and y values for the regression. The X is a matrix of features. The y is a list of targets.\n",
        "\n",
        "Since a generator uses randomness to generate data, we are going to set a random_state in this colab for reproducibility. **You won't do this in your production code.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MiR5MD06l44S",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "features, targets = make_regression(n_samples=10, n_features=1, random_state=42)\n",
        "\n",
        "features, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mPGFAiWXn-L2"
      },
      "source": [
        "We can use a visualization library to plot the regression data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a3G9YzxnnlgN",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6CaLo1RUoFaa"
      },
      "source": [
        "That data do have a very linear pattern!\n",
        "\n",
        "If we want to make it more realistic, just add some noise during data generation.\n",
        "\n",
        "**Remember that random_state is for reproducibility only. Don't use this in your code unless you have a good reason to!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_FL8nFnoOET",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "features, targets = make_regression(n_samples=10, n_features=1, random_state=42, noise=5.0)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xEAwguq9oqU_"
      },
      "source": [
        "There are dozens of dataset loaders and generators in the scikit-learn [datasets](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) package. When you want to play with a new machine learning algorithm, they are a great source of data for getting started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PH7eg79ApDWK"
      },
      "source": [
        "## Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgxQbr7apHtX"
      },
      "source": [
        "Machine learning involves training a model to gain insight and predictive power from a dataset. Scikit-learn has support for many different types of models ranging from classic algebraic models through more modern deep learning models.\n",
        "\n",
        "This section exists to survey some concepts that you will encounter when building and running models in scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NQZBibFBlgaI"
      },
      "source": [
        "### Estimators\n",
        "\n",
        "Most of the models in scikit-learn are considered [estimators](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator). An estimator is expected to implement two methods: `fit` and `predict`.\n",
        "\n",
        "`fit` is used to train the model. At a minimum it is passed the feature data used to train the model. In supervised models it is also passed the target data.\n",
        "\n",
        "`predict` is used to get predictions from the model. This method is passed features and returns target predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YAbSxJWngm_"
      },
      "source": [
        "Let's see an example of this in action.\n",
        "\n",
        "A linear regression is a simple model that you might have encountered in a statistics class in the past. The model attempts to draw a straight line through a set of data points so that the line is as close to as many points as possible.\n",
        "\n",
        "We'll use scikit-learn's [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class to fit a line to the regression data that we generated earlier in this colab. To do that we simply call `fit(features, targets)`.\n",
        "\n",
        "After fitting, we can ask the model for predictions. In this case we just ask for predictions based on the features that we used to train in order to draw a scatter plot of the actual data with the regression line plotted over it by calling `predict(features)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5LNyQLumj8Qt",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regression = LinearRegression()\n",
        "regression.fit(features, targets)\n",
        "predictions = regression.predict(features)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.plot(features, predictions, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYzxy7UeofmQ"
      },
      "source": [
        "At this point, don't worry too much about the details of what `LinearRegression` is doing. There is a deep-dive into regression problems coming up soon.\n",
        "\n",
        "For now just note the `fit`/`predict` pattern for training estimators and know that you'll see it throughout our adventures with scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6DgmveIfo6g9"
      },
      "source": [
        "### Transformers\n",
        "\n",
        "In practice it is rare that you will get perfectly clean data that is ready to feed into your model for training (calling `fit`). Most of the time you will need to perform some type of cleaning on the data first.\n",
        "\n",
        "You've got some hands-on experience doing this in our Pandas colabs. Scikit-learn can also be used to perform some data preprocessing tasks on your datasets.\n",
        "\n",
        "Transformers are spread about within the scikit-learn library. Some are in the [preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module while others are in more specialized packages like [compose](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.compose), [feature_extraction](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction), [impute](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute), and more.\n",
        "\n",
        "All transformers implement a `fit` and `transform` methods. The `fit` method calculates parameters necessary to perform the data transformation. `transform` actually applies the transformation. There is a convenience `fit_transform` method that performs both fitting and transformation in one method call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pTgwqMxuPmPA"
      },
      "source": [
        "Let's see a transformer in action.\n",
        "\n",
        "We will use the [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) to scale our feature data between zero and one.\n",
        "\n",
        "Looking at our feature data now we can see values below zero and above one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I-LZHd6LP60G",
        "colab": {}
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FyPTAg2JP9xO"
      },
      "source": [
        "We will now create a `MinMaxScaler` and fit it to our feature data.\n",
        "\n",
        "Each transformer has different information that it needs to perform a transformation. In the case of the `MinMaxScaler` the smallest and largest values in the data are needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4O9ZSNZdOg9J",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "transformer = MinMaxScaler()\n",
        "transformer.fit(features)\n",
        "transformer.data_min_, transformer.data_max_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QoxuBVpFQmOP"
      },
      "source": [
        "You might notice that the values are stored in arrays. This is because transformers can operate on more than one feature. In this case we have only one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xDS2hECWQvRi"
      },
      "source": [
        "Next we need to apply the transformation to our features.\n",
        "\n",
        "We can now see that all of the features fall between the range of zero to one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j_xYLozNQxrP",
        "colab": {}
      },
      "source": [
        "features = transformer.transform(features)\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0UPfbF0CQ-lI"
      },
      "source": [
        "### Pipelines\n",
        "\n",
        "It isn't coincidence that transformers have `fit` and `transform` methods and that models have `fit` methods. The common interface across classes allows scikit-learn to create pipelines for data processing and model building.\n",
        "\n",
        "A [pipeline](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline) is simply a series of transformers, often with an estimator at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l0O6u-_2TfAj"
      },
      "source": [
        "In the example below we use a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class to perform min-max scaling or our feature data and then train a linear regression model using the scaled features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4p2o-I2fSG1O",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "features, targets = make_regression(n_samples=10, n_features=1, random_state=42, noise=5.0)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('scale', MinMaxScaler()),\n",
        "  ('regression', LinearRegression())\n",
        "])\n",
        "\n",
        "pipeline.fit(features, targets)\n",
        "\n",
        "predictions = pipeline.predict(features)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.plot(features, predictions, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqDW3kmkS4cm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "prTIe6_GUkm9"
      },
      "source": [
        "### Metrics\n",
        "\n",
        "So far we have seen ways that scikit-learn can help you get data to perform machine learning, modify that data, train a model, and finally make predictions. But how good are the predictions?\n",
        "\n",
        "Scikit-learn also comes with many functions for measuring model performance in the [metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AWi3wKw_cYbN"
      },
      "source": [
        "To illustrate a metrics function in action we'll import the [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) function and use it to find the mean squared error (MSE) between the target values that we used to train our linear regression model and the predicted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tLs7G3oWaJBd",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(targets, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7xZORiurbb4D"
      },
      "source": [
        "What does the resulting value mean in relation to our model? Is it good or bad?\n",
        "\n",
        "In this case it doesn't have much meaning aside from being the mean of the squares of the distance between our actual target values and their predicted values. Since the data that we fit the regression to isn't related to any real-world metrics the MSE is just a number.\n",
        "\n",
        "As we learn more about machine learning and begin training models on real data you'll learn how to interpret MSE and other metrics in context of the data being analyzed and the problem being solved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yvBWBvc9cyRN"
      },
      "source": [
        "There are also metrics in each estimator class. These metrics can be extracted using the `score` method.\n",
        "\n",
        "The `regression` class we created earlier can be scored, as can the `pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b2vz0Y__cQT3",
        "colab": {}
      },
      "source": [
        "print(regression.score(features, targets))\n",
        "print(pipeline.score(features, targets))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kfEBzfm9dSce"
      },
      "source": [
        "The return value of the `score` method depends on the estimator being used. In the case of `LinearRegression` the score is the r-squared score, where scores closer to 1.0 are better. You can find the metric that `score` returns in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) for the estimator that you are using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T_mlNNxxd-8l"
      },
      "source": [
        "## Closing\n",
        "\n",
        "Scikit-learn is a massive library that contains scores of resources for performing machine learning tasks. In this colab we have only introduced some basic concepts that you will see repeated throughout your career in data science.\n",
        "\n",
        "You are also encouraged to check out the [scikit-learn documentation](https://scikit-learn.org/stable/documentation.html) where you will find a user's guide, tutorials, and a full API reference.\n",
        "\n",
        "Scikit-learn is an Open Source project. You can find it on [Github](https://github.com/scikit-learn/scikit-learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8aQ_TRj-DCms"
      },
      "source": [
        "## Resources\n",
        "\n",
        "* https://scikit-learn.org/stable/documentation.html\n",
        "* https://en.wikipedia.org/wiki/Scikit-learn\n",
        "* https://en.wikipedia.org/wiki/Estimator\n",
        "* https://en.wikipedia.org/wiki/Mean_squared_error\n",
        "* https://github.com/scikit-learn/scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ws5zs84Vev_k"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22oKL4SMexsr"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6K9IrnNBoHxB"
      },
      "source": [
        "Load the [Boston house price dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) into a Pandas `DataFrame`. Append the target values to the last column of the `DataFrame` called `boston_df`. Name the target column 'PRICE'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDd0ygxP-o3L"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SJCrOW1DfOBe",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IICeaKEEfTdl",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "boston_data = load_boston()\n",
        "\n",
        "boston_df = pd.DataFrame(\n",
        "  data=np.append(\n",
        "    boston_data['data'], \n",
        "    np.array(boston_data['target']).reshape(len(boston_data['target']), 1), \n",
        "    axis=1),\n",
        "  columns=np.append(boston_data['feature_names'], ['PRICE'])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3QLCOmwXi3Gn"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YAB-WxNgoKDp"
      },
      "source": [
        "Search the [scikit-learn datasets documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) and find a function to make a \"Moons\" dataset. Create a dataset with 75 samples. Use a random state of `42` and a noise of 0.08. Store the X return value in a variable called `features` and the y return value in a variable called `targets`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uenWPTVD-iYN"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fg8y7o5bjw5-",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWKxB3hfjz9m",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "features, targets = make_moons(n_samples=75, random_state=42, noise=0.08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kx7HErvKnAbE"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRQq8jR6oMYc"
      },
      "source": [
        "In Exercise Two you created a \"moons\" dataset. In that dataset the features are (x,y)-coordinates that can be graphed in a scatterplot. The targets are zeros and ones that represent a binary classification.\n",
        "\n",
        "Use matplotlib's [scatter](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) method to visualize the data as a scatterplot. Use the `c` argument to scatter to make the dots for each class a different color."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "atYw390N-Yn-"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IUqEHOdWnhtM",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-3-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_5dHZ5lnkfd",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features, targets = make_moons(n_samples=75, random_state=42, noise=0.08)\n",
        "\n",
        "plt.scatter(features[:, 0], features[:, 1], c=targets)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UQhscobnqFdc"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VLNgam9WoQc8"
      },
      "source": [
        "Use the [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class to combine a data pre-processor and an estimator.\n",
        "\n",
        "To accomplish this:\n",
        "\n",
        "1. Find a [preprocessor](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) that uses the max absolute value for scaling.\n",
        "1. Find a [linear_model](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) based on the Huber algorithm.\n",
        "1. Combine this preprocessor and estimator into a pipeline.\n",
        "1. Make a sample regression dataset with 200 samples, 1 feature. Use a random state of 85 and a noise of 5.0. Save the features in a variable called `features` and the targets in a variable called `targets`.\n",
        "1. Fit the model.\n",
        "1. Using the features that were created when the regression dataset was created, make predictions with the model and save them into a variable called `predictions`.\n",
        "1. Plot the features and targets used to train the model on a scatterplot with blue dots.\n",
        "1. Plot the features and predictions over the scatterplot as a red line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aAidCrO3-PtA"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgEaukESqHpm",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-4-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5KL8WwFqJEV",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('scale', MaxAbsScaler()),\n",
        "  ('regression', HuberRegressor())\n",
        "])\n",
        "\n",
        "features, targets = make_regression(n_samples=200, n_features=1, random_state=85, noise=5.0)\n",
        "\n",
        "pipeline.fit(features, targets)\n",
        "\n",
        "predictions = pipeline.predict(features)\n",
        "\n",
        "plt.plot(features, targets, 'b.')\n",
        "plt.plot(features, predictions, 'r-')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}