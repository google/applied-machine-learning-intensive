{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-Xt6PXeVjxQN"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2hPzRb6j_CA"
      },
      "source": [
        "# Basic Classification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fsdfasdfsadfsd"
      },
      "source": [
        "In this project you will perform a basic classification task.\n",
        "You will apply what you learned about binary classification and tensorflow to implement a Kaggle project without much guidance. The challenge is to achieve a high accuracy score when trying to predict which passengers survived the Titanic crash. After building your model, you will upload your predictions to Kaggle and submit the score that you receive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "overview"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "learning-objectives"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Define, build, train and evaluate a Linear Classifier model in TensorFlow.\n",
        "* Submit predictions to a Kaggle challenge.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VZe4Xj9tyQRD"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* T05-09 Classification with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "duration"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "330 minutes (270 minutes working time, 60 minutes for presentations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WwdVfHZBADHQ"
      },
      "source": [
        "### Deliverables\n",
        "\n",
        "1. A copy of this Colab notebook containing your code and a written response with your conclusions and the score that you receive from Kaggle.\n",
        "1. A group presentation. After everyone is done, we will ask each group to stand in front of the class and give a brief presentation about what they have done in this lab. The presentation can be a code walkthrough, a group discussion, a slide show, or any other means that conveys what you did over the course of the day and what you learned. If you do create any artifacts for your presentation, please share them in the class folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSlHSTIWAiIE"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "This project is worth 50 points in your final grade, and it will be graded in separate sections that each contribute a percentage of the total score:\n",
        "\n",
        "1. Building and Using a Model (Exercise 1) (60%)\n",
        "2. Kaggle score and conclusion (Exercise 2) (20%)\n",
        "3. Improving your model (Exercise 3) (10%)\n",
        "4. Project Presentation (10%)\n",
        "\n",
        "#### 1. Building and Using a Model (Exercise 1) \n",
        "\n",
        "There are 10 demonstrations of competency listed in the first exercise. Each competency is graded on a 3 point scale for a total of 30 available points. The following rubric will be used:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at the competency |\n",
        "| 1      | Attempted competency, but in an incorrect manner |\n",
        "| 2      | Attempted competency correctly, but sub-optimally |\n",
        "| 3      | Successful demonstration of competency |\n",
        "\n",
        "\n",
        "#### 2. Kaggle score and conclusion (Exercise 2)\n",
        "\n",
        "There are 3 demonstrations of competency and 1 question in the second exercise. Each competency is worth 2 points, and your written response is worth 4 points. The rubric for calculating the competency points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at the competency |\n",
        "| 1      | Attempted competency |\n",
        "| 2      | Successful demonstration of competency |\n",
        "\n",
        "The rubric for the written response is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at question or answer was off-topic or didn't make sense |\n",
        "| 1      | Question was answered, but answer didn't include Kaggle score and relevant observations |\n",
        "| 2      | Question was answered, but answer didn't include Kaggle score or relevant observations |\n",
        "| 3      | Question was answered and included Kaggle score and observations, but conclusion was superficial |\n",
        "| 4      | Answer adequately included Kaggle score and meaningful observations about the model and its performance |\n",
        "\n",
        "\n",
        "#### 3. Improving your model (Exercise 3)\n",
        "\n",
        "This exercise is worth 5 points and it will be graded on your demonstrated ability to manually modify your model to test different thresholds and build a precision vs. recall chart.\n",
        "\n",
        "The rubric for calculating the competency points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at the competency |\n",
        "| 1      | Attempted competency, but in an incorrect manner |\n",
        "| 2      | Attempted competency correctly, but did not try multiple thresholds and did not show precision/recall changes |\n",
        "| 3      | Attempted competency correctly and tried multiple thresholds, but did not show precision/recall changes |\n",
        "| 4      | Attempted competency correctly, tried multiple thresholds, and showed precision/recall changes, but did not clearly show precision/recall tradeoff |\n",
        "| 5      | Successful demonstration of competency - Different thresholds attempted clearly show precision/recall tradeoff  |\n",
        "\n",
        "#### Project Presentation\n",
        "\n",
        "The project presentation will be graded on participation. All members of a team should actively participate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vaP1zrKmAl2o"
      },
      "source": [
        "## Team\n",
        "\n",
        "Please enter your team members names in the placeholders in this text area:\n",
        "\n",
        "*   *Team Member Placeholder*\n",
        "*   *Team Member Placeholder*\n",
        "*   *Team Member Placeholder*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDzCkRNv8Kmz"
      },
      "source": [
        "## Titanic: Machine Learning from Disaster\n",
        "\n",
        "[Kaggle](https://www.kaggle.com) has a [dataset](https://www.kaggle.com/c/titanic/data) containing the passenger list for the Titanic voyage. The data contains passenger features such as age, gender, and ticket class, as well as whether or not they survived.\n",
        "\n",
        "Your job is to load the data and create a binary classifier using TensorFlow to determine if a passenger survived or not. Then, upload your predictions to Kaggle and submit your accuracy score at the end of this colab, along with a brief conclusion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-U_zk4L_HpWJ"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sxmnIepvmdCx"
      },
      "source": [
        "## Exercise 1: Create a Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mntl2Njdme0h"
      },
      "source": [
        "**Graded** demonstrations of competency:\n",
        "\n",
        "1. Download the [dataset](https://www.kaggle.com/c/titanic/data).\n",
        "2. Load the data into this Colab.\n",
        "3. Look at the description of the [dataset](https://www.kaggle.com/c/titanic/data) to understand the columns.\n",
        "4. Explore the dataset. Ask yourself: are there any missing values? Do the data values make sense? Which features seem to be the most important? Are they highly correlated with each other?\n",
        "5. Prep the data (deal with missing values, drop unnecessary columns, transform the data if needed, etc).\n",
        "6. Split the data into testing and training set.\n",
        "7. Create a `tensorflow.estimator.LinearClassifier`.\n",
        "8. Train the classifier using an input function that feeds the classifier training data.\n",
        "9. Make predictions on the test data using your classifier.\n",
        "10. Find the accuracy, precision, and recall of your classifier.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LO8x9d6GHwgQ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zKgNoBuEm2h0"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HASbqtkRHzkI"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hzzf0H2r5F_j"
      },
      "outputs": [],
      "source": [
        "## Step 1: Download the dataset and load the data. ##\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "titanic_df = pd.read_csv('https://raw.githubusercontent.com/juemura/amli/master/titanic/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8t4I4pL5_nJD"
      },
      "outputs": [],
      "source": [
        "## Step 2: Look at the description of the dataset to understand the columns. ##\n",
        "\n",
        "titanic_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XoBHaAlrGjm-"
      },
      "outputs": [],
      "source": [
        "## SOLUTION: Automatically removed from student copy (keep this comment) ##\n",
        "## Examine the dataset format and sample data points ##\n",
        "\n",
        "print(titanic_df.dtypes)\n",
        "titanic_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vu5G6j_pAGfV"
      },
      "outputs": [],
      "source": [
        "## Step 3: Perform analysis on the dataset and repair or drop columns and rows of data as needed. \n",
        "## Are there any missing values? \n",
        "\n",
        "titanic_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2z0VjHbGAmVe"
      },
      "outputs": [],
      "source": [
        "## Step 3: (cont)\n",
        "## Do the data values make sense?\n",
        "\n",
        "def titanic_data_prep(df):\n",
        "  # PassengerId is a unique identifier and thus should be used as the index\n",
        "  df.set_index('PassengerId', inplace=True)\n",
        "\n",
        "  # Embarked has 2 null values, we can simply replace them with \"unknown\"\n",
        "  df['Embarked'].fillna('unknown', inplace=True)\n",
        "\n",
        "  # Encode categorical data, i.e. Sex and Embarked\n",
        "  # Among other options, you can use LabelEncoder, One-Hot Encoding, or simply replace the values\n",
        "  # For Sex the categories are simple, but for ports we can create a list of unique labels\n",
        "  # and use a dictionary comprehension\n",
        "  port_labels = df['Embarked'].astype('category').cat.categories.tolist()\n",
        "  encoding = {'Sex': {'male': 0, 'female': 1}, 'Embarked': {k:v for k,v in zip(port_labels, range(1, len(port_labels)+1))}}\n",
        "  df.replace(encoding, inplace=True)\n",
        "  \n",
        "  # Age has 177 null values that we need to deal with before training our model\n",
        "  # One simple approach is to replace null values with the mean\n",
        "  df.fillna(df.mean(), inplace=True)\n",
        "  \n",
        "  # Name, Ticket, and Cabin are likely irrelevant for our model since they are \n",
        "  # simply identifiers and don't indicate any distinguishing characteristic\n",
        "  df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], inplace=True, axis=1)\n",
        "\n",
        "titanic_data_prep(titanic_df)\n",
        "\n",
        "# Double check that we got rid of all null values\n",
        "print(titanic_df.isnull().sum())\n",
        "\n",
        "# Check the description of the dataset again to make sure everything looks good \n",
        "titanic_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HZisbMFxAvrN"
      },
      "outputs": [],
      "source": [
        "## Step 3: (cont)\n",
        "## Which features seem to be the most important?\n",
        "## Are there highly correlated with each other?\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "corMat = titanic_df.corr(method='pearson')\n",
        "print(corMat)\n",
        "\n",
        "sns.heatmap(corMat, square=True)\n",
        "plt.yticks(rotation=0)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# Observations:\n",
        "# Sex and Fare seem to have the highest correlation with whether or not they \n",
        "# survived, and they are not highly correlated with each other.\n",
        "# Thus they appear to be important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Savxgg8SAJf3"
      },
      "outputs": [],
      "source": [
        "## Step 4: Split the data into testing and training set. ##\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TARGET = 'Survived'\n",
        "FEATURES = [col for col in titanic_df.columns if col != TARGET]\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "  titanic_df,\n",
        "  test_size=0.2,\n",
        ")\n",
        "\n",
        "print(\"Training set shape: {}\".format(train_df.shape))\n",
        "print(\"Test set shape: {}\".format(test_df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "r6F9SgmTAQsJ"
      },
      "outputs": [],
      "source": [
        "## Step 5: Create a tensorflow.estimator.LinearClassifier. ##\n",
        "\n",
        "from tensorflow.feature_column import numeric_column\n",
        "from tensorflow.estimator import LinearClassifier\n",
        "\n",
        "\n",
        "# Declare the feature columns\n",
        "feature_columns = []\n",
        "\n",
        "for column_name in FEATURES:\n",
        "  feature_columns.append(numeric_column(str(column_name)))\n",
        "\n",
        "for feature in feature_columns:\n",
        "  print(feature)\n",
        "\n",
        "\n",
        "# Check the class count\n",
        "class_count = len(train_df[TARGET].unique()) # This should be 2 (survived / didn't survive)\n",
        "print(\"Class count: {}\".format(class_count))\n",
        "\n",
        "\n",
        "# Create a classifier\n",
        "classifier = LinearClassifier(feature_columns=feature_columns, n_classes=class_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ui-pOIL-ASr0"
      },
      "outputs": [],
      "source": [
        "## Step 6: Train the classifier using an input function that feeds the classifier training data. ##\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "\n",
        "def training_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = train_df[feature]\n",
        "  \n",
        "  labels = train_df[TARGET]\n",
        "\n",
        "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(100)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "classifier.train(training_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FvaOtBr_AT9e"
      },
      "outputs": [],
      "source": [
        "## Step 7: Make predictions on the test data using your classifier. ##\n",
        "\n",
        "def testing_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = test_df[feature]\n",
        "  return Dataset.from_tensor_slices((features)).batch(1)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "print(predictions_iterator)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "predictions = [p['class_ids'][0] for p in predictions_iterator]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jWmpzFwPNAcc"
      },
      "outputs": [],
      "source": [
        "## Step 8: Find the accuracy, precision, and recall of your classifier. ##\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "print(\"Accuracy: {}\".format(accuracy_score(test_df['Survived'], predictions)))\n",
        "\n",
        "print(\"Precision: {}\".format(precision_score(test_df['Survived'], predictions, average='micro')))\n",
        "\n",
        "print(\"Recall: {}\".format(recall_score(test_df['Survived'], predictions, average='micro')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RrWuSYn9H-Pp"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ps0VEZTjH_v5"
      },
      "outputs": [],
      "source": [
        "# TODO(juemura)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXJCSsAdz-f0"
      },
      "source": [
        "## Exercise 2: Upload your predictions to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ONevNjq2UXu"
      },
      "source": [
        "**Graded** demonstrations of competency:\n",
        "1. Download the test.csv file from Kaggle and re-run your model using all of the training data.\n",
        "2. Use this new test data to generate predictions using your model.\n",
        "3. Follow the instructions in the [evaluation section](https://www.kaggle.com/c/titanic/overview/evaluation) to output the predictions in the format of the gender_submission.csv file. Download the predictions file from your Colab and upload it to Kaggle.\n",
        "\n",
        "\n",
        "**Written Response**\n",
        "\n",
        "Write down your conclusion along with the score that you got from Kaggle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fijeUn4tIFCo"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dEWZUCnT9UkK"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRZni-CBVjFV"
      },
      "source": [
        "{### Your written response goes here. Make sure to include your Kaggle score. ###}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q47q8OjlILQ2"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3n1w0QRP9YhA"
      },
      "outputs": [],
      "source": [
        "## Step 1: Re-run your model using all of the training data. ##\n",
        "\n",
        "full_train_df = titanic_df\n",
        "\n",
        "print(\"Training set shape: {}\".format(train_df.shape))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset\n",
        "\n",
        "\n",
        "def training_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = full_train_df[feature]\n",
        "  \n",
        "  labels = full_train_df[TARGET]\n",
        "\n",
        "  training_ds = Dataset.from_tensor_slices((features, labels))\n",
        "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
        "  training_ds = training_ds.batch(10)\n",
        "  training_ds = training_ds.repeat(5)\n",
        "\n",
        "  return training_ds\n",
        "\n",
        "classifier.train(training_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "J7Uv9Cnano76"
      },
      "outputs": [],
      "source": [
        "## Step 2: Download the test.csv and use it to generate predictions. ##\n",
        "\n",
        "full_test_df = pd.read_csv('https://raw.githubusercontent.com/juemura/amli/master/titanic/test.csv')\n",
        "print(\"Test set shape: {}\".format(test_df.shape))\n",
        "\n",
        "titanic_data_prep(full_test_df)\n",
        "\n",
        "def testing_input():\n",
        "  features = {}\n",
        "  for feature in FEATURES:\n",
        "    features[feature] = full_test_df[feature]\n",
        "  return Dataset.from_tensor_slices((features)).batch(1)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "print(predictions_iterator)\n",
        "\n",
        "predictions_iterator = classifier.predict(testing_input)\n",
        "\n",
        "predictions = [p['class_ids'][0] for p in predictions_iterator]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YWjWAdDeurzV"
      },
      "outputs": [],
      "source": [
        "## Step 3: Output the predictions in the format of the gender_submission.csv file.\n",
        "## Download the predictions file from your Colab and upload it to Kaggle. ##\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "results = pd.DataFrame({'PassengerId': full_test_df.index, 'Survived': predictions})\n",
        "results.to_csv('titanic_predictions.csv', index=False)\n",
        "files.download('titanic_predictions.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m4YaqZRjIPX_"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ASNKMLkZISQV"
      },
      "outputs": [],
      "source": [
        "# TODO(juemura)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9KdtnUJP2Uen"
      },
      "source": [
        "## Exercise 3: Improve your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C781-AwN4q9Z"
      },
      "source": [
        "The predictions returned by the LinearClassifer contain scoring and/or confidence information about why the decision was made to classify a passenger as a survivor or not. Find the number used to make the decision and manually play around with different thresholds to build a precision vs. recall chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w5rYKVkgT8NL"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MDEErS0f8oi7"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-3-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SYRk1PknIcdy"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QzI42N4Y9Zkz"
      },
      "outputs": [],
      "source": [
        "# TODO(juemura)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oq5Ued3VId4c"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dLmHtwuqIfpZ"
      },
      "outputs": [],
      "source": [
        "# TODO(juemura)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFFInD4j-VMc"
      },
      "source": [
        "## Exercise 4: Dig deeper (optional and ungraded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "93t_PYx6-W_N"
      },
      "source": [
        "Check out the different approaches in [this kernel](https://www.kaggle.com/startupsci/titanic-data-science-solutions) (kernels are solutions or data exploration notebooks shared by other users).\n",
        "Try using a different approach and see if you can improve your results.\n",
        "\n",
        "Alternatively, you can try implementing a simple decision tree by hand, as in this [Udacity Project](https://github.com/juemura/machine-learning/blob/master/projects/titanic_survival_exploration/titanic_survival_exploration.ipynb). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3_tj2sXDIk7N"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BhbZHXy-ImSj"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-4-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "alWO0aaVIp8v"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Jkipr-LlIpEc"
      },
      "outputs": [],
      "source": [
        "# TODO(juemura)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRjSsJVpIuMb"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5bRsnk03Ivz7"
      },
      "outputs": [],
      "source": [
        "# TODO(juemura)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1",
        "exercise-3-key-1",
        "exercise-4-key-1"
      ],
      "name": "Basic Classification Project",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
