{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian Models",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7PLP9Q30PKtv",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f5W9rkuBmBu9"
      },
      "source": [
        "# Bayesian Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zIykBQbYXrXA"
      },
      "source": [
        "Bayesian models are at the heart of many ML applications, and can be implemented in regression or classification.  Naive Bayes has proven to be an excellent spam detection method. Bayesian Inference is often used in applications of modeling stochastic, temporal, or time-series data like finance, healthcare, sales, marketing, and economics.  Bayesian Networks are also at the heart of reinforcement learning (RL) algorithms which drive complex automation, like autonomous vehicles. And Bayesian Optimization is used to maximize the effectiveness of AI game opponents like alphaGO.  Bayesian Models make effective use of information, and it is possible to parameterize, and update these models using prior, and posterior probability functions.\n",
        "\n",
        "There are many libraries that implement probabilistic programming including [tensorflow.org/probability](https://www.tensorflow.org/probability).  \n",
        "\n",
        "In this module we will implement a Bayesian Model using a Naive Bayes Classifier to predict the likelihood of spam in a sample of text data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSwFn8YlaDL2"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHVHPJhSaEEM"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Review Bayes' Theorem\n",
        "* Build a Classifier with sklearn\n",
        "* clean, and analyze text\n",
        "* predict spam or ham\n",
        "* predict review sentiment (+ or -)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGrUipVEawYy"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Probability\n",
        "* Classification with Sklearn\n",
        "* Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0bExBYnwa7i2"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "60 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SavoD7IUa-vY"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Attempted exercise, but code does not run |\n",
        "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
        "| 3      | Exercise completed successfully |\n",
        "\n",
        "There are 1 exercises in this Colab so there are 3 points available. The grading scale will be 3 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR_Tz2pn1WMf",
        "colab_type": "text"
      },
      "source": [
        "### Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jrdAklFCx-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G8u2lYRWbE37"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3cNxL12_cMz",
        "colab_type": "text"
      },
      "source": [
        "What is Naive Bayes?  There are two aspects, the first being naive, and the second is Bayes'.  Let us review Bayes' theorem from probability.\n",
        "$$ P(x)P(y|x) = P(y)P(x|y) $$\n",
        "\n",
        "Using this theorem, we can solve for the conditional probability of event $y$, given condition $x$.  Furthermore, Bayes' Rule can be extended to incorporate $n$ vectors as follows:\n",
        "\n",
        "$$ P(y|x_1...x_n) = \\frac{P(y)P(x_1...x_n|y)}{P(x_1...x_n)}$$\n",
        "\n",
        "These probability vectors can then be simplified by multiplying the individual conditional probability for each vector, and taking the maximum likelihood. Naive Bayes returns the y value, or category that maximizes the following argument.\n",
        "\n",
        "$$ \\hat{y} = argmax_y(P(y)\\prod_{i=1}^nP(x_i|y) $$\n",
        "\n",
        "### But wait, why Naive?\n",
        "\n",
        "In this context, Naive assumes that there is independence between pairs of conditional vectors, in other words, the features of your model have a low multicollinearity.  This is typically not the case, and is the cause for error.  Naive Bayes is practically good for classification, but not for estimation.  Furthermore, it is not robust to interaction, so some of your variables may have interactions, or create a different effect when they both have a specific value.  This comes up quite frequently in Natural Language Processing, and so Naive Bayes usefulness is limited to simpler applications.  Sometimes, simple is better, like in spam filtering, where Naive Bayes can perform reasonably well, with limited training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Vi3O347bIWz"
      },
      "source": [
        "## Spam Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LHNLjQ4sV6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LoadZip(url, file_name, cols=['type', 'message']):\n",
        "    # Download file\n",
        "    urllib.request.urlretrieve(url, 'spam.zip')\n",
        "    # Open zip in memory\n",
        "    with ZipFile('spam.zip') as myzip:\n",
        "        with myzip.open(file_name) as myfile:\n",
        "            df = pd.read_csv(myfile, sep='\\t', header=None)\n",
        "\n",
        "    df.columns=cols\n",
        "    display(df.head())\n",
        "    display(df.shape)\n",
        "    return df\n",
        "\n",
        "url = ('https://archive.ics.uci.edu/ml/machine-learning-databases/00228/'\n",
        "       'smsspamcollection.zip')\n",
        "df = LoadZip(url, 'SMSSpamCollection')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKrSKgU3zHoC",
        "colab_type": "text"
      },
      "source": [
        "## First analyze the the number of spam vs. ham"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLwafSIUzGrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(df['type'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP7Dp8t00I4Q",
        "colab_type": "text"
      },
      "source": [
        "Here we notice a class imbalance with under 1000 spam messages out over 5000 total."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKB4EJ761-ho",
        "colab_type": "text"
      },
      "source": [
        "## Create a list of keywords that might indicate spam\n",
        "\n",
        "and generate features columns for each keyword.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NSy7WYCt4g0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = pd.DataFrame()\n",
        "keywords = ['selected', 'win','deal', 'free', 'trip', 'urgent', 'require',\n",
        "            'need', 'cash', 'asap']\n",
        "\n",
        "# use regex search built into pandas\n",
        "for k in keywords:\n",
        "    features[k]=df['message'].str.contains(k, case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbSYInPU3qwL",
        "colab_type": "text"
      },
      "source": [
        "## Come up with some more rules and implement them as feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lshSJEY3w2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features['allcaps'] = df['message'].str.isupper()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u29iAoBR38nG",
        "colab_type": "text"
      },
      "source": [
        "## Look at correlation of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qaAHAk53_XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(features.corr())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHZwDW7uE-0L",
        "colab_type": "text"
      },
      "source": [
        "The heatmap shows only weak correlations between variables like cash-win,free, urgent.  So, we can assume that there is independence between each keyword.  In actuality, we are violating this assumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkaWZj0Y5WDs",
        "colab_type": "text"
      },
      "source": [
        "## Train a model to predict spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvRDb-m6360O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(seed=0)\n",
        "X = features\n",
        "y = df['type']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "sns.countplot(y_test)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxpi8kjd5fpK",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions\n",
        "\n",
        "Using `features` we will now make predictions on whether an individual message is spam or ham."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US0BySNq5g5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifyNB(X_train,y_train, X_test, y_test, cols=['spam', 'ham']):\n",
        "    nb = BernoulliNB()\n",
        "\n",
        "    nb.fit(X_train,y_train)\n",
        "\n",
        "    y_pred = nb.predict(X_test)\n",
        "    class_names = cols\n",
        "    print('Classification Report')\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=class_names)\n",
        "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "\n",
        "    sns.heatmap(df_cm, cmap='Blues', annot=True, fmt=\"d\",\n",
        "                xticklabels=True, yticklabels=True, cbar=False, square=True)\n",
        "    plt.ylabel('Predicted')\n",
        "    plt.xlabel('Actual')\n",
        "    plt.suptitle(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "    \n",
        "classifyNB(X_train,y_train,X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCL48RLyoabw",
        "colab_type": "text"
      },
      "source": [
        "The confusion matrix reads as follows:\n",
        "\n",
        "* 1182 ham messages correctly predicted\n",
        "* 114 ham messages were predicted to be spam (Type II error)\n",
        "* 71 spam messages were correctly predicted\n",
        "* 26 spam messages were erroneously predicted to be ham (Type I error)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-opQR47Tdhu",
        "colab_type": "text"
      },
      "source": [
        "### Precision and Recall\n",
        "\n",
        "Remember that precision and recall are derived from the ground truth, review the diagram below for clarification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaW0wGp6Si7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "\n",
        "<a title=\"Walber [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], via Wikimedia Commons\" \n",
        "   href=\"https://commons.wikimedia.org/wiki/File:Precisionrecall.svg\">\n",
        "    <img width=\"256\" alt=\"Precisionrecall\" \n",
        "         src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/256px-Precisionrecall.svg.png\">\n",
        "</a>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlKMwRYaBNgG",
        "colab_type": "text"
      },
      "source": [
        "## For Gmail? What's more important, spam detection or ham protection?\n",
        "\n",
        "In the case of your inbox, I don't think anyone wants to have legitimate email end up in the spam folder.  On the other hand, your organization may be the target of phishing, so it depends on the objective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5WFLU7hWbO8_"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* [Naive Bayes Docs](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
        "* [spam dataset](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)\n",
        "* [sentiment reviews](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)\n",
        "* [Paper on Classifiers](http://mdenil.com/media/papers/2015-deep-multi-instance-learning.pdf)",
        "* [Bayesian Inference](https://cran.r-project.org/web/packages/LaplacesDemon/vignettes/BayesianInference.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Swt2fxm-fG_B"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWq38ASlb2aY"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECfJaKHhBqAk",
        "colab_type": "text"
      },
      "source": [
        "Load Reviews Data and do sentiment analysis\n",
        "\n",
        "Download the text data from [UCI ML archive](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)\n",
        "\n",
        "Create a classifier using Naive Bayes one of the 3 datasets, and see how it performs on the other two sets of reviews.  Comment on your approach to building features and why that may, or may not work well for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz_hmP64BMWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = ('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
        "'00331/sentiment%20labelled%20sentences.zip')\n",
        "\n",
        "cols = ['message', 'sentiment']\n",
        "folder = 'sentiment labelled sentences'\n",
        "print('\\nYelp')\n",
        "df_yelp = LoadZip(url, folder+'/yelp_labelled.txt', cols)\n",
        "print('\\nAmazon')\n",
        "df_amazon = LoadZip(url, folder+'/amazon_cells_labelled.txt', cols)\n",
        "print('\\nImdb')\n",
        "df_imdb = LoadZip(url, folder+'/imdb_labelled.txt', cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYZEXNK1VDIJ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TI_WxOyjcfNu",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgv9zjpkmH5c",
        "colab_type": "text"
      },
      "source": [
        ">***Train on Yelp Data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFUg4N-YghoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df_yelp.copy()\n",
        "df['sentiment'] = df['sentiment'].apply(lambda x: 'positive' if x==1 else 'negative')\n",
        "sns.countplot(df['sentiment'])\n",
        "plt.suptitle('Yelp Reviews')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKb-7oqrcfox",
        "colab": {}
      },
      "source": [
        "\n",
        "# replace punctuation \n",
        "df['message'] = df.message.str.replace(r'[^a-zA-Z\\d\\s:]', '')\n",
        "# make lower case\n",
        "df['message'] = df['message'].str.lower()\n",
        "\n",
        "\n",
        "# split negative messages and combine into one list\n",
        "negative_words = df.message[df['sentiment']=='negative'].str.cat(sep=' ').split()\n",
        "\n",
        "positive_words = df.message[df['sentiment']=='positive'].str.cat(sep=' ').split()\n",
        "\n",
        "# Unique Words\n",
        "print('negative:', len(np.unique(negative_words)), ' positive:', len(np.unique(positive_words)))\n",
        "\n",
        "# Create positive words\n",
        "diff_pos = np.setdiff1d(ar1=positive_words, \n",
        "                      ar2=negative_words\n",
        "                     )\n",
        "\n",
        "# Create negative words\n",
        "diff_neg = np.setdiff1d(ar1=positive_words, \n",
        "                      ar2=negative_words\n",
        "                     )\n",
        "\n",
        "# combine\n",
        "diff = np.append(diff_pos, diff_neg)\n",
        "\n",
        "#split\n",
        "diff = np.random.choice(diff, size=int(len(diff) / 2))\n",
        "\n",
        "diff = diff_neg\n",
        "\n",
        "# diff = diff_pos\n",
        "\n",
        "features = pd.DataFrame()\n",
        "\n",
        "for key in diff:\n",
        "    # Note that we add spaces around the key so that we're getting the word,\n",
        "    # not just pattern matching.\n",
        "    features[key] = df['message'].str.contains(key, case=False)\n",
        "\n",
        "X = features\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Fit our model to the data.\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Classify, storing the result in a new variable.\n",
        "y_pred = bnb.predict(X_test)\n",
        "\n",
        "classifyNB(X_train,y_train,X_test,y_test, cols=['negative', 'positive'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5EndkJMJVKjw"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SgzIrUK1dFdQ",
        "colab": {}
      },
      "source": [
        "# If the solution can be auto-graded, perform the autograding here."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}