{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright"
   },
   "source": [
    "#### Copyright 2019 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "hMqWDc_m6rUC"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2hPzRb6j_CA"
   },
   "source": [
    "# Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x88D_U-4oTH"
   },
   "source": [
    "In a previous exercise, you worked with [Scikit Learn](https://scikit-learn.org/stable/) to define a linear regression model.   Recently you were introduced to [TensorFlow](https://www.tensorflow.org/), a powerful computational toolkit. We will now combine those learnings and create a linear regression model in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bW7AVurPpb0u"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bd2Zkk1LE2Zr"
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "  * Review the TensorFlow programming model\n",
    "  * Use the `LinearRegressor` class in TensorFlow to predict median housing price, at the granularity of city blocks, based on one input feature\n",
    "  * Evaluate the accuracy of a model's predictions using Root Mean Squared Error (RMSE)\n",
    "  * Improve the accuracy of a model by tuning its hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCw0L_c7pg0L"
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Introduction to Colab\n",
    "* Intermediate Python\n",
    "* Introduction to Pandas\n",
    "* Visualizations\n",
    "* Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GF_PMg4plQ-"
   },
   "source": [
    "### Estimated Duration\n",
    "\n",
    "60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KJWVzfcpnBg"
   },
   "source": [
    "### Grading Criteria\n",
    "\n",
    "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
    "\n",
    "| Points | Description |\n",
    "|--------|-------------|\n",
    "| 0      | No attempt at exercise |\n",
    "| 1      | Attempted exercise, but code does not run |\n",
    "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
    "| 3      | Exercise completed successfully |\n",
    "\n",
    "There are 3 exercises in this Colab so there are 9 points available. The grading scale will be 9 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hknYP8ou1cPK"
   },
   "source": [
    "## Problem Framing\n",
    "\n",
    "Machine learning is not a solution looking for a problem, but is instead one of a variety of solutions that might work for an existing problem. Given this, we should begin our journey by understanding the problem we are trying to solve.\n",
    "\n",
    "In this particular case, we would like to be able to **predict the price of a house in California**.\n",
    "\n",
    "Questions we should ask ourselves might include:\n",
    "\n",
    "*  Predict the price when? Now? In the past? In the future? For what range?\n",
    "*  What is our tolerance for being wrong?\n",
    "*  Are we okay with a few huge outliers if the overall model is better?\n",
    "*  What metrics are we using to define success and what are the acceptable values?\n",
    "*  Is there an non-ML way to solve this problem?\n",
    "*  What data is available to solve the problem?\n",
    "\n",
    "The list of questions is boundless. Eventually you'll need to move on, but understanding the problem and the solution space is vital.\n",
    "\n",
    "---\n",
    "\n",
    "For this problem we'll further define the problem by saying:\n",
    "\n",
    ">  We want to create a system that predicts the prices of houses in California in 1990. We have census data from 1990 available to build and test the system. We will accept a system with a root mean squared error of 200,000 or better.\n",
    "\n",
    "Since this is a contrived example we'll short-cut and say that our analysis has led us to believe that we want to use a linear regression model to serve as our prediction system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "The dataset we'll use for this Colab contains California housing data taken from the 1990 census data. This is a popular dataset for experimenting with machine learning models.\n",
    "\n",
    "As with any data science project it is a good idea to take some time and review the [data schema and description](https://developers.google.com/machine-learning/crash-course/california-housing-data-description). Ask yourself:\n",
    "\n",
    "* What data is available? What are the columns?\n",
    "* What do those columns mean?\n",
    "* What data types are those columns?\n",
    "* What is the granularity of the data? In this particular case, what is a \"block\"?\n",
    "* How many rows of data are there?\n",
    "* Roughly how big is the data? Kilobytes? Megabytes? Gigabytes? Terabytes? More?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxiIKhP4E2Zr"
   },
   "source": [
    "### Load the data\n",
    "\n",
    "Now that we have a rough understanding of the data that we are going to use in our model, let's load it into this Colab and examine the data a little more closely.\n",
    "\n",
    "We'll rely on Pandas to read a CSV version of the data from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ivCDWnwE2Zx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "housing_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Examine the data\n",
    "\n",
    "You should always look at your data and statistics about that data before you begin modelling it. A great tool for getting a high-level view is to ask Pandas to describe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tcms-0dziNlO"
   },
   "source": [
    "In this case we can see that all of the column counts are the same. That lets us know that every data point has a value. This can sometimes give you a false sense of security because many datasets have default values instead of empty values.\n",
    "\n",
    "Looking at the min and max can be helpful too. Does a 1 value for a minimum number of rooms for a block match your mental model of what a block is?\n",
    "\n",
    "As you probe a dataset you should ask yourself questions like this. When something doesn't look right, investigate it.\n",
    "\n",
    "We can also identify the column of data that contains our target value. In this case we want to predict home values, so we will use `median_home_value` as our target.\n",
    "\n",
    "Let's *imagine* that through more data analysis we decide that we'll use `total_rooms` as the feature that will be used to predict the home value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFY9F9PPjKcC"
   },
   "source": [
    "It is also a good idea to take a look a the actual data. We can use Panda's `head` and `tail` methods to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyJQrnogjSNc"
   },
   "outputs": [],
   "source": [
    "housing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywB10labjXxg"
   },
   "outputs": [],
   "source": [
    "housing_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmHCrw9cjbpr"
   },
   "source": [
    "Did you gain any insight from peeking at the actual data? Is the data sorted in a manner that might lead to a bad model?\n",
    "\n",
    "In this case the data seems to be sorted ascending by longitude and possibly secondarily descending by latitude. We need to consider this when sampling or splitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVk_qlG6U80j"
   },
   "source": [
    "### Prepare the data\n",
    "\n",
    "A considerable amount of time is spent working with the dataset when creating a machine learning solution. In this case, we have looked at the data and it actually seems to be relatively clean.\n",
    "\n",
    "The largest problem that we've seen is that there is an obvious sorting order to the data. To ensure that the sorting doesn't bite us later on, we should go ahead and randomize it now. A way to do this built into Pandas is to just create a 100% sample of the `DataFrame` in place of the original `DataFrame`.\n",
    "\n",
    "The scale of the data across columns is also considerably different. It is often useful to normalize this data before feeding it to machine learning algorithms. We'll not do that now though since our intent for this lab is to build a simple linear regression model with one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0eVyguIU80m"
   },
   "outputs": [],
   "source": [
    "housing_df = housing_df.sample(frac=1)\n",
    "\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xuz9tZs5irjC"
   },
   "source": [
    "### Train/Test Split\n",
    "\n",
    "We want to go ahead and divide our data into testing and training splits. For this example we'll hold out 20% of the data for testing. Since the data is already shuffled, we can just take the first 20% and set it aside for testing and then take the final 80% and use it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Bz5_x-FjJX9"
   },
   "outputs": [],
   "source": [
    "test_set_size = int(len(housing_df) * 0.2)\n",
    "\n",
    "testing_df = housing_df[:test_set_size]\n",
    "training_df = housing_df[test_set_size:]\n",
    "\n",
    "print(\"Holding out {} records for testing. Using {} records for training.\".format(len(testing_df), len(training_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odbXASMkjn2d"
   },
   "source": [
    "### Translating DataFrames to Datasets\n",
    "\n",
    "`DataFrame` is a container for a dataset in Pandas. To process the data with TensorFlow we need to get the data in the `DataFrame` into a TensorFlow [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
    "\n",
    "Since our housing data fits in memory, we can use the `from_tensor_slices` class method to create our `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNo22B3Skhcv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset\n",
    "\n",
    "testing_ds = Dataset.from_tensor_slices(testing_df)\n",
    "training_ds = Dataset.from_tensor_slices(training_df)\n",
    "\n",
    "testing_ds, training_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLd86oNWmfJp"
   },
   "source": [
    "The code above runs, but did it work? We can see that the shape is (9,) which tells us that the data sets have 9 columns and an unknown number of rows. The nine columns fits with our expectations, but it would be nice to know that our row counts are the same.\n",
    "\n",
    "Intuitively you'd think this would be as simple as asking for the length of the data sets from Python:\n",
    "\n",
    "```\n",
    " len(testing_ds)\n",
    " len(training_ds)\n",
    "```\n",
    "\n",
    "This won't work though. Remember that TensorFlow is just building a graph of things to run, but hasn't executed any of our graph yet. To do that we must create a session.\n",
    "\n",
    "You also can't just ask for the count of rows in the dataset from the dataset itself. Why is this? The dataset doesn't necessarily know and it could be a very expensive operation.\n",
    "\n",
    "The `Dataset` object can represent in-memory data, like what we have now. It can also represent data in multiple sources stored in different locations. In can even represent a stream of data that is never-ending.\n",
    "\n",
    "Because of this we need to do a little more work to get a count of the data in a TensorFlow `Dataset`. To get a count we'll use the `reduce` operation. This operation takes an initial value, in our case 0, and then performs some function over and over for each row in the dataset. In this case we just add one for each value. The reduction returns values for each row and feeds it to the next. The final row simply returns the value to the runtime.\n",
    "\n",
    "We can see below that the `reduce` operation counts the number of rows for the testing and training dataset and they both match the values we saw above in the Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qiNjkMGrm1B0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "testing_ds_count = testing_ds.reduce(np.int64(0), lambda x, _: x + 1)\n",
    "training_ds_count = training_ds.reduce(np.int64(0), lambda x, _: x + 1)\n",
    "\n",
    "print(testing_ds_count)\n",
    "print(training_ds_count)\n",
    "\n",
    "print(session.run([testing_ds_count, training_ds_count]))\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Build and Train the Model\n",
    "\n",
    "In this section, we'll build a model to try to predict `median_house_value`, which will be our label (often called a target).  We'll use `total_rooms` as our input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7Plfl3K6xEj"
   },
   "source": [
    "### LinearRegressor\n",
    "\n",
    "To train our model, we'll use the [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) interface provided by the TensorFlow [Estimator](https://www.tensorflow.org/get_started/estimator) API. This API takes care of a lot of the low-level model plumbing, and exposes convenient methods for performing model training, evaluation, and inference.\n",
    "\n",
    "Though the `LinearRegressor` has many configuration options, [only feature columns have to be specified when the regressor is created](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#__init__).\n",
    "\n",
    "We provide the regressor [feature columns](https://www.tensorflow.org/guide/feature_columns) as a list of columns that we'd like the model to use for training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XBeRgQh7cZ9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "housing_features = [tf.feature_column.numeric_column(\"total_rooms\")]\n",
    "\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=housing_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IY422qVBPhy"
   },
   "source": [
    "### Input Function\n",
    "\n",
    "The LinearRegressor that we just created is still not trained. To train the model we need to call the [train](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#train) method and pass it an input function that feeds the regressor data.\n",
    "\n",
    "The input function is responsible for creating the TensorFlow [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset). Let's look at a basic input function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05R0-6Da3axE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "def training_input():\n",
    "  # First, we extract the features that we want to use to\n",
    "  # train the model. In this case we are using the total_rooms\n",
    "  # series from our housing data DataFrame.\n",
    "  features = {\n",
    "    'total_rooms': training_df['total_rooms'],\n",
    "  }\n",
    "  \n",
    "  # Next we extract our labels (also called targets) from\n",
    "  # the housing data DataFrame.\n",
    "  labels = training_df['median_house_value']\n",
    "\n",
    "  # We now create a TensorFlow Dataset object using the features\n",
    "  # and labels.\n",
    "  training_ds = Dataset.from_tensor_slices((features,labels))\n",
    "\n",
    "  # We tell the Dataset to shuffle the order of the rows of data\n",
    "  # passed to TensorFlow. We already shuffled the data once in\n",
    "  # Pandas in order to create a training and testing set. We are\n",
    "  # shuffling again because the data will be fed to TensorFlow\n",
    "  # multiple times in batches. Shuffling adds some randomness\n",
    "  # between batches.\n",
    "  training_ds = training_ds.shuffle(buffer_size=10000)\n",
    "\n",
    "  # We set the batch size. This will be the number of rows of\n",
    "  # data that TensorFlow will operate on in each step of the\n",
    "  # optimization.\n",
    "  training_ds = training_ds.batch(100)\n",
    "\n",
    "  # We now tell the Dataset to feed the entire training set five\n",
    "  # times to the model.\n",
    "  training_ds = training_ds.repeat(5)\n",
    "\n",
    "  # And finally we return the Dataset to TensorFlow so that\n",
    "  # the model can be trained.\n",
    "  return training_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WczWK_rFnHV"
   },
   "source": [
    "### Train\n",
    "\n",
    "At this point training is as easy as calling the `train` method on the regressor and passing it the input function that we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m32hOayrFuYQ"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "linear_regressor.train(\n",
    " input_fn=training_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89rdMHaJ_zC3"
   },
   "source": [
    "We can see in the above output how TensorFlow's LinearRegressor will tell us, as it's training, what the loss is as the model improves. This output can be useful when, later on, we'll tweak the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5u5awVpG-97"
   },
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "We have built and trained a `LinearRegressor`. Let's now use our regressor to make predictions about our test data and see how accurate it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzhWiGIzHQAw"
   },
   "source": [
    "### Input Function\n",
    "\n",
    "We need a way to get the features that we'll be using for testing into our model for predictions. To do this we'll create an input function similar to the one above that we created for training.\n",
    "\n",
    "You'll notice that the input function for prediction is much simpler than that for training. We simply need to create a `Dataset` containing the features that we'd like to use for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZphAewXsHgKp"
   },
   "outputs": [],
   "source": [
    "def testing_input():\n",
    "  # Extract the features that we'd like to use for\n",
    "  # prediction from our Pandas DataFrame.\n",
    "  features = {\n",
    "    'total_rooms': testing_df['total_rooms'],\n",
    "  }\n",
    "\n",
    "  # Create a TensorFlow Dataset of those features.\n",
    "  testing_ds = Dataset.from_tensor_slices(features)\n",
    "\n",
    "  # Set the batch size. The exact value isn't too\n",
    "  # important here since we aren't training and only\n",
    "  # need to send each row of data to TensorFlow once.\n",
    "  # Batch size is a required setting, so we just set\n",
    "  # it to one for this case.\n",
    "  testing_ds = testing_ds.batch(1)\n",
    "\n",
    "  return testing_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7qke3gvShNkX"
   },
   "source": [
    "### Make Predictions\n",
    "\n",
    "Now we need to make predictions using our test features. To do that we pass our testing input function to the `predict` method on our trained linear regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGds4R4fhSZL"
   },
   "outputs": [],
   "source": [
    "predictions_node = linear_regressor.predict(\n",
    "  input_fn=testing_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oi6Hv0mhhcsx"
   },
   "source": [
    "That runs pretty fast... almost suspiciously fast. The reason is that the model isn't actually making predictions at this point. We have just built the graph to make predictions. Since TensorFlow uses lazy execution the predictions won't be made until we ask for them.\n",
    "\n",
    "Let's go ahead and get the predictions and put them in a NumPy array so that we can calculate our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twhy8Q7hhv9T"
   },
   "outputs": [],
   "source": [
    "predictions = np.array([item['predictions'][0] for item in predictions_node])\n",
    "print(\"Our predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PMlmcvIdh1iE"
   },
   "source": [
    "### Evaluate Model\n",
    "\n",
    "Now that we have predictions we can compare them to our actual values and evaluate the quality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKUugsQTiBeH"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, testing_df['median_house_value'])\n",
    "print(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\n",
    "\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Gv12Vavif8O"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1tRI52Vxihh0"
   },
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PpoW4JOm3Xa"
   },
   "source": [
    "TensorFlow offers a variety of optimizers. We accepted the default in our example above. In this exercise we'll choose our own optimizer.\n",
    "\n",
    "1. Check out the documentation for the [GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer).\n",
    "1. Create an instance of `GradientDescentOptimizer` with a learning rate of 0.0000001 in the code block below.\n",
    "1. Wrap the optimizer with a call to [tf.contrib.estimator.clip_gradients_by_norm](https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/clip_gradients_by_norm) with a clip norm of 5.0.\n",
    "1. Create a new `LinearRegressor`, passing it your new optimizer.\n",
    "\n",
    "Is your root mean squared error better with this new optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T1w-bNP9av2"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XxK53QSjE_V"
   },
   "outputs": [],
   "source": [
    "gd_optimizer = None # TODO: Create the optimizer here\n",
    "\n",
    "#TODO: Clip the optimizer here\n",
    "\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=housing_features,\n",
    "    # TODO: Plug a new optmizer in right here\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "linear_regressor.train(\n",
    " input_fn=training_input,\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions_node = linear_regressor.predict(\n",
    "  input_fn=testing_input,\n",
    ")\n",
    "\n",
    "# Convert the predctions to a NumPy array\n",
    "predictions = np.array([item['predictions'][0] for item in predictions_node])\n",
    "\n",
    "# Find the RMSE\n",
    "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['median_house_value']))\n",
    "root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-1-key-1"
   },
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-1-solution-1"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8zRmh7z9eRw"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4S697oP9fGt"
   },
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gt9ks2W9gpg"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSaybPnhlnSx"
   },
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpVHdK9Qm-SQ"
   },
   "source": [
    "In this exercise we will build a model using a different feature. Choose a feature, say `housing_median_age` and use it in the place of `total_rooms`.\n",
    "\n",
    "To do this you will need to:\n",
    "\n",
    "1. Create a new training input function that uses the alternative feature\n",
    "1. Create a new testing input function that use the alternative feature\n",
    "1. Create a `LinearRegressor`\n",
    "1. Train the model\n",
    "1. Make predictions\n",
    "1. Measure RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLmealg79jUx"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZvBCdvNDovB3"
   },
   "outputs": [],
   "source": [
    "def training_input():\n",
    "  # Your code goes here\n",
    "  pass\n",
    "\n",
    "def testing_input():\n",
    "  # Your code goes here\n",
    "  pass\n",
    "\n",
    "housing_features = [] # TODO: Choose your housing features\n",
    "\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=housing_features,\n",
    "    # TODO: Use a custom optimizer and explore other hyperparameters if you would like \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "linear_regressor.train(\n",
    " input_fn=training_input,\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions_node = linear_regressor.predict(\n",
    "  input_fn=testing_input,\n",
    ")\n",
    "\n",
    "# Convert the predctions to a NumPy array\n",
    "predictions = np.array([item['predictions'][0] for item in predictions_node])\n",
    "\n",
    "# Find the RMSE\n",
    "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['median_house_value']))\n",
    "root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-2-key-1"
   },
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-2-solution-1"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVVbRXIq9my7"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UqYD6r189neW"
   },
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGmWQkxx9oq7"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdWPUISu0Jge"
   },
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7HDd7LOnC7l"
   },
   "source": [
    "In this exercise we will build a model using a multiple features. Choose a group of features and then:\n",
    "\n",
    "1. Create a new training input function that uses the multiple features\n",
    "1. Create a new testing input function that uses the multiple features\n",
    "1. Create a `LinearRegressor`\n",
    "1. Train the model\n",
    "1. Make predictions\n",
    "1. Measure RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omvDa39B9qbx"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvavoMsW0bUI"
   },
   "outputs": [],
   "source": [
    "def training_input():\n",
    "  # TODO: Your code goes here\n",
    "  pass\n",
    "\n",
    "def testing_input():\n",
    "  # TODO: Your code goes here\n",
    "  pass\n",
    "\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=housing_features,\n",
    "    # TODO: Use a custom optimizer and explore other hyperparameters if you would like \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "linear_regressor.train(\n",
    " input_fn=training_input,\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions = linear_regressor.predict(\n",
    "  input_fn=testing_input,\n",
    ")\n",
    "\n",
    "# Convert the predctions to a NumPy array\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "# Find the RMSE\n",
    "root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, testing_df['median_house_value']))\n",
    "root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-3-key-1"
   },
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-3-solution-1"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arG8rq_F9uxq"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQyDEeVD9vuP"
   },
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39AyEGc39wzq"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YSzFB2u0zBi"
   },
   "source": [
    "## Exercise 4: Challenge (Ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oL_KnBxCnHVP"
   },
   "source": [
    "Given the [Kaggle Black Friday Sales](https://www.kaggle.com/mehdidag/black-friday) dataset use a TensorFlow `LinearRegressor` to predict the total price of the purchases for the day. This is the `sum(purchase)` for a shopper.\n",
    "\n",
    "Features can include some combination of their **age**, **gender**, **occupation**, **city_category**, **stay_in_current_city_years**, and **marital_status**. Product and category data should not be used.\n",
    "\n",
    "The data should be grouped by user for analysis.\n",
    "\n",
    "Play with different optimizers, model settings, and data parameters (batch size, repeat, etc) to achieve the lowest RMSE that you can.\n",
    "\n",
    "Work will likely include:\n",
    "\n",
    "* Loading the data into Colab\n",
    "* Examining the data quality\n",
    "* Aggregating the data by user\n",
    "* Examining the data\n",
    "* Test/train split\n",
    "* Building an input function for training\n",
    "* Building an input function for testing\n",
    "* Train model\n",
    "* Make predictions\n",
    "* Measure RSME\n",
    "* Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbvxT8tS9yor"
   },
   "source": [
    "### Student Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzDfx_-v00Qp"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-4-key-1"
   },
   "source": [
    "### Answer Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exercise-4-solution-1"
   },
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDU_TpGC91hm"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_z98hv3893lS"
   },
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHKpv9r295f9"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "copyright",
    "exercise-1-key-1",
    "exercise-2-key-1",
    "exercise-3-key-1",
    "exercise-4-key-1"
   ],
   "name": "Regression with TensorFlow",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
