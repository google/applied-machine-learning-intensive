{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative Adversarial Networks",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7PLP9Q30PKtv",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f5W9rkuBmBu9"
      },
      "source": [
        "# Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zIykBQbYXrXA"
      },
      "source": [
        "Generative Adversarial Networks (GANs) have been gaining immense popularity since the [first paper](https://arxiv.org/abs/1406.2661) was published in 2014.  Since then there have been numerous innovations in the field of GANs.  As the advent of faked images has become mainstream, so has the sophistication in in deep fakes.  GANs have been used in fashion to create life-like models that could convince even experts of their authenticity.  This module will cover the concepts: generator and a discriminator, and the different techniques used in , and the results they achieve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vSwFn8YlaDL2"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xHVHPJhSaEEM"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* GAN\n",
        "* DCGAN\n",
        "* CGAN\n",
        "* CycleGAN\n",
        "* CoGAN\n",
        "* ProGAN\n",
        "* WGAN\n",
        "* SAGAN\n",
        "* BigGAN\n",
        "* StyleGAN\n",
        "* Implement Style Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGrUipVEawYy"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* RNN\n",
        "* Autoencoders\n",
        "* CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0bExBYnwa7i2"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "60 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SavoD7IUa-vY"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Attempted exercise, but code does not run |\n",
        "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
        "| 3      | Exercise completed successfully |\n",
        "\n",
        "There are 2 exercises in this Colab so there are 6 points available. The grading scale will be 6 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G8u2lYRWbE37"
      },
      "source": [
        "## Generative Adversarial Networks (GANs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2SxCqR9qVf5",
        "colab_type": "text"
      },
      "source": [
        "The images below show the innovation progress in GANs.  Each of the images below was generated by training on images of faces. The fellow from 2017 shows a pretty striking image of a celebrity who does not exist.  And now, with the ubiquity of facial image training data on the internet, it is possible to generate a face of a non-celebrity in 2018."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yfi21QDa_Oe",
        "colab_type": "text"
      },
      "source": [
        "### GAN Celebrity Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBf71pZToiWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "\n",
        "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">4.5 years of GAN progress on face generation. <a href=\"https://t.co/kiQkuYULMC\">https://t.co/kiQkuYULMC</a> <a href=\"https://t.co/S4aBsU536b\">https://t.co/S4aBsU536b</a> <a href=\"https://t.co/8di6K6BxVC\">https://t.co/8di6K6BxVC</a> <a href=\"https://t.co/UEFhewds2M\">https://t.co/UEFhewds2M</a> <a href=\"https://t.co/s6hKQz9gLz\">https://t.co/s6hKQz9gLz</a> <a href=\"https://t.co/F9Dkcfrq8l\">pic.twitter.com/F9Dkcfrq8l</a></p>&mdash; Ian Goodfellow (@goodfellow_ian) <a href=\"https://twitter.com/goodfellow_ian/status/1084973596236144640?ref_src=twsrc%5Etfw\">January 15, 2019</a></blockquote>\n",
        "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h156KMBitLR-",
        "colab_type": "text"
      },
      "source": [
        "### Obama Deepfake video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1toKe2vRsMAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/cQ54GDm1eL0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7cS_rDS4NYx",
        "colab_type": "text"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg-ooxjM4RwA",
        "colab_type": "text"
      },
      "source": [
        "A GAN is not like a typical model that we have seen, that tries to predict something given some input.  It is not just one artificial neural network, but 2 competing, or adversarial networks.  Rather than competing in chess they are entangled in a counterfeiting operation.  The counterfeiter is the generator, **G**, who is fed input data, and **D**, is the discriminator who is auditing the counterfeits as they are produced.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeDL8z6IIvBW",
        "colab_type": "text"
      },
      "source": [
        "## Style Transfer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ_VB9LBIw67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wroNtzSWKuOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASlzKH7rKyBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import functools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qfGgzEQK3Mm",
        "colab_type": "text"
      },
      "source": [
        "### Download content and style images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsNkW2eCK8b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_path = tf.keras.utils.get_file('turtle.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Green_Sea_Turtle_grazing_seagrass.jpg')\n",
        "style_path = tf.keras.utils.get_file('kandinsky.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a62FykFsLDUA",
        "colab_type": "text"
      },
      "source": [
        "Load image and set max dimensions to 512 px."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StJ-U_YnK9Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img(path_to_img):\n",
        "  max_dim = 512\n",
        "  img = tf.io.read_file(path_to_img)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYF_kjxLLNI6",
        "colab_type": "text"
      },
      "source": [
        "Display image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5R3j65dLOgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(image, title=None):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV1k-B1pLQcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content_image, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style_image, 'Style Image')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-kIiav_NLI1",
        "colab_type": "text"
      },
      "source": [
        "### Set style and content representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdC9eDQ2LSE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.keras.applications.vgg19.preprocess_input(content_image*255)\n",
        "x = tf.image.resize(x, (224, 224))\n",
        "vgg = tf.keras.applications.VGG19(include_top=True, weights='imagenet')\n",
        "prediction_probabilities = vgg(x)\n",
        "prediction_probabilities.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhBRDF26Neq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[0]\n",
        "[(class_name, prob) for (number, class_name, prob) in predicted_top_5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ScF2ldpOHOy",
        "colab_type": "text"
      },
      "source": [
        "Load VGG19 with penultimate layer removed from classification head and list layer names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gA2eDUPLMnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "\n",
        "print()\n",
        "for layer in vgg.layers:\n",
        "  print(layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMOCrIM5OfS7",
        "colab_type": "text"
      },
      "source": [
        "Choose intermediate layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI4uuq27OeB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Content layer where will pull our feature maps\n",
        "content_layers = ['block5_conv2'] \n",
        "\n",
        "# Style layer of interest\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1', \n",
        "                'block4_conv1', \n",
        "                'block5_conv1']\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RumqvA5OrT_",
        "colab_type": "text"
      },
      "source": [
        "#### Intermediate layers for style and content\n",
        "\n",
        "The intermediate outputs of the pretrained image model allow us to extract the defining features of both content and style images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_jFZ648PDAT",
        "colab_type": "text"
      },
      "source": [
        "### Building the Model\n",
        "\n",
        "Use Keras to define the inputs and outputs of the model.  The function below will use the pretrained model, VGG19 and return a list of the intermediate layer outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVa_YJ7nPdJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg_layers(layer_names):\n",
        "  \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
        "  # Load our model. Load pretrained VGG, trained on imagenet data\n",
        "  vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "  vgg.trainable = False\n",
        "  \n",
        "  outputs = [vgg.get_layer(name).output for name in layer_names]\n",
        "\n",
        "  model = tf.keras.Model([vgg.input], outputs)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKaJsGduPpg8",
        "colab_type": "text"
      },
      "source": [
        "Now assemble the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1oM-u7VPekR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_extractor = vgg_layers(style_layers)\n",
        "style_outputs = style_extractor(style_image*255)\n",
        "\n",
        "#Look at the statistics of each layer's output\n",
        "for name, output in zip(style_layers, style_outputs):\n",
        "  print(name)\n",
        "  print(\"  shape: \", output.numpy().shape)\n",
        "  print(\"  min: \", output.numpy().min())\n",
        "  print(\"  max: \", output.numpy().max())\n",
        "  print(\"  mean: \", output.numpy().mean())\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dneqY3gP0w1",
        "colab_type": "text"
      },
      "source": [
        "### Calculating Style\n",
        "\n",
        "The image's content can be described by the means and correlations across each feature map.  A Gram matrix takes the outer product of the feature vector and itself at each precise location.  It then averages the outer product over all locations.\n",
        "\n",
        "$$G^l_{cd} = \\frac{\\sum_{ij} F^l_{ijc}(x)F^l_{ijd}(x)}{IJ}$$\n",
        "\n",
        "This is implemented using the `tf.linalg.einsum` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ_UPYDjPxzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(input_tensor):\n",
        "  result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "  input_shape = tf.shape(input_tensor)\n",
        "  num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)\n",
        "  return result/(num_locations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVk-yxGbQrJ0",
        "colab_type": "text"
      },
      "source": [
        "### Extracting the Content and Style\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "810jSwepQpWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StyleContentModel(tf.keras.models.Model):\n",
        "  def __init__(self, style_layers, content_layers):\n",
        "    super(StyleContentModel, self).__init__()\n",
        "    self.vgg =  vgg_layers(style_layers + content_layers)\n",
        "    self.style_layers = style_layers\n",
        "    self.content_layers = content_layers\n",
        "    self.num_style_layers = len(style_layers)\n",
        "    self.vgg.trainable = False\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"Expects float input in [0,1]\"\n",
        "    inputs = inputs*255.0\n",
        "    preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "    outputs = self.vgg(preprocessed_input)\n",
        "    style_outputs, content_outputs = (outputs[:self.num_style_layers], \n",
        "                                      outputs[self.num_style_layers:])\n",
        "\n",
        "    style_outputs = [gram_matrix(style_output)\n",
        "                     for style_output in style_outputs]\n",
        "\n",
        "    content_dict = {content_name:value \n",
        "                    for content_name, value \n",
        "                    in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "    style_dict = {style_name:value\n",
        "                  for style_name, value\n",
        "                  in zip(self.style_layers, style_outputs)}\n",
        "    \n",
        "    return {'content':content_dict, 'style':style_dict}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O69bOEkbRZQ4",
        "colab_type": "text"
      },
      "source": [
        "This function will return a gram matrix for `style_layers` and `content_layers`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VleloF-Q4d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extractor = StyleContentModel(style_layers, content_layers)\n",
        "\n",
        "results = extractor(tf.constant(content_image))\n",
        "\n",
        "style_results = results['style']\n",
        "\n",
        "print('Styles:')\n",
        "for name, output in sorted(results['style'].items()):\n",
        "  print(\"  \", name)\n",
        "  print(\"    shape: \", output.numpy().shape)\n",
        "  print(\"    min: \", output.numpy().min())\n",
        "  print(\"    max: \", output.numpy().max())\n",
        "  print(\"    mean: \", output.numpy().mean())\n",
        "  print()\n",
        "\n",
        "print(\"Contents:\")\n",
        "for name, output in sorted(results['content'].items()):\n",
        "  print(\"  \", name)\n",
        "  print(\"    shape: \", output.numpy().shape)\n",
        "  print(\"    min: \", output.numpy().min())\n",
        "  print(\"    max: \", output.numpy().max())\n",
        "  print(\"    mean: \", output.numpy().mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5IYU_IRerM",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent\n",
        "\n",
        "Now that the style and content have been extracted, style transfer is implemented using MSE.  To accomplish this, set style and content targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_fINK-4RzkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_targets = extractor(style_image)['style']\n",
        "content_targets = extractor(content_image)['content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TolXzY-7R3Vr",
        "colab_type": "text"
      },
      "source": [
        "Use `tf.Variable` to optimize. Initialize it with the content image (the `tf.Variable` must be the same shape as the content image):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-MMMk8nR9vT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = tf.Variable(content_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAij0r_aSBCd",
        "colab_type": "text"
      },
      "source": [
        "Define function to scale pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ler5TyA8SGbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_0_1(image):\n",
        "  return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPdSDqK6SJTL",
        "colab_type": "text"
      },
      "source": [
        "Initialize the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6dUwVc6SM-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPok5jtSSQef",
        "colab_type": "text"
      },
      "source": [
        "So the optimization works, use a weighted combination of the losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsN6zcp1SXN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_weight=1e-2\n",
        "content_weight=1e4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV1_TbTVSagR",
        "colab_type": "text"
      },
      "source": [
        "### Create loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHxeTAuNSgAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_content_loss(outputs):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "    style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) \n",
        "                           for name in style_outputs.keys()])\n",
        "    style_loss *= style_weight / num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) \n",
        "                             for name in content_outputs.keys()])\n",
        "    content_loss *= content_weight / num_content_layers\n",
        "    loss = style_loss + content_loss\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCYLroqJSiiD",
        "colab_type": "text"
      },
      "source": [
        "Now update the image with `tf.GradientTape`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta4WLv1ZSphH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function()\n",
        "def train_step(image):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = extractor(image)\n",
        "    loss = style_content_loss(outputs)\n",
        "\n",
        "  grad = tape.gradient(loss, image)\n",
        "  opt.apply_gradients([(grad, image)])\n",
        "  image.assign(clip_0_1(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSR6ovRoSuMS",
        "colab_type": "text"
      },
      "source": [
        "Test algorithm by running several steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V70XY61bSygQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_step(image)\n",
        "train_step(image)\n",
        "train_step(image)\n",
        "plt.imshow(image.read_value()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAsHbF-kS6po",
        "colab_type": "text"
      },
      "source": [
        "It looks like some of the style from Kandinsky is transferring to the turtle image.  Now, since it is working, run the optimization for a longer time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN84c8LPTMa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "epochs = 10\n",
        "steps_per_epoch = 100\n",
        "\n",
        "step = 0\n",
        "for n in range(epochs):\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1\n",
        "    train_step(image)\n",
        "    print(\".\", end='')\n",
        "  display.clear_output(wait=True)\n",
        "  imshow(image.read_value())\n",
        "  plt.title(\"Train step: {}\".format(step))\n",
        "  plt.show()\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time: {:.1f}\".format(end-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu513FOUUGDR",
        "colab_type": "text"
      },
      "source": [
        "## Total variation loss\n",
        "\n",
        "This basic implementation produces a lot of high frequency artifacts. Decrease these using an explicit regularization term on the high frequency components of the image.This is often called the *total variation loss* in Style Transfer applications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf9leDFyTOYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def high_pass_x_y(image):\n",
        "  x_var = image[:,:,1:,:] - image[:,:,:-1,:]\n",
        "  y_var = image[:,1:,:,:] - image[:,:-1,:,:]\n",
        "\n",
        "  return x_var, y_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTEIovA1UacL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_deltas, y_deltas = high_pass_x_y(content_image)\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.subplot(2,2,1)\n",
        "imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Original\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Original\")\n",
        "\n",
        "x_deltas, y_deltas = high_pass_x_y(image)\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "imshow(clip_0_1(2*y_deltas+0.5), \"Horizontal Deltas: Styled\")\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "imshow(clip_0_1(2*x_deltas+0.5), \"Vertical Deltas: Styled\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r8bs-AjUgzk",
        "colab_type": "text"
      },
      "source": [
        "You can see the edge detection from the content, and then the styled image.  \n",
        "\n",
        "Now try the sobel edge detector on the content image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnpEhh1vU3aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "sobel = tf.image.sobel_edges(content_image)\n",
        "plt.subplot(1,2,1)\n",
        "imshow(clip_0_1(sobel[...,0]/4+0.5), \"Horizontal Sobel-edges\")\n",
        "plt.subplot(1,2,2)\n",
        "imshow(clip_0_1(sobel[...,1]/4+0.5), \"Vertical Sobel-edges\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMVqh6xJVC0e",
        "colab_type": "text"
      },
      "source": [
        "Calculate total regularization loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O46j-WDVVID_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def total_variation_loss(image):\n",
        "  x_deltas, y_deltas = high_pass_x_y(image)\n",
        "  return tf.reduce_mean(x_deltas**2) + tf.reduce_mean(y_deltas**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAE2jKW7VLsO",
        "colab_type": "text"
      },
      "source": [
        "Now rerun total optimization and choose a weight for the loss, and include it in a `train_step` loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWRPEyJxVlZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_variation_weight=1e8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPK_BOTvVfBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function()\n",
        "def train_step(image):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = extractor(image)\n",
        "    loss = style_content_loss(outputs)\n",
        "    loss += total_variation_weight*total_variation_loss(image)\n",
        "\n",
        "  grad = tape.gradient(loss, image)\n",
        "  opt.apply_gradients([(grad, image)])\n",
        "  image.assign(clip_0_1(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sclYlFORVoK9",
        "colab_type": "text"
      },
      "source": [
        "Reinitialize the optimization var:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urfWq3cVVrqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = tf.Variable(content_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NT6rXC4Vuzx",
        "colab_type": "text"
      },
      "source": [
        "### Run the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_l6JFerVxlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "epochs = 10\n",
        "steps_per_epoch = 100\n",
        "\n",
        "step = 0\n",
        "for n in range(epochs):\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1\n",
        "    train_step(image)\n",
        "    print(\".\", end='')\n",
        "  display.clear_output(wait=True)\n",
        "  imshow(image.read_value())\n",
        "  plt.title(\"Train step: {}\".format(step))\n",
        "  plt.show()\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total time: {:.1f}\".format(end-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5WFLU7hWbO8_"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* [Style Transfer Code](https://www.tensorflow.org/beta/tutorials/generative/style_transfer)\n",
        "* [Goodfellow et. al](https://arxiv.org/abs/1406.2661)\n",
        "* [GAN Survey](https://blog.floydhub.com/gans-story-so-far/)\n",
        "* [Implemented GANS in 50 LOC](https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f)\n",
        "* [Intro to GANs](https://towardsdatascience.com/understanding-and-optimizing-gans-going-back-to-first-principles-e5df8835ae18)\n",
        "* [VAE + GAN](https://medium.com/artists-and-machine-intelligence/generative-machine-learning-on-the-cloud-1ccdfeb33ea2)\n",
        "* [Pix2Pix with Eager execution](https://research.google.com/seedbank/seed/pixpix_with_eager_execution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Swt2fxm-fG_B"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWq38ASlb2aY"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWq38ASlb2aX"
      },
      "source": [
        "Upload new content and style images, and create a fresh work of art!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYZEXNK1VDIJ"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TI_WxOyjcfNu",
        "colab": {}
      },
      "source": [
        "# Your answer goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKb-7oqrcfox",
        "colab": {}
      },
      "source": [
        "# Put the recommended solution here; if there is more than one \"good\" solution\n",
        "# that you think students should know put those solutions in subsequent code\n",
        "# boxes with \"# Solution\" in the first line."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5EndkJMJVKjw"
      },
      "source": [
        "**Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SgzIrUK1dFdQ",
        "colab": {}
      },
      "source": [
        "# If the solution can be auto-graded, perform the autograding here."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}