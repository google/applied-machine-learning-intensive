{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification with scikit-learn",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "copyright",
        "exercise-1-key-1",
        "exercise-2-key-1",
        "exercise-3-key-1",
        "exercise-4-key-1",
        "exercise-5-key-1",
        "exercise-6-key-1",
        "exercise-7-key-1",
        "exercise-8-key-1",
        "exercise-9-key-1",
        "exercise-10-key-1",
        "exercise-11-key-1",
        "exercise-12-key-1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTI6TJZfOdZH",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ZfzpqO9atfK"
      },
      "source": [
        "# Classification with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S8pjZcxYWZ8Y"
      },
      "source": [
        "It's time to take what we've learned about the concepts of classification and see how software tools help us to accomplish this task using software.\n",
        "For this Colab, we will be using a Python library called scikit-learn. Scikit-learn is a Machine-Learning library for Python built on top of numpy that provides a\n",
        "lot of functionality for classification, regression, clustering and many other Machine-Learning tasks.\n",
        "\n",
        "Even just in the context of classification, it provides many different standard algorithms to perform that task such as Nearest Neighbors, Decision Tree, Naive Bayes\n",
        "and many others. This [page](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py)\n",
        "provides a complete list and shows some interesting visualizations of how the different classification algorithms compare on three small datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S-it-gNTOuK4"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X7djifpMOvm8"
      },
      "source": [
        "### Learning Objectives\n",
        "\n",
        "* Create a classification model with scikit-learn.\n",
        "* Use scikit-learn to make classification predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NiUF4EoxO-Vk"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "* Introduction to Colab\n",
        "* Intermediate Python\n",
        "* Intermediate Pandas\n",
        "* Visualizations\n",
        "* Introduction to scikit-learn\n",
        "* Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VXB_yHF7PIon"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "60 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1sPvH4sVPKms"
      },
      "source": [
        "### Grading Criteria\n",
        "\n",
        "Each exercise is worth 3 points. The rubric for calculating those points is:\n",
        "\n",
        "| Points | Description |\n",
        "|--------|-------------|\n",
        "| 0      | No attempt at exercise |\n",
        "| 1      | Attempted exercise, but code does not run |\n",
        "| 2      | Attempted exercise, code runs, but produces incorrect answer |\n",
        "| 3      | Exercise completed successfully |\n",
        "\n",
        "There is 1 exercise in this Colab so there are 3 points available. The grading scale will be 3 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a1cjMb2GPREz"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lUC2a6L5OqIl"
      },
      "source": [
        "Let's take a look at how to use scikit-learn to classify some data.\n",
        "\n",
        "---\n",
        "\n",
        "### The Iris data set\n",
        "For this example, we will be using the [Iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). This is a data set that was used in 1936 by British biologist and statistician Ronald Fisher to classify these flowers into one of three species of iris based on 4 measurements:\n",
        "- The length of the petals\n",
        "- The width of the petals\n",
        "- The length of the sepals (the green petal-looking bits that are found at the base of the petals)\n",
        "- The width of the sepals\n",
        "\n",
        "![Iris](https://upload.wikimedia.org/wikipedia/commons/2/21/Blue_Iris.JPG)\n",
        "\n",
        "Conveniently, the iris data set is built-in to the scikit-learn library so it is readily available to us. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "839qQ8bWalSl",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris_bunch = datasets.load_iris()\n",
        "iris_bunch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zweFHsbUgEUL"
      },
      "source": [
        "Scikit-learn datasets are usually delivered in the form of a dictionary-like object called a `Bunch`. This `Bunch` contains the following fields:\n",
        "\n",
        "- *DESCR*: A string describing the dataset.\n",
        "- *data*: An array containing the features we are using for classifying. In this case, the four measurements listed above for each of 150 plants.\n",
        "- *feature_names*: Labels for the data.\n",
        "- *filename*: the file that this data came from.\n",
        "- *target*: the values that we are trying to classify these flowers into. In this case, since we are dealing with three species of iris, we use three numbers 0, 1 and 2 to identify each species.\n",
        "- *target_names*: labels for the target values. In this case, 0 refers to the setosa species, 1 to the versicolor specie and 2 to the virginica species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wvjklYlhIafY"
      },
      "source": [
        "So that we don't get our species crossed, let us first create some named variables for each target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZL2nk8KQIViC",
        "colab": {}
      },
      "source": [
        "SETOSA = 0\n",
        "VERSICOLOR = 1\n",
        "VIRGINICA = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GqOmZ2ORJhTj"
      },
      "source": [
        "We'll also create a list of columns that we'll use for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMqyeotgJoAo",
        "colab": {}
      },
      "source": [
        "FEATURES = iris_bunch['feature_names']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fQiAihz5DCfP"
      },
      "source": [
        "Next we will load the feature and target data into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z4df5QLtC8kK",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris_df = pd.DataFrame(iris_bunch['data'], columns=FEATURES)\n",
        "iris_df['species'] = iris_bunch['target']\n",
        "iris_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8NjnaQldDJLl"
      },
      "source": [
        "Let's take a look at a description of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNZ2fI-gDWMF",
        "colab": {}
      },
      "source": [
        "iris_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9mEyzlzmDkNR"
      },
      "source": [
        "There are 150 data points. No columns seem to be missing data and no values seem to be too far out of expected ranges. For example, there are no zero or negative lengths or widths and the length and width values fall well within what we'd expect for a tulip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7sOwA2U2EAJs"
      },
      "source": [
        "We are interested in using the measurement features to predict the species of an iris. Let's take a closer look at the values we'll be predicting.\n",
        "\n",
        "In this case we'll group by our 'species' feature and get a count of each species in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FPb2c7WZD4P_",
        "colab": {}
      },
      "source": [
        "iris_df.groupby('species').agg('count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WZQxmfnFkFw9"
      },
      "source": [
        "So we have 50 examples of each kind of iris. When we go to do a train/test split, we could rely on a random split, but that would lead to some cases where a type of iris never made it into the test set or a type of iris was very over or under represented in one of the sets.\n",
        "\n",
        "Instead of relying on pure randomness in our split, we will perform a **stratified** split. This allows us to randomly split the data while keeping the ratio or iris types equivalent in each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s0BhenEm_sd0",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test  = train_test_split(\n",
        "  iris_df,                      # split our iris dataframe\n",
        "  stratify=iris_df['species'],  # stratify by the species column   \n",
        "  test_size=0.2,                # 20% of the data should be held for testing\n",
        "  random_state=42               # hard-coded random state for repeatability in the example\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NUydHbohFk2w"
      },
      "source": [
        "We can now verify that the test set has roughly the same count of each type of iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gkAEKt9dFpxV",
        "colab": {}
      },
      "source": [
        "test.groupby('species').agg('count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QS6Jp8nLFrP2"
      },
      "source": [
        "As does the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Wv2b5WeFtFD",
        "colab": {}
      },
      "source": [
        "train.groupby('species').agg('count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CLgpKyKKjhz4"
      },
      "source": [
        "## Training a binary classifier\n",
        "\n",
        "Now that our data is prepared, our first classification task will be to create a classifier that distinguishes versicolor irises from the rest. In other words, rather than considering three classes of outcome (one for each species), we'll just care about two: \"versicolor\" and \"not versicolor\". This makes our classifier a binary classifier. This also requires us to use a different target than the one supplied with the data set.\n",
        "\n",
        "We will add an 'is_versicolor' column to our training and testing data. This new column will be the target for our binary classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dLuAmn2dGDWK",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train = train.assign(is_versicolor=train['species'] == VERSICOLOR)\n",
        "test = test.assign(is_versicolor=test['species'] == VERSICOLOR)\n",
        "\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fnZ9GAkwq72V"
      },
      "source": [
        "At this point, we could use several of scikit-learn's classifiers to classify our data but let's start with the [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) classifier, using the `SGDClassifier` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7oseMj3ipq87",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "binary_classifier = linear_model.SGDClassifier(\n",
        "  random_state=33, # Specifying random state allow us to get repeatable outcomes\n",
        "  tol=1e-3, \n",
        "  max_iter=500) \n",
        "\n",
        "binary_classifier.fit(train[FEATURES], train['is_versicolor'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xep1QArVsei0"
      },
      "source": [
        "So how well did we do? Let's take a look at a test iris that we know is versicolor and see if we can correctly predict the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jsWrIpgsseNh",
        "colab": {}
      },
      "source": [
        "# Grab the first versicolor flower in our test dataset.\n",
        "flower = test[test['is_versicolor']].iloc[0]\n",
        "\n",
        "# Predict if that flower is a versicolor flower or not.\n",
        "binary_classifier.predict([flower[FEATURES]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gm_BpdB1thG7"
      },
      "source": [
        "So the classifier is able to identify this test flower as versicolor (True) but how can we evaluate how good our classifier is?\n",
        "\n",
        "## Evaluating our classifier\n",
        "\n",
        "One way to measure the accuracy of our classifier is to use cross-validation.\n",
        "Scikit-Learn makes that easy for us to do by providing the `cross_val_score` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bjRKSX3ir0nk",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "model_selection.cross_val_score(\n",
        "  binary_classifier, \n",
        "  test[FEATURES],\n",
        "  test['is_versicolor'],\n",
        "  cv=3,\n",
        "  scoring=\"accuracy\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yecT90FovLRA"
      },
      "source": [
        "63-70% seems like a pretty good result for our classifier. But it's not. Keep in mind that 66.6% of the flowers are not versicolor so a model that always predict False would get pretty close!\n",
        "\n",
        "It's important to remember when you're dealing with data that isn't evenly split between the classes that accuracy needs to factor in the distribution data. \n",
        "\n",
        "A classic example of this would be a medical test to detect a rare disease. A test that always returned False would be correct a high percentage of the time but completely fail to meet its purpose. See an illustration of this principle in [this article](https://www.scientificamerican.com/article/what-is-bayess-theorem-an/).\n",
        "\n",
        "### Confusion matrix\n",
        "\n",
        "To look at how well our model is really doing, we need to consider the number of items that we correctly identify as being part of our class (true positives) or out of our class (true negatives) as well as the number that incorrectly identify as part of our class (false positives) and incorrectly identify as not part of our class (false negatives).\n",
        "\n",
        "A confusion matrix for a binary classifier is a matrix made up of those four values:\n",
        "\n",
        "<table>\n",
        "<tr><td>True negatives<td>False positives</tr>\n",
        "<tr><td>False negatives<td>True positives</tr>\n",
        "</table>\n",
        "\n",
        "Scikit-Learn makes it easy to get this matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RD0ZW-j0u1DV",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "predictions = model_selection.cross_val_predict(\n",
        "  binary_classifier,\n",
        "  test[FEATURES],\n",
        "  test['is_versicolor'],\n",
        "  cv=3\n",
        ")\n",
        "\n",
        "metrics.confusion_matrix(test['is_versicolor'], predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "maQk30RouO6K"
      },
      "source": [
        "This matrix represents the behavior of our classifier:\n",
        "- Each row represents an actual class. In this case, the first row represents the 20 flowers that are not versicolor, the second represents the 10 flowers that are.\n",
        "- Each column represents a predicted class. In this case, the first column represents the 22 flowers that our classifier identified as not versicolor and  the second column represents the 8 flowers that were identified as versicolor\n",
        "\n",
        "We can then use these values to analyze our model. Two metrics that are commonly used to summarize the behavior of a classifier are precision (percentage of identified positives that are correct) and recall (percentage of positives that are correctly identified)\n",
        "\n",
        "Scikit-Learn also allows us to extract those values directly without going through the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5C76Kidt78B",
        "colab": {}
      },
      "source": [
        "precision = metrics.precision_score(test['is_versicolor'], predictions)\n",
        "recall = metrics.recall_score(test['is_versicolor'], predictions)\n",
        "\n",
        "print(\"Precision: {}\\nRecall: {}\".format(precision, recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T7HCyjqwrwvx"
      },
      "source": [
        "Our model isn't looking so good anymore! \n",
        "\n",
        "We can try to increase precision or recall by adjusting the threshold that our classifier uses to determine whether an item belongs in a class. The classifier computes a value for each item in our data set and items that correspond to a value over the threshold are deemed to be in the class and those below the threshold are deemed not in the class. \n",
        "\n",
        "For example, if we use our test data we can get the scores that our classifier assigned to each flower:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhtVlH1lryWm",
        "colab": {}
      },
      "source": [
        "# What scores does or model generate?\n",
        "scores = binary_classifier.decision_function(test[FEATURES])\n",
        "\n",
        "# What predictions are made?\n",
        "predictions = binary_classifier.predict(test[FEATURES])\n",
        "\n",
        "# What is the actual value that should have been predicted?\n",
        "actuals = test['is_versicolor']\n",
        "\n",
        "# Store everything in a DataFrame\n",
        "df = pd.DataFrame({\n",
        "  'Scores': scores,\n",
        "  'Predictions': predictions,\n",
        "  'Actuals': actuals\n",
        "})\n",
        "\n",
        "# Output the data sorted by score\n",
        "df[['Scores', 'Predictions', 'Actuals']].sort_values(by=['Scores'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eq9rkpk9saQP"
      },
      "source": [
        "By default, Scikit-Learn uses a threshold of 0 so any flower that scores > 0 is going to be deemed part of versicolor.\n",
        "\n",
        "We can affect the decisions that the classifier is making by setting our own value for threshold.\n",
        "\n",
        "Scikit-Learn does not allow us to specify a different threshold when training the classifier but we can use the output of `decision_function` to make our own prediction with our own threshold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "htGn6oyqsbNb",
        "colab": {}
      },
      "source": [
        "threshold = 20\n",
        "predictions = (scores > threshold)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QfjxZ4hQuFSq"
      },
      "source": [
        "It's hard to tell if we're doing better since the samples are scrambled so we go back to precision and recall: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MgDw89lsvGHY",
        "colab": {}
      },
      "source": [
        "precision = metrics.precision_score(test['is_versicolor'], predictions)\n",
        "recall = metrics.recall_score(test['is_versicolor'], predictions)\n",
        "\n",
        "print(\"Precision: {}\\nRecall: {}\".format(precision, recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1nd-CtYAWV72"
      },
      "source": [
        "By lowering the threshold, we've improved the recall but lost some precision in our model. \n",
        "This is the usual trade-off when tweaking the threshold that we are using. We can visualize this trade-off by using the `precision_recall_curve` function which tries many different thresholds allowing us to plot the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lb9Vj3ySRZ6M",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores = model_selection.cross_val_predict(\n",
        "  binary_classifier, \n",
        "  test[FEATURES],\n",
        "  test['is_versicolor'],\n",
        "  cv=3,\n",
        "  method=\"decision_function\"\n",
        ")\n",
        "precisions, recalls, thresholds = metrics.precision_recall_curve(\n",
        "  test['is_versicolor'],\n",
        "  scores\n",
        ")\n",
        "\n",
        "plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QHqDysloYQPv"
      },
      "source": [
        "This is (roughly) the kind of shape that we expect from this graph: as we increase the threshold, precision improves but recall drops. With a large dataset, this trend continues until precision reaches 100% and recall drops to 0.  But in this case, the data set is small enough that the overall graph looks strange when we zoom out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QOJSyAOBY6_U"
      },
      "source": [
        "We see that raising the threshold ends up hurting precision as well as recall because a few incorrectly labelled flowers end up significantly hurting our metric.\n",
        "\n",
        "Another graph that we can use to evaluate our binary classifier is the _receiver operating characteristic_ (ROC) curve. This is a complex name for a relatively simple concept, the curve  plots the true positive rate (TPR which is just recall) against the false positive rate (FPR) for various threshold values. FPR is just (1 - the true negative rate). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_XPXD7w4ZNhr",
        "colab": {}
      },
      "source": [
        "fpr, tpr, thresholds = metrics.roc_curve(test['is_versicolor'], scores)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.axis([0, 1, 0, 1])\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IRD6JpBibHUJ"
      },
      "source": [
        "The dotted line in this graph represents the behavior of a purely random classifier. The blue line represents the behavior of our classifier. The furthest away from the dotted line that our blue line is, the better our classifier. We can represent this \"furthest away\" concept numerically by measuring the area under the curve (AUC) using Scikit-Learn's built-in function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "64EYzJ2abnet",
        "colab": {}
      },
      "source": [
        "metrics.roc_auc_score(test['is_versicolor'], scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3LmPBdw5bwIA"
      },
      "source": [
        "A ROC AUC score of 1 indicates a perfect classifier, a score of 0.5 is equivalent to a random classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bbIY3s1AxC30"
      },
      "source": [
        "## Classifying into multiple classes\n",
        "\n",
        "Often times, we are not just classifying into two classes (nails vs. screws or versicolor vs. not) but into multiple classes (nails vs. screws vs. bolts or the various types of irises). Since our dataset considers three different species of flowers, it would be great to be able to predict which species a flower belongs to.\n",
        "\n",
        "Random Forest classifiers and Naive Bayes classifiers are able to handle multiple classes directly but others (like our SGD classifier) are not able to do so. Instead, we must use multiple binary classifiers to break up our data into more than two classes.\n",
        "\n",
        "One way to do is to create one classifier like the one that we created earlier (versicolor vs. not) for each class that we want to support. In this case, it would mean 3 classifiers:\n",
        "- setosa vs. not\n",
        "- versicolor vs. not\n",
        "- virginica vs. not\n",
        "\n",
        "Determining the class for a test case is then a matter of running all three classifiers and selecting the one that gives the strongest positive score. This is called the one-versus-all (OvA) strategy.\n",
        "\n",
        "Alternatively, we could train a classifier to distinguish between every pair of classes that we are trying to classify our data into. This is called the one-versus-one (OvO) strategy. In our case, it would mean 3 classifiers again:\n",
        "- setosa vs. versicolor\n",
        "- setosa vs. virginica\n",
        "- versicolor vs. virginica\n",
        "\n",
        "Although we end up with the same number of classifier in our case of dealing with 3 classes, this is not the case when dealing with more classes. As the number of classes grows, the number of classifiers for OvO grows much more rapidly (O(n^2)) than OvA (O(n)). On the other hand, each classifier for OvO only requires the data from the two classes that it is considering in order to be built whereas each classifier for OvA must consider all the training data.\n",
        "\n",
        "Luckily, Scikit-Learn hides a lot of the complexity from us. In the case of our SGD classifier, it automatically detects that we are trying to do multiclass classification and uses the OvA strategy to create multiple classifiers for us and present us with the result of comparing the outcome of the 3 classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EjgeCLB4wm9A",
        "colab": {}
      },
      "source": [
        "multi_class_classifier = linear_model.SGDClassifier(random_state=1701, tol=1e-3)  \n",
        "multi_class_classifier.fit(train[FEATURES], train['species'])   # We're not using training_target_is_versicolor anymore\n",
        "multi_class_classifier.predict([flower[FEATURES]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fTrtovnM58FN"
      },
      "source": [
        "The output is no longer a True/False value but a number representing the class that `flower` is predicted to be, in this case, 1 which indicates versicolor.\n",
        "\n",
        "We can pull back the curtain on what `SGDClassifier` is doing for us behind the scenes by using `decision_function`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QkzGAQrH5wSS",
        "colab": {}
      },
      "source": [
        "  multi_class_classifier.decision_function([flower[FEATURES]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9sFbBb0DJuO"
      },
      "source": [
        "This array represents the three scores that the three binary classifiers gave `flower`. Clearly, number 1 was the strongest score so `flower` was identified as versicolor.\n",
        "\n",
        "We can now evaluate the accuracy of this new classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u3kF47acDBTT",
        "colab": {}
      },
      "source": [
        "model_selection.cross_val_score(multi_class_classifier, test[FEATURES], test['species'], cv=3, scoring=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W-D1Yb_AEIpc"
      },
      "source": [
        "This is looking more promising than before. Although our odds of being randomly right have dropped to 33%, our model is able to predict the species of a flower with 66% accuracy.\n",
        "\n",
        "We can now compare that to how a Naive Bayes classifier would do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y1Vu3lzdEDIx",
        "colab": {}
      },
      "source": [
        "from sklearn import naive_bayes\n",
        "\n",
        "nb_classifier = naive_bayes.GaussianNB()\n",
        "nb_classifier.fit(train[FEATURES], train['species'])\n",
        "\n",
        "model_selection.cross_val_score(\n",
        "  nb_classifier,\n",
        "  train[FEATURES],\n",
        "  train['species'],\n",
        "  cv=3,\n",
        "  scoring=\"accuracy\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-NWoShLqcLq3"
      },
      "source": [
        "So it looks like a Naive Bayes classifier would do better for us for this data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TaQgAcKkFWcV"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "In these exercises we will use another sample dataset provided by Scikit Learn. This dataset contain examples of handwritten digits. We'll create a binary classifier that determines if the digit we are provided is less than or equal to three.\n",
        "\n",
        "In order to do this we'll need to:\n",
        "\n",
        "1. Load the dataset from Scikit Learn.\n",
        "1. Convert the data from a `Bunch` to a `DataFrame`.\n",
        "1. Create a synthetic column that contains the value `True` if the digit is less than or equal to three and `False` otherwise.\n",
        "1. Split the data into a train and test set, stratifying by digit.\n",
        "1. Train an SGDClassifier.\n",
        "1. Graph precision vs. recall.\n",
        "1. Create custom predictions with our own hand-selected threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MoEaQTxEtNdt"
      },
      "source": [
        "## Exercise 1: Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zeo65tX7l2VH"
      },
      "source": [
        "Scikit Learn has a built in dataset of handwritten digits. Look at the [load_digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) documentation and write code below to load the digits bunch into memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uBz4lMIoZCoe"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bcF9KyGJFB7w",
        "colab": {}
      },
      "source": [
        "digits_bunch = None # Load the digits bunch here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0N8VcSh3f35L"
      },
      "source": [
        "Now that the data is loaded, we can take a look at it. Though this is numeric we don't need to do any image manipulation. The images are represented as 64 pixels (8x8) values representing intensity from 0 to 64.\n",
        "\n",
        "In the example below we recreate the image of one of these data points. From this point on we'll just be treating the images as numerical values across 64 columns named '0' to '63'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c80bh__Ff3Mx",
        "colab": {}
      },
      "source": [
        "# Nothing to add here... this is just for illustrative purposes!\n",
        "if digits_bunch: \n",
        "  some_digit = digits_bunch['data'][400]\n",
        "  some_digit_image = some_digit.reshape(8, 8)\n",
        "\n",
        "  plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-1-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whL9dFp2ZJz0",
        "colab": {}
      },
      "source": [
        "digits_bunch = datasets.load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qxwAOVgouki0"
      },
      "source": [
        "## Exercise 2: Convert the Bunch to a Data Frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0oXJKdFl5Ez"
      },
      "source": [
        "Though it isn't strictly necessary, we have been using Pandas DataFrames throughout most of our machine learning experience so far. To keep things consistent, write code below to create a Pandas DataFrame containing 65 columns of data. The first 64 columns are the pixel intensities for the images. The columns will be named '0' through '63'. Then add in a column called 'digit' that contains the target value for each row."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LqDqpxrfZTvd"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IDl1eYaufwd",
        "colab": {}
      },
      "source": [
        "digits = None # Create your data frame here. Add the 'digit' column here or below."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-2-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VB5WhACBZVEP",
        "colab": {}
      },
      "source": [
        "digits = pd.DataFrame(digits_bunch.data)\n",
        "digits['digit'] = digits_bunch.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j7B3VE9qvQqb"
      },
      "source": [
        "## Exercise 3: Create a Synthetic Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hkgTwUZKl8BG"
      },
      "source": [
        "Use the `assign` function to create a synthetic column called 'lt_eq_3' that contains `True` values if the target digit is three or less and `False` otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WSPMALoHZeKM"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fPj2veJQvTik",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-3-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-3-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qzQXYsHYZfwL",
        "colab": {}
      },
      "source": [
        "digits = digits.assign(lt_eq_3=digits['digit'] <= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zZpldSjTvlPH"
      },
      "source": [
        "## Exercise 4: Split the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FDL9P5N9l-HN"
      },
      "source": [
        "Use `train_test_split` to split 20% of the digits data off for testing. Stratify by digit so that you get a representative sample from the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SP-KwUpNZ1Kc"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SRRDdHyDvnMX",
        "colab": {}
      },
      "source": [
        "train, test = None, None # Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-4-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-4-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0_nhK2lYZ27t",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(\n",
        "  digits,\n",
        "  stratify=digits['digit'], \n",
        "  test_size=0.2,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UAA9T67jwBxy"
      },
      "source": [
        "## Exercise 5: Create and Fit a Binary Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DztsQdmZmBrt"
      },
      "source": [
        "Create an instance of the `SGDClassifier`. Train the classifier on features '0' through '63' and target the 'lt_eq_3' column created earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_FsACOwEaL-q"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F1lkXY9DwEeV",
        "colab": {}
      },
      "source": [
        "binary_classifier = None # Your code goes here and below"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-5-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-5-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CW392EzFaQmN",
        "colab": {}
      },
      "source": [
        "binary_classifier = linear_model.SGDClassifier(\n",
        "  tol=1e-3, \n",
        "  max_iter=500) \n",
        "\n",
        "FEATURES = train.columns[:64]\n",
        "TARGET = 'lt_eq_3'\n",
        "\n",
        "binary_classifier.fit(train[FEATURES], train[TARGET])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q4t8S7JCwn_k"
      },
      "source": [
        "## Exercise 6: Get Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JCJZIqKamExd"
      },
      "source": [
        "Use the `cross_val_predict` to get scores for the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pPonNu2EauHT"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-r95ijqwvE2",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-6-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-6-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UcU3SW86aygR",
        "colab": {}
      },
      "source": [
        "scores = model_selection.cross_val_predict(\n",
        "  binary_classifier, \n",
        "  test[FEATURES],\n",
        "  test[TARGET],\n",
        "  cv=3,\n",
        "  method=\"decision_function\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tG6i68xqw4rT"
      },
      "source": [
        "## Exercise 7: Get Precision, Recall, and Thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OL0r7rnsmG-A"
      },
      "source": [
        "Use `precision_recall_curve` to get precisions, recalls, and thresholds for the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7gcmoWrxa7pq"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xq_vMcwHw7Yt",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-7-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-7-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8xrWvYa1bBRZ",
        "colab": {}
      },
      "source": [
        "precisions, recalls, thresholds = metrics.precision_recall_curve(\n",
        "  test[TARGET],\n",
        "  scores\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MksAmL-AxJBD"
      },
      "source": [
        "## Exercise 8: Plot the Precision Recall Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RDgDNr60mKAt"
      },
      "source": [
        "Use Matplotlib to plot the precision recall curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ZVwu4elbHeB"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ikE7cS1JxLp3",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-8-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-8-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oUJJvBOYbOOB",
        "colab": {}
      },
      "source": [
        "plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n",
        "plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ipbputQtw1Q0"
      },
      "source": [
        "## Exercise 9: Make New Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J-JhqUJBmNC-"
      },
      "source": [
        "Eyeballing the graph produced above, use a custom threshold to make new predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "splXb1hgbWiA"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hegKVZDkxi6r",
        "colab": {}
      },
      "source": [
        "threshold = 0 # Change to a better thresold\n",
        "predictions = None # Make new predictions here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-9-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-9-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bpvDTFlMbZPr",
        "colab": {}
      },
      "source": [
        "threshold = 1500\n",
        "predictions = (scores > threshold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFvFYaqCxqWy"
      },
      "source": [
        "## Exercise 10: Output New Precision and Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ILAsWdpmPSq"
      },
      "source": [
        "Based on your new predictions use `precision_score` and `recall_score` to print out the new precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_qoRSMqFbjfx"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6tuzVTcHblFJ",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-10-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-10-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7yvvLfE0wgqE",
        "colab": {}
      },
      "source": [
        "precision = metrics.precision_score(test[TARGET], predictions)\n",
        "recall = metrics.recall_score(test[TARGET], predictions)\n",
        "print(\"Precision: {}\\nRecall: {}\".format(precision, recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-BU-kVEDyJkm"
      },
      "source": [
        "## Exercise 11: Multiclass Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYBvLLuYmR4G"
      },
      "source": [
        "Create and fit a multiclass classifier to attempt to distinguish each digit from each other from 0 to 9.\n",
        "\n",
        "Report its cross-value score for accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ym8ooazWbwqt"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tyg1w-0jKID",
        "colab": {}
      },
      "source": [
        "multi_class_digit_classifier = None # Create your classifer here\n",
        "cross_value_scores = None # Calculate and report scores here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-11-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-11-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R4_2v1elbyIp",
        "colab": {}
      },
      "source": [
        "multi_class_classifier = linear_model.SGDClassifier(tol=1e-3)  \n",
        "multi_class_classifier.fit(train[FEATURES], train[TARGET])\n",
        "model_selection.cross_val_score(\n",
        "  multi_class_classifier, \n",
        "  test[FEATURES],\n",
        "  test[TARGET],\n",
        "  cv=3,\n",
        "  scoring=\"accuracy\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5BvYN1BjQEK"
      },
      "source": [
        "## Exercise 12: Challenge (Ungraded) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BQhSi3fhmUM1"
      },
      "source": [
        "As an optional exercise, try 4 different binary classifiers of your choice for the  \"less than or equal to 3\" or \"greater than 3\" problem. Graph the ROC curve for all 4 classifiers on the same plot to compare them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mpxsRdBFb3E4"
      },
      "source": [
        "### Student Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6e7e-bCfj70d",
        "colab": {}
      },
      "source": [
        "# Your code goes here."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-12-key-1"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise-12-solution-1"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtsJSGQfb5vo",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}