{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Classification",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "wgjCUHZDcoFN",
        "CzT_KlNQz3QJ",
        "ctYb2Kciz5_g",
        "jl6jXALoz81g",
        "fIUMc607o4nx",
        "aPoWWQ_GzwRl",
        "ARQ5UMWCB6-8",
        "rzu1QHN2Qnp8",
        "KgBbJ6wjXooe",
        "It_3UR-j0bp8",
        "Shdk3nhrr2V2",
        "HkMc6Hwrsq3S",
        "XT5DFgkutI8o",
        "mGj9sLw_uYcC",
        "TVw5HbU_07oY",
        "mmX5KyZk42h_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgjCUHZDcoFN",
        "colab_type": "text"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QYNKEzLcTMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-JgxO6Qcrk9",
        "colab_type": "text"
      },
      "source": [
        "# Binary Classification\n",
        "\n",
        "*Orange you glad I didn't say linear regression again!*\n",
        "\n",
        "> Concepts:\n",
        "  * model types:regression\n",
        "  * model types:classification:binary\n",
        "  * algorithms:linear regression\n",
        "  * algorithms:logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwVCC6XOhhni",
        "colab_type": "text"
      },
      "source": [
        "In this unit we will explore [binary classifcation](https://en.wikipedia.org/wiki/Binary_classification) using [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression).\n",
        " \n",
        "There is quite a bit to unpack in the previous sentence. Some of these terms might be new to you so let's explore them a bit more.\n",
        " \n",
        "*First we will look at [classification](https://en.wikipedia.org/wiki/Statistical_classification).*\n",
        " \n",
        "Classification is the process of mapping a set of datapoints to a finite set of labels. If you studied [regression](https://en.wikipedia.org/wiki/Regression_analysis) you likely remember that regression models, such as [linear regression](https://en.wikipedia.org/wiki/Linear_regression), map input variables to a continuous values. In the domain of machine learning models that predict continuous values are considered regression models. Models that predict from a known finite set of values are considered classification problems.\n",
        " \n",
        "*So what does binary mean?*\n",
        " \n",
        "Binary means that there are two values. Binary classification is used to predict one of two values. These can be *true*/*false*, *hotdog/not hotdog*, *yes*/*no*, or any one of many other this-or-that options.\n",
        " \n",
        "*And what about logistic regression?*\n",
        " \n",
        "We've learned about linear regression, which attempts to fit a line to a set of data in order to predict continuous values. [Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) similarly attempts to fit a line to data. However, the line is typically a [logistic/sigmoid](https://en.wikipedia.org/wiki/Logistic_function) curve. Instead of predicting a continuous value, the model uses the logistic curve to split the data into two classes. One class falls to one side of the line and the second class falls to the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qPWFXBwIzS6",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2SSIlFrIBjv",
        "colab_type": "text"
      },
      "source": [
        "### Learning Objectives\n",
        " \n",
        "* Differentiate between classification and regression models.\n",
        "* Create a logistic regression model for a binary classification problem.\n",
        "* Interpret a confusion matrix for a binary classification model.\n",
        "* Use a grid search to find optimal hyperparameters for a model.\n",
        "* Create an image using color data.\n",
        "* Create and interpret box-and-whisker charts.\n",
        "* Standardize data to improve model training performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wEJDoe9Iuaq",
        "colab_type": "text"
      },
      "source": [
        "### Estimated Duration\n",
        "\n",
        "120 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODh348gr0ddg",
        "colab_type": "text"
      },
      "source": [
        "## Framing the Problem\n",
        "\n",
        "> Concepts:\n",
        "  * problem framing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzMnO97Q0kbo",
        "colab_type": "text"
      },
      "source": [
        "*Cindy's Produce For Good* has a problem. Their business model revolves around collecting unsold fruit and vegetables from local growers and distributing it to families in need so that they can consume it or resell it at local farmer's markets and roadside stands.\n",
        " \n",
        "Quite a few complaints have been coming in lately from families and customers who have had a bitter surprise. They've peeled what they thought was an orange only to bite in and find out that they are eating a grapefruit!\n",
        " \n",
        "Cindy's growers give her truckloads of mixed citrus: lemons, limes, oranges, and grapefruits. She has a volunteer crew sorting the fruit. They are really good at lemons and limes, but falsely identify grapefruit as oranges about 5% of the time.\n",
        " \n",
        "In order to ensure that customers get the oranges they expect Cindy has created a machine that measures the weight, color, and largest diameter of fruit. She wants to create some software that can use this information and tell her workers if the fruit is an orange or not.\n",
        " \n",
        "She put a few thousand pieces of orange-like fruit from one of her shipments through the sensors and manually labelled them as oranges or grapefruit. Looking at the data, she couldn't see an obvious pattern. Her best performance was about 90% accuracy. Her human sorters can do at least 95%. She's now requested our help to see if we can solve the orange vs. grapefruit problem.\n",
        " \n",
        "In this lab we'll examine Cindy's citrus data and try to build a model to help her reliably sort her fruit as well or better than human sorters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAPcKBq854Z5",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1: Thinking About the Data\n",
        "\n",
        "Before we dive in to looking closely at the data, let's think about the problem space and the data set. Please answer the questions Below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFx7Ts3b6N6d",
        "colab_type": "text"
      },
      "source": [
        "#### Question 1\n",
        "\n",
        "Is this problem actually a good fit for machine learning? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEECNP0z4Eqz",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNcJPqVF6UNi",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2igvBUtXqcAS",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzT_KlNQz3QJ",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGcwESY6joR",
        "colab_type": "text"
      },
      "source": [
        "Examine the students answer and see if they make a good case for the machine learning being a good fit. Below you'll see an example argument for and against using machine learning. As long as the arguments or solid, the case for or against machine learning solutions are both acceptable.\n",
        "\n",
        "**Yes**\n",
        "\n",
        "> This problem is probably a good fit for machine learning. She knows the accuracy of her hand-coded system and the accuracy of her workers.  She has already measured her system against her workers and has been unable to come up with a good automated system. Machine learning is at least worth a try.\n",
        "\n",
        "> Also, knowing the accuracy of her workers gives her a very clear success criteria. She can experiment with different models and see if she can build one more accurate than her workers.\n",
        "\n",
        "> As an added benefit, Cindy has a lot of control of her input data. She can calibrate and monitor the scale and lighting around the sensors to give the model very clean input data.\n",
        "\n",
        "**No**\n",
        "\n",
        "> It is likely that machine learning is overkill for this project. Her workers already are accurate 95% of the time. Instead of creating an elaborate system she could solve her problem by having her workers put indeterminant fruit in a separate pile and just label it as \"mixed citrus\". This moves the orange/grapefruit determination downstream to the customer and will likely improve the accuracy of the separate orange and grapefruit piles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVeKI8yNqK6B",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMfvenfO6ZK9",
        "colab_type": "text"
      },
      "source": [
        "#### Question 2\n",
        "\n",
        "If we do build Cindy a machine learning model, what biases might exist in the data? Is there anything that might cause her model to have trouble generalizing to other data? If so, how might she make the model more resilient?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P_GjcKE4Nil",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzqOPKOb6_A2",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T8_zS4Pqio3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctYb2Kciz5_g",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwb7nYJoXV-Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Ensure that the student identifies potential problems with the model and the dataset. Also, make sure the student has at least one mitigation strategy. Below is an example of a good answer.\n",
        " \n",
        "> There are a few sources of biases in Cindy's data. For one, all of the samples came from a single shipment of fruit from a single supplier. The fruit from this supplier might have different characteristics than the fruit from other suppliers, so the model might not generalize well. The time of year and the amount of sun and rain so far in the year could also affect the input data to the model.\n",
        " \n",
        "> To make the model better, Cindy could continue to train the model over time and across suppliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyBkTQZBqj1S",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "814wZ3BlYqK_",
        "colab_type": "text"
      },
      "source": [
        "#### Question 3\n",
        "\n",
        "We've been asked to create a system that determines if a piece of fruit is an orange or not an orange, but aside from that we haven't gotten much information about how the system would work as a whole.\n",
        "\n",
        "Describe how you would design the system from end-to-end. Things to consider:\n",
        "\n",
        "Would the input fruit be all of the fruit that Cindy receives? Only the fruit suspected of being an orange? Only questionable fruit? Anything suspected of being an orange or a grapefruit?\n",
        "\n",
        "What happens to fruit classified as \"not orange\". Is it automatically considered a grapefruit? Is it thrown away? Put in a mixed fruit bag?\n",
        "\n",
        "Justify the inputs and the output actions for the system. What are the trade-offs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6wlYr_74KMT",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEO2I08VcgfR",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JYLIPUpqtzn",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl6jXALoz81g",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-embZc5gbmeJ",
        "colab_type": "text"
      },
      "source": [
        "There are \"what\" and \"why\" components to this question. Make sure that the student is clear on what pieces of fruit go into the system and what to do with fruit classified as \"not an orange\". Also, make sure they have some reasonable arguments as to why. This could be to maximize some performance metric or even to maximize the speed of processing in the system.\n",
        " \n",
        "An example answer might be:\n",
        " \n",
        "> Most of the problem with the system seems to be grapefruit being mistaken for oranges. Since we are probably dealing with a lot of types of fruit and we've only gotten complaints about faux oranges, the processing line will still manually sort all of the fruit and the fruit classified as oranges will then be double-checked in our automated system. Since the system has to check fruit one piece at a time, this will help keep the line moving fast by only using our model on a subset of the fruit.\n",
        " \n",
        "> Once the candidate oranges are classified, those considered \"not an orange\" can put put into the grapefruit pile since for now we only seem to have issues with grapefruit and oranges. If other similar citrus, like tangerine, starts being processed by our line we'd have to re-think this action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1IUQnATqu2u",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO4DpNhgk66g",
        "colab_type": "text"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "> Concepts:\n",
        "  * kaggle:dataset:acquisition\n",
        "  * linux:ls\n",
        "  * linux:unzip\n",
        "  * linux:environment variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRLHpnzclbUI",
        "colab_type": "text"
      },
      "source": [
        "### Acquire the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCJUYfK3k_Au",
        "colab_type": "text"
      },
      "source": [
        "We have some idea about the problem that we are trying to solve, so let's take a look at what has been collected. The data is [hosted on Kaggle](https://www.kaggle.com/joshmcadams/oranges-vs-grapefruit). You can download the dataset and then upload it to this lab or use the code blocks below to fetch the data directly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPYUr0Oal8Oa",
        "colab_type": "text"
      },
      "source": [
        "#### Direct Kaggle Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8Cnk0WmLS1",
        "colab_type": "text"
      },
      "source": [
        "Follow the [API Credentials](https://github.com/Kaggle/kaggle-api#api-credentials) instructions and get a `kaggle.json` file (if you don't already have one) and upload it to this lab.\n",
        "\n",
        "Then run the code block below to download the oranges vs. grapefruit dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DCns7DaatrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!KAGGLE_CONFIG_DIR=`pwd` kaggle datasets download joshmcadams/oranges-vs-grapefruit\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kZpRsJVnXjI",
        "colab_type": "text"
      },
      "source": [
        "There should now be an `oranges-vs-grapefruit.zip` file in the virtual machine for this lab. Let's unzip it so we can access the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lVK5qcenhL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -o oranges-vs-grapefruit.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl8SHuXhn3MA",
        "colab_type": "text"
      },
      "source": [
        "There is now a `citrus.csv` file in our virtual machine. Let's start digging into the data next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2UUc8mkleDw",
        "colab_type": "text"
      },
      "source": [
        "### Basic Analysis\n",
        "\n",
        "> Concepts:\n",
        " * pandas:read_csv\n",
        " * pandas:dataframe:sample\n",
        " * pandas:random_state\n",
        " * pyplot:histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouEjcJQIl1K_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "First and foremost, we need to load the data. For that we'll rely on [Pandas](https://pandas.pydata.org/) and use the `read_csv` function since the data was provided to us as a CSV file.\n",
        " \n",
        "After we load the data, let's sample it to get an idea of what we are working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0tP0yHJ7orM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df.sample(10, random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqg9pDY3mWZe",
        "colab_type": "text"
      },
      "source": [
        " It looks like we have a mixed bag of fruit containing oranges and grapefruit, just as expected.\n",
        "\n",
        " How many do we have of each?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4bIdlfJoVgt",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 2: Basic Statsitics\n",
        "\n",
        "Let's take a moment to determine the distribution of fruit in our dataset. Use [pyplot](https://matplotlib.org/api/pyplot_api.html) to create a histogram of the values in the `name` column of our `DataFrame`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFliytaio2Kk",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gS50q4_oQI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Solution Goes Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwWvCUx2qDpq",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIUMc607o4nx",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rVBSr3epSod",
        "colab_type": "text"
      },
      "source": [
        "Solution using Pandas+PyPlot integration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-6JP23-o7ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df.sample(10, random_state=2020)\n",
        "\n",
        "citrus_df['name'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefgjGblpmyD",
        "colab_type": "text"
      },
      "source": [
        "Alternative solution passing a Panda's Series to PyPlot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXpZFYRUpIro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df.sample(10, random_state=2020)\n",
        "\n",
        "plt.hist(citrus_df['name'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEkZEuQlqHXI",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHo70ZE5pxAk",
        "colab_type": "text"
      },
      "source": [
        "### Interpreting Our Histogram\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz_kZJbbpz3g",
        "colab_type": "text"
      },
      "source": [
        "The histogram shows the data evenly distributed across different types of fruit. This makes the dataset very balanced for building a model for our classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlIQ6RartLAU",
        "colab_type": "text"
      },
      "source": [
        "### Describing Our Dataset\n",
        "\n",
        "> Concepts:\n",
        "  * pandas:dataframe:describe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIPBq2G3tPt3",
        "colab_type": "text"
      },
      "source": [
        "Next, let's do a simple `describe` of our dataset to get some more detailed information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "todQOhCQAayf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citrus_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X1rOcIju8NG",
        "colab_type": "text"
      },
      "source": [
        "Based on this describe output, do we have any missing values?\n",
        "\n",
        "Since every count is 10,000 we don't seem to have missing values.\n",
        "\n",
        "Also, every min value is a positive number. That's a good sign. It would be really odd to have negative diameters, weights, or colors.\n",
        "\n",
        "Do the values themselves look sane? The diameter is measured in centimeters. Is a 2 cm piece of fruit believable? What about a 16 cm piece of fruit?\n",
        "\n",
        "Similarly, do the weights seem within ranges that we'd expect?\n",
        "\n",
        "It is actually difficult to tell since we have a mixed bag of fruit values. We'd likely be better off seeing if the values of individual fruit types makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeIOaYrCxfo6",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 3: More Focused Description\n",
        "\n",
        "We have used `describe()` to get statistics about the entire dataset, but there isn't a lot of information in the data. Write Python code to print `describe()` statistics for each type of fruit in the dataset. Use the `percentiles` argument to the [describe method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) to not print the 25th and 75th percentile.\n",
        "\n",
        "Your output should look similar to:\n",
        "\n",
        "```\n",
        "orange\n",
        "          diameter       weight          red        green         blue\n",
        "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000\n",
        "mean      8.474424   152.804920   156.832800    81.988200     7.115200\n",
        "std       1.260665    18.669021     9.890258    10.090789     6.493779\n",
        "min       2.960000    86.760000   123.000000    49.000000     2.000000\n",
        "50%       8.470000   152.665000   157.000000    82.000000     4.000000\n",
        "max      12.870000   231.090000   192.000000   116.000000    38.000000\n",
        "\n",
        "grapefruit\n",
        "          diameter       weight          red        green         blue\n",
        "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000\n",
        "mean     11.476946   197.296664   150.862800    70.033000    15.611200\n",
        "std       1.221148    19.193190    10.103148    10.044924     9.271592\n",
        "min       7.630000   126.790000   115.000000    31.000000     2.000000\n",
        "50%      11.450000   197.430000   151.000000    70.000000    15.000000\n",
        "max      16.450000   261.510000   187.000000   103.000000    56.000000\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJjtTQBVzosh",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c61DljFmzpY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Solution Goes Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-NaXC8jzvVQ",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPoWWQ_GzwRl",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkL4U6pAx25V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "\n",
        "for citrus_name in citrus_df['name'].unique():\n",
        "  print(citrus_name)\n",
        "  print(citrus_df[citrus_df['name'] == citrus_name].describe(percentiles=[]))\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYKb5JLL0MOV",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYmcbBp0hK0",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing With Boxplots\n",
        "\n",
        "> Concepts:\n",
        " * altair:chart:mark_boxplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3VKH6Um0lVs",
        "colab_type": "text"
      },
      "source": [
        "Now that we've sanity checked our data, let's visualize it to see if we can gather more insight. Above we gathered the min, max, mean, etc. for each numeric column for each type of fruit in a tabular form. Let's now visualize that data using a boxplot and the [Altair](https://altair-viz.github.io/) visualization library.\n",
        "\n",
        "To start using Altair we simply import it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPMKh6R51Z8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import altair as alt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myyagald1fCs",
        "colab_type": "text"
      },
      "source": [
        "Next will want to use the `mark_boxplot` method of the [Chart](https://altair-viz.github.io/user_guide/generated/toplevel/altair.Chart.html?highlight=mark_boxplot) class to create our boxplot.\n",
        "\n",
        "Let's start by plotting the diameter by name.\n",
        "\n",
        "To do this we must first sample a subset of our data. We have 20,000 rows of data and Altair struggles to visualize that much data in a boxplot. The row limit is 5,000 rows so we'll create a 5,000 row sample and then pass that sample to Altair."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlBaIjExfPFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citrus_df_sample = citrus_df.sample(n=5000, random_state=2020)\n",
        "\n",
        "alt.Chart(citrus_df_sample, width=400).mark_boxplot().encode(\n",
        "    x='name',\n",
        "    y='diameter'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgEKnpIK3DXy",
        "colab_type": "text"
      },
      "source": [
        "What insights can we glean from this graphic?\n",
        " \n",
        "As expected, the diameter of a grapefruit trends larger than that of an orange, but there is some overlap.\n",
        " \n",
        "Let's now add in weight to our boxplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9S23tjUAMXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alt.Chart(citrus_df_sample, width=400).mark_boxplot().encode(\n",
        "    x='name',\n",
        "    y='diameter'\n",
        ") | alt.Chart(citrus_df_sample, width=400).mark_boxplot().encode(\n",
        "    x='name',\n",
        "    y='weight'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Rag3gLEHMk",
        "colab_type": "text"
      },
      "source": [
        "### Correlation\n",
        "\n",
        "> Concepts:\n",
        "* pandas:dataframe:corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awOjMaT-AIqZ",
        "colab_type": "text"
      },
      "source": [
        "Notice that relative weight and diameter seem pretty similar. These two columns might be closely correlated enough that we only need to use one of them. Let's check the correlation coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ith_gAJeBV4D",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 4: Correlation Coefficient\n",
        "\n",
        "Based on our visualization above we suspect that diameter and weight are highly correlated. Write code to find the correlation coefficient between the diameter and weight columns in our `DataFrame`.\n",
        "\n",
        "*Hint: Check out the [corr](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html) documentation.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZOllTtZBo93",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvguHDwYB4_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Solution Goes Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-BPzLFMB5xY",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARQ5UMWCB6-8",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Kl-ymlAbkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "\n",
        "citrus_df['diameter'].corr(citrus_df['weight'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsHcORTTCL1w",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8WcHxyREKeC",
        "colab_type": "text"
      },
      "source": [
        "### Understanding the Correlation\n",
        "\n",
        "> Concepts:\n",
        " * statistics:correlation\n",
        " * altair:chart:mark_circle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzKTnQt_ENr8",
        "colab_type": "text"
      },
      "source": [
        "The correlation between diameter and weight is over 99%. That is a very high value.\n",
        "\n",
        "This shouldn't come as a big surprise. We should expect that as the diameter of a piece of fruit grows its weight does also.\n",
        "\n",
        "For now we can leave the data as is, but remember this correlation. We might be able to use it to remove a column from our training data without negatively affecting our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nGieXUmG_8T",
        "colab_type": "text"
      },
      "source": [
        "Let's take another look at height and weight. They are definitely correlated, but how do they relate to each other per fruit type.\n",
        "\n",
        "One way to see this is to use a scatter plot chart to plot the diameter versus the weight, segmented by fruit type.\n",
        "\n",
        "We'll use Altair to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voAyuNFs7uBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alt.Chart(citrus_df_sample).mark_circle().encode(\n",
        "    x='diameter',\n",
        "    y='weight',\n",
        "    color='name'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "748C7ws7I5Bo",
        "colab_type": "text"
      },
      "source": [
        "We can see that oranges and grapefruit have very similar rates of weight gain as their diameter increases. This shouldn't be too surprising since they are very similar fruits.\n",
        " \n",
        "In this chart we can also see that there are some fruits that are clearly oranges because of their small size and weight, as well as some that are clearly grapefruit due to their large size and weight. However, we have a large number of fruit that will be difficult to classify using diameter and weight alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfhTyJXjJOh9",
        "colab_type": "text"
      },
      "source": [
        "### Checking Color Values\n",
        "\n",
        "> Concepts:\n",
        " * pandas:dataframe:groupby:count\n",
        " * pil:image\n",
        " * pyplot:imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjAZwYeIJZmN",
        "colab_type": "text"
      },
      "source": [
        "We've looked pretty closely at the diameter and weight values, but we haven't done much with the color (RGB) values.\n",
        "\n",
        "Let's first see if boxplots are helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCwnzlaqMMPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alt.Chart(citrus_df_sample, width=400).mark_boxplot().encode(\n",
        "    x='name',\n",
        "    y='red'\n",
        ") | alt.Chart(citrus_df_sample, width=400).mark_boxplot().encode(\n",
        "    x='name',\n",
        "    y='green'\n",
        ") | alt.Chart(citrus_df_sample, width=400).mark_boxplot().encode(\n",
        "    x='name',\n",
        "    y='blue'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhD1jxTQJy91",
        "colab_type": "text"
      },
      "source": [
        "There doesn't seem to be a lot of value there, at least examining each element of color separately. There is quite a bit of overlap between each color element, which grapefruit displaying a little less red and green typically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKEKDZTZKKcH",
        "colab_type": "text"
      },
      "source": [
        "It would also be nice to \"sanity check\" the color values similar to how we checked to make sure that our diameters and weights were within reason. We could use statistics to see if the values fall within a range, but then we'd need to know reasonable RGB values for oranges and grapefruit.\n",
        "\n",
        "For this case, since we are dealing with color data we can just create an image for each piece of fruit that contains a sampling (or all) of the colors that we have and we can see if it looks reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4mL5EK4L04L",
        "colab_type": "text"
      },
      "source": [
        "First, let's get an exact count of the number of samples of each fruit type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfZyWY4_Lqo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citrus_df.groupby('name')['name'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO7e97CPL5Db",
        "colab_type": "text"
      },
      "source": [
        "Yay! We have 5000 samples each. We can create a 100x50 image for each fruit and visualize the data.\n",
        "\n",
        "We'll use [PIL's Image class](https://pillow.readthedocs.io/en/stable/reference/Image.html) to create a white 100x50 image. Then we'll get the editable pixel map from the image and assign the color value for each orange in our data to a different pixel in the image.\n",
        "\n",
        "Once we have the image filled out with color we'll use PyPlot to display the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR96sFvDLnCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "\n",
        "height, width = 50, 100\n",
        "img = Image.new('RGB', (width, height), color=(255, 255, 255))\n",
        "pixels = img.load()\n",
        "\n",
        "row_i, col_i = 0, 0\n",
        "for _, fruit in citrus_df[citrus_df['name'] == 'orange'].iterrows():\n",
        "  pixels[col_i, row_i] = (fruit['red'], fruit['green'], fruit['blue'])\n",
        "  col_i += 1\n",
        "  if col_i >= width:\n",
        "    col_i = 0\n",
        "    row_i += 1\n",
        "\n",
        "imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KViuNrS8Px5-",
        "colab_type": "text"
      },
      "source": [
        "That looks like a pretty reasonable orange color. What about the grapefruit?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4u-yPUjP3OX",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 5: Create a Color Map Image\n",
        "\n",
        "We only visualized data from oranges. We'd really like to see the colors of all of the fruit. Create and show a 100x100 image that contains the colors for all of the oranges in the first 100x50 block. This should be followed with the colors for all of the grapefruit in the next 100x50 block. Visually inspect your image to see if the colors are believable as oranges and grapefruit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEs1H0QHQhZy",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWmg9cLXQlWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Solution Goes Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKQo_3M2YITQ",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzu1QHN2Qnp8",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ1PeITOQrNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "\n",
        "height, width = 100, 100\n",
        "img = Image.new('RGB', (width, height), color=(255, 255, 255))\n",
        "pixels = img.load()\n",
        "\n",
        "row_i, col_i = 0, 0\n",
        "for fruit_name in ('orange', 'grapefruit'):\n",
        "  for _, fruit in citrus_df[citrus_df['name'] == fruit_name].iterrows():\n",
        "    pixels[col_i, row_i] = (fruit['red'], fruit['green'], fruit['blue'])\n",
        "    col_i += 1\n",
        "    if col_i >= width:\n",
        "      col_i = 0\n",
        "      row_i += 1\n",
        "\n",
        "imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYuusbTKYK1P",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX2Jwx2wRoxi",
        "colab_type": "text"
      },
      "source": [
        "### Data Analysis Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qWJ3X1aRxk0",
        "colab_type": "text"
      },
      "source": [
        "We've done a lot of data analysis and have a pretty good feel for our data. We have:\n",
        "\n",
        "* Examined the distribution of our dataset and saw that we have an equal distribution of fruit types.\n",
        "* Determined that no data is missing.\n",
        "* Determined that our weight, diameter, and color values are all within reason.\n",
        "* Found a strong correlation between weight and diameter.\n",
        "\n",
        "Let's take our learning and see if we can build a model to classify our oranges!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRd-BEHtTHyL",
        "colab_type": "text"
      },
      "source": [
        "## Simple Logistic Model\n",
        "\n",
        "> Concepts:\n",
        " * pandas:dataframe:columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUeivRYFTLoi",
        "colab_type": "text"
      },
      "source": [
        "It is now time to build and iterate on a model. We'll start with a simple logic regression model using scikit-learn's [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class and the feature columns already in our training data.\n",
        "\n",
        "Let's first remind ourselves of the columns that we have at our disposal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV0d1qhhOxml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citrus_df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlmgcGGVWXUI",
        "colab_type": "text"
      },
      "source": [
        "We'll use 'diameter', 'weight', 'red', 'green', and 'blue' as feature columns. Using 'name' for our target column is tempting, but remember that it contains fruit names for values and for this exercise we are only interested in determining if a piece of fruit is an orange or not an orange.\n",
        "\n",
        "We could leave the column as-is since orange/grapefruit is binary, but to make the target clearer it is not a bad idea to create a new column called 'is_orange' that contains the value `True` if the datum is an orange and `False` otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gry5FUYVXJCy",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 6: Is Orange?\n",
        "\n",
        "Create a new column in `citrus_df` called `is_orange`. The column should be a boolean column and should contain the value `True` if a given row represents an orange and `False` otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrMMuSoMXi-3",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlRxZuRSXlWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Solution Goes Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NyvANlnYGlE",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgBbJ6wjXooe",
        "colab_type": "text"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5sVBo8LXrwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "\n",
        "citrus_df['is_orange'] = citrus_df['name'].apply(lambda name: name == 'orange')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25N8CU5QYV_Q",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBpOC1xuX6Wp",
        "colab_type": "text"
      },
      "source": [
        "### Examining Our New Target Column\n",
        "\n",
        "> Concepts:\n",
        " * pandas:dataframe:groupby:count\n",
        " * pandas:dataframe:boolean tables\n",
        " * pandas:series:unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CVIhZJwYj-8",
        "colab_type": "text"
      },
      "source": [
        "Now that we've created a new target column, we should do some sanity checking to make sure that it was created correctly.\n",
        "\n",
        "First, we'll simply see the count per value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dtKjRtAYtsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citrus_df.groupby('is_orange')['is_orange'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgVllZcyY2p0",
        "colab_type": "text"
      },
      "source": [
        "There should be 5,000 `True` values and 5,000 `False` values.\n",
        "\n",
        "Now check to see that all 5,000 of the `True` values have the `name` \"orange\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdyNHZgZEUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "citrus_df[citrus_df['is_orange']]['name'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPYJT9NKYszc",
        "colab_type": "text"
      },
      "source": [
        "We should only see a single value in the unique list: 'orange'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tf5GjMYaHJE",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Split\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:train_test_split\n",
        " * data:shuffle\n",
        " * data:stratify\n",
        " * data:test-train\n",
        " * numpy:ndarray:shape\n",
        " * pandas:series:shape\n",
        " * pandas:dataframe:shape\n",
        " * pandas:dataframe:describe\n",
        " * pandas:dataframe:groupby:count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r62BzXuyacop",
        "colab_type": "text"
      },
      "source": [
        "We can now split our data for training and testing. First we will create variables to hold our training and target column names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuE6tX8qO3fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_column = 'is_orange'\n",
        "\n",
        "feature_columns = ['diameter', 'weight', 'red', 'green', 'blue']\n",
        "\n",
        "target_column, feature_columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga6YhfzKaxUW",
        "colab_type": "text"
      },
      "source": [
        "We need to split the data into a training and testing set. In this case we'll split 20% of the data off for testing and train off the other 80%.\n",
        "\n",
        "Since we are performing classification and have a fixed number of buckets (two in this case) we should stratify the split using our target column.\n",
        "\n",
        "Also, it is a really good idea to shuffle our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvwWlAKcOliP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    citrus_df[feature_columns],\n",
        "    citrus_df[target_column],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=citrus_df[target_column])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMK0XRQYcHER",
        "colab_type": "text"
      },
      "source": [
        "We can now verify that we have 80% of the data in training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M05Xb00YQce_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP8SlC1NcLHJ",
        "colab_type": "text"
      },
      "source": [
        "And 20% in testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J5iWTZVQgYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTlWBlvPdHmK",
        "colab_type": "text"
      },
      "source": [
        "Let's look at the training data and see if it stratified correctly. There are multiple ways to do this. On a series with two values one way is to simply describe the series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYqtUfInQw2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWTEqjnJdRf4",
        "colab_type": "text"
      },
      "source": [
        "From this output we can see that there are 8,000 pieces of data with 2 unique values. The top value is `True` and it occurs 4,000 times. That would leave us with 4,000 other values that are `False`.\n",
        "\n",
        "We can do the same for the y-test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgTAtdGRRdzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teL0KUBhdx5B",
        "colab_type": "text"
      },
      "source": [
        "Another alternative is to use `groupby` on the series. Notice that the `by` argument contains the series once again and not a column name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwnrwBbKTLo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test.groupby(by=y_test).count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-czcddqd72v",
        "colab_type": "text"
      },
      "source": [
        "### Create and Train the Model\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:linear model:logistic regression\n",
        " * scikit-learn:random_state\n",
        " * scikit-learn:model:fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpAKoPIUd_jW",
        "colab_type": "text"
      },
      "source": [
        "It is finally time to build and train our model. As a reminder, we are using [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Let's see how good we can do.\n",
        "\n",
        "First, we'll build a baseline model with default arguments and see how well it does. To build the model we import `LogisticRegression`, create a class instance, and then fit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCmKNLvDTgti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(random_state=2020)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpguGiacfHVU",
        "colab_type": "text"
      },
      "source": [
        "### Measure Model Performance\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:model:predict\n",
        " * scikit-learn:metrics:accuracy score\n",
        " * scikit-learn:metrics:precision score\n",
        " * scikit-learn:metrics:recall score \n",
        " * scikit-learn:metrics:f1 score\n",
        " * scikit-learn:metrics:confusion matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OHxe_Tle2zI",
        "colab_type": "text"
      },
      "source": [
        "We now have a model ready to use to make predictions. Let's first make predictions on the test data that we held out of our training set and see how good we did.\n",
        "\n",
        "The first step is to actually make the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZcUbj2dUIJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UgWpmXYfnUA",
        "colab_type": "text"
      },
      "source": [
        "Now we can use metrics functions from scikit-learn to see how well our model performed. We'll check the accuracy, precision, recall, and F1 scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIESA8B8WYgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print('Accuracy: ', round(accuracy_score(predictions, y_test), 3))\n",
        "print('Precision: ', round(precision_score(predictions, y_test), 3))\n",
        "print('Recall: ', round(recall_score(predictions, y_test), 3))\n",
        "print('F1: ', round(f1_score(predictions, y_test), 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD3ZQ7AFhctN",
        "colab_type": "text"
      },
      "source": [
        "Numbers for most of the metrics are above 90%, which is better than a human sorter!\n",
        "\n",
        "Let's see how this looks in a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqkTlKu_ax3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
        "\n",
        "print(f'True Positive: {tp}\\nTrue Negative: {tn}\\nFalse Positive: {fp}\\nFalse Negative: {fn}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTXiVIjOkBt6",
        "colab_type": "text"
      },
      "source": [
        "We have just under 100 falsely identified fruit. There are about twice as many false positives as there are false negatives. Let's take a few minutes to think about what this confusion matrix means."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HALEd_j5vRc3",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise 7: Interpreting a Confusion Matrix\n",
        "\n",
        "In the text cell below, explain what a false positive and false negative represents in our dataset? Which is an orange classified as a grapefruit and which is a grapefruit classified as an orange."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g2z3L-v4WXP",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yEN7fQNvqK1",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Yi8NNevu1k",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It_3UR-j0bp8",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg6-Lnlgv_Y2",
        "colab_type": "text"
      },
      "source": [
        "Our false negatives are oranges that were classified as grapefruit. Our false positives are grapefruit that were identified as oranges.\n",
        "\n",
        "This can be verified with the code below that selects misclassified labels into a series and sums them. We can see that the count of `True` values aligns with the 'False Negative' values in the matrix and the count of `False` values aligns with the `False Positive` values in the matrix. Since `True` means \"is orange\" we know that we misclassify more grapefruit as oranges than we do oranges as not oranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFKyf17CwC9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df['is_orange'] = citrus_df['name'].apply(lambda name: name == 'orange')\n",
        "\n",
        "target_column = 'is_orange'\n",
        "feature_columns = ['diameter', 'weight', 'red', 'green', 'blue']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    citrus_df[feature_columns],\n",
        "    citrus_df[target_column],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=citrus_df[target_column])\n",
        "\n",
        "model = LogisticRegression(random_state=2020)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "misclassified = y_test[predictions != y_test]\n",
        "misclassified.groupby(by=misclassified).count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVSTwDYkwAr0",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RptgsFxBkUyf",
        "colab_type": "text"
      },
      "source": [
        "#### ROC Curve\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:metrics:roc curve\n",
        " * scikit-learn:metrics:roc auc score\n",
        " * scikit-learn:model:decision_function\n",
        " * pyplot:plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_s0IEeaPRo_",
        "colab_type": "text"
      },
      "source": [
        "We can visualize this in another way using the Receiver-Operator Curve. This graph plots the true-positive rate on the y-axis against the false-positive rate on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4vXHTwvY4aV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "scores = model.decision_function(X_test)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, scores, pos_label=True)\n",
        "\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEo_TM_ClV8F",
        "colab_type": "text"
      },
      "source": [
        "Interpreting this chart we can see that there is a steep increase in false positives as the true positive rate crosses into the 90% range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7qc9WwVlkMf",
        "colab_type": "text"
      },
      "source": [
        "#### Precision Recall Curve\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:metrics:precision recall curve\n",
        " * scikit-learn:model:decision function\n",
        " * pyplot:plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OFLWPJ0P5hD",
        "colab_type": "text"
      },
      "source": [
        "We can also get a feel for how precision and recall relate for this model by plotting the precision recall curve. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyvmOGaHluCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "scores = model.decision_function(X_test)\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, scores)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.plot(recall, precision)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KozxQbBMnGqJ",
        "colab_type": "text"
      },
      "source": [
        "This shows the balance between precision and recall as the model adjusts classification thresholds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgGfw7FUnMnL",
        "colab_type": "text"
      },
      "source": [
        "## Improving Our Model\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:model selection:grid search cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCXsEo4znO-s",
        "colab_type": "text"
      },
      "source": [
        "Our initial model was actually pretty good. Can it be even better?\n",
        " \n",
        "In the next exercise we'll attempt to improve our model by exploring hyperparameters and manipulating features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmOpuYyOooWx",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 8: Using GridSearchCV\n",
        "\n",
        "We will now experiment with different hyperparameters to see if we can tune the model to increase our scores. To do this we will use the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class to [tune hyperparameters](https://scikit-learn.org/stable/modules/grid_search.html) of the scikit-learn [LogisticRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXG7dvgHrWmQ",
        "colab_type": "text"
      },
      "source": [
        "#### Question 1: Performing the Search\n",
        " \n",
        "Below you will find code that imports the necessary functions and classes and sets up a logistic regression model for grid search. Add code to the grid search to test different hyperparameters such as `tol`, `C`, `solver`, and `max_iter`.\n",
        " \n",
        "The best estimator will be displayed after running the code block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZunsUXx4ZpL",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrFSNQv1onp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df['is_orange'] = citrus_df['name'].apply(lambda name: name == 'orange')\n",
        "\n",
        "target_column = 'is_orange'\n",
        "feature_columns = ['diameter', 'weight', 'red', 'green', 'blue']\n",
        "\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\n",
        "    citrus_df[feature_columns],\n",
        "    citrus_df[target_column],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=citrus_df[target_column])\n",
        "\n",
        "model = LogisticRegression(\n",
        "    random_state=2020,\n",
        ")\n",
        "\n",
        "search = GridSearchCV(model, {\n",
        "  # Your Solution Goes Here\n",
        "})\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(search.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Od1RX5gtCGT",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shdk3nhrr2V2",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cT90hzaoWCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df['is_orange'] = citrus_df['name'].apply(lambda name: name == 'orange')\n",
        "\n",
        "target_column = 'is_orange'\n",
        "feature_columns = ['diameter', 'weight', 'red', 'green', 'blue']\n",
        "\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\n",
        "    citrus_df[feature_columns],\n",
        "    citrus_df[target_column],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=citrus_df[target_column])\n",
        "\n",
        "model = LogisticRegression(\n",
        "    random_state=2020,\n",
        ")\n",
        "\n",
        "search = GridSearchCV(model, {\n",
        "  'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "  'max_iter': [10000],\n",
        "  'C': [0.01, 0.1, 0.5, 1.0],\n",
        "})\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(search.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MTJ5WvjtDeA",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FI4zQuar69J",
        "colab_type": "text"
      },
      "source": [
        "#### Question 2: Validate the Model\n",
        "\n",
        "Now that grid search has produced a model that scored the highest in a cross-validation grid search, let's validate the model to see if it generalizes well on our validation data.\n",
        "\n",
        "We kept validation hold-out data in the `X_validate` and `y_validate` variables. Use that data to calculate the accuracy, precision, recall, and F1 scores for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ49ehXl4chc",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RpgwipWsmB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Solution Goes Here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtZxZufztEqR",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkMc6Hwrsq3S",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa4sHfqnsn8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df['is_orange'] = citrus_df['name'].apply(lambda name: name == 'orange')\n",
        "\n",
        "target_column = 'is_orange'\n",
        "feature_columns = ['diameter', 'weight', 'red', 'green', 'blue']\n",
        "\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\n",
        "    citrus_df[feature_columns],\n",
        "    citrus_df[target_column],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=citrus_df[target_column])\n",
        "\n",
        "model = LogisticRegression(\n",
        "    random_state=2020,\n",
        ")\n",
        "\n",
        "search = GridSearchCV(model, {\n",
        "  'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "  'max_iter': [10000],\n",
        "  'C': [0.01, 0.1, 0.5, 1.0],\n",
        "})\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "model = search.best_estimator_\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_validate)\n",
        "\n",
        "print('Accuracy: ', round(accuracy_score(predictions, y_validate), 3))\n",
        "print('Precision: ', round(precision_score(predictions, y_validate), 3))\n",
        "print('Recall: ', round(recall_score(predictions, y_validate), 3))\n",
        "print('F1: ', round(f1_score(predictions, y_validate), 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwVUsGvWtFph",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdl_tvGZsuVJ",
        "colab_type": "text"
      },
      "source": [
        "#### Question 3: Relative Model Quality\n",
        "\n",
        "Now that we have the scores for our model on our validation set, is the version found by grid search notably better? Discuss the difference in scores, if any, between our base model and the model selected by grid search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL74G6Jk4d9C",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNzRzEB8tHaZ",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP0FL0xftINf",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT5DFgkutI8o",
        "colab_type": "text"
      },
      "source": [
        "##### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLA-Bw2utMMQ",
        "colab_type": "text"
      },
      "source": [
        "The scores are basically the same. Though the grid search selected a different set of hyperparameters than the default, they didn't generalize any better on our validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAXklS3nuUBj",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hphJaGFtvtk",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 9: Final Model Assessment\n",
        "\n",
        "Given our model performance, is this machine learning model a good fit for the problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwVtY7eb4gr8",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIR8qHyyuVPy",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vjHHg2StLPb",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGj9sLw_uYcC",
        "colab_type": "text"
      },
      "source": [
        "### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSIdk-1aubgP",
        "colab_type": "text"
      },
      "source": [
        "Since the scores are very close to human levels of accuracy, both yes and no are acceptable answers.\n",
        " \n",
        "**Yes Case**\n",
        " \n",
        "The model performs as well as a human and Cindy's sorting staff are all volunteers. If the orange/grapefruit sorting can be automated at a level equal to human performance Cindy might as well give it a try and free up her volunteers for other tasks.\n",
        " \n",
        "**No Case**\n",
        " \n",
        "The model doesn't perform significantly better than a human sorter and Cindy didn't mention a shortage of volunteers. People might find value in volunteering. There is no reason to replace them with a complex technological stack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adEU4z8uuZ3Y",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT8bPMU0xBzV",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "> Concepts:\n",
        " * scikit-learn:preprocessing:standard scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g2r7I4y0sPv",
        "colab_type": "text"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "Normalization and standardization of data is not strictly required for performing logistic regression. It is however suggested in some cases. Research reasons why you might want, or not want, to normalize or standardize your input data to a logistic regression.\n",
        "\n",
        "Explain your findings and link to any relevant articles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKe9gOYY4jQa",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tibOqWcM1UIP",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n9SPA9z1MhQ",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVw5HbU_07oY",
        "colab_type": "text"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjSoiFW51yt_",
        "colab_type": "text"
      },
      "source": [
        "If you search for \"normalize data for logistic regression\" and \"standardize data for logistic regression\" you'll find a wide variety of opinions on the topic.\n",
        "\n",
        "The regularization method used in the regression might benefit from standardization. This is set with the 'penalty' hyperparameter.\n",
        "\n",
        "References:\n",
        "  * [Logistic regression and scaling of features](https://stats.stackexchange.com/questions/290958/logistic-regression-and-scaling-of-features)\n",
        "  * [Is standardization needed before fitting logistic regression?](https://stats.stackexchange.com/questions/48360/is-standardization-needed-before-fitting-logistic-regression)\n",
        "  * [When conducting multiple regression, when should you center your predictor variables & when should you standardize them?](https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56dA_utF3IFG",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v56Y-Ix93JfE",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Use the [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to scale the feature data before training a logistic model. Use [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to iterate through hyperparameters to find an optimal model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmv-j6oR4lFK",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLTLFHgZyP_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPW8fDV34mtj",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Ehs9Cc0o_w",
        "colab_type": "text"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1cIjSzz0rFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "citrus_df = pd.read_csv('citrus.csv', header=0)\n",
        "citrus_df['is_orange'] = citrus_df['name'].apply(lambda name: name == 'orange')\n",
        "\n",
        "target_column = 'is_orange'\n",
        "feature_columns = ['diameter', 'weight', 'red', 'green', 'blue']\n",
        "\n",
        "scaler = StandardScaler() \n",
        "data_scaled = scaler.fit_transform(citrus_df[feature_columns])\n",
        "\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(\n",
        "    data_scaled,\n",
        "    citrus_df[target_column],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=citrus_df[target_column])\n",
        "\n",
        "model = LogisticRegression(\n",
        "    random_state=2020,\n",
        ")\n",
        "\n",
        "search = GridSearchCV(model, {\n",
        "  'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "  'max_iter': [10000],\n",
        "  'C': [0.01, 0.1, 0.5, 1.0],\n",
        "})\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print(search.best_estimator_)\n",
        "\n",
        "model = search.best_estimator_\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_validate)\n",
        "\n",
        "print('Accuracy: ', round(accuracy_score(predictions, y_validate), 3))\n",
        "print('Precision: ', round(precision_score(predictions, y_validate), 3))\n",
        "print('Recall: ', round(recall_score(predictions, y_validate), 3))\n",
        "print('F1: ', round(f1_score(predictions, y_validate), 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBRhFJkf3x_t",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Are the optimal hyperparameters the same for the logistic regression model before and after scaling the data? Why or why not? Did you notice any other differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS4EWkOS3-MH",
        "colab_type": "text"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy3g7pz4win",
        "colab_type": "text"
      },
      "source": [
        "*Please Put Your Answer Here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5zDowQC4xMq",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmX5KyZk42h_",
        "colab_type": "text"
      },
      "source": [
        "#### Answer Key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrKKwyBc45Ri",
        "colab_type": "text"
      },
      "source": [
        "The best model hyperparameters selected after standardization where the same in after standardization, however, the validation scoring suffered a bit. One noticeable difference was that the grid search returned almost instantly on the scaled data, but too minutes to return for the non-scaled data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmymrjVu43-s",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    }
  ]
}